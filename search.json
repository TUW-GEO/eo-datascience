[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Earth Observation Datascience",
    "section": "",
    "text": "Preface\nThis is a collection of Jupyter notebooks for education at the TU Wien.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/Classification.html",
    "href": "chapters/Classification.html",
    "title": "2  Classification of Sentinel-2 imagery",
    "section": "",
    "text": "2.1 Data Acquisition\nIn this chapter, we will employ machine learning techniques to classify a scene using satellite imagery. Specifically, we will utilize scikit-learn to implement two distinct classifiers and subsequently compare their results. To begin, we need to import the following modules.\nfrom datetime import datetime, timedelta\n\nimport xarray as xr\nimport pystac_client\nimport odc.stac\nimport rioxarray  # noqa: F401\nimport geopandas as gpd\nfrom odc.geo.geobox import GeoBox\nfrom shapely.geometry import Polygon\n\nimport cmcrameri as cmc  # noqa: F401\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as colors\nimport pandas as pd\n\n# Scikit Learn\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nBefore we start, we need to load the data. We will use odc-stac to obtain data from Earth Search by Element 84. Here we define the area of interest and the time frame, aswell as the EPSG code and the resolution.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/Classification.html#data-acquisition",
    "href": "chapters/Classification.html#data-acquisition",
    "title": "2  Classification of Sentinel-2 imagery",
    "section": "",
    "text": "2.1.1 Searching in the Catalog\nThe module odc-stac provides access to free, open source satelite data. To retrieve the data, we must define several parameters that specify the location and time period for the satellite data. Additionally, we must specify the data collection we wish to access, as multiple collections are available. In this example, we will use multispectral imagery from the Sentinel-2 satellite.\n\ndx = 0.0006  # 60m resolution\nepsg = 4326\n\n# Set Spatial extent\nlatmin, latmax = 47.86, 48.407\nlonmin, lonmax = 16.32, 16.9\nbounds = (lonmin, latmin, lonmax, latmax)\n\n\n# Set Temporal extent\nstart_date = datetime(year=2024, month=5, day=1)\nend_date = start_date + timedelta(days=10)\n\ntime_format = \"%Y-%m-%d\"\ndate_query = start_date.strftime(time_format) + \"/\" + end_date.strftime(time_format)\n\n# Search for Sentinel-2 data\nitems = pystac_client.Client.open(\n    \"https://earth-search.aws.element84.com/v1\"\n).search(\n    bbox=bounds,\n    collections=[\"sentinel-2-l2a\"],\n    datetime=date_query,\n    limit=100,\n).item_collection()\nprint(len(items), 'scenes found')\n\n10 scenes found\n\n\nWe will now focus on the area south-east of Vienna, where the Nationalpark Donauauen is situated. The time frame we are interested in is the beginning of May 2024. After passing these parameters to the stac-catalog we have found 10 scenes that we can use for our analysis.\n\n\n2.1.2 Loading the Data\nNow we will load the data directly into an xarray dataset, which we can use to perform computations on the data. xarray is a powerful library for working with multi-dimensional arrays, making it well-suited for handling satellite data.\nHere’s how we can load the data using odc-stac and xarray:\n\n# define a geobox for my region\ngeobox = GeoBox.from_bbox(bounds, crs=f\"epsg:{epsg}\", resolution=dx)\n\n# lazily combine items into a datacube\ndc = odc.stac.load(\n    items,\n    bands=[\"scl\", \"red\", \"green\", \"blue\", \"nir\"],\n    chunks={'time': 5, 'x': 600, 'y': 600},\n    geobox=geobox,\n    resampling=\"bilinear\",\n)\ndc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 79MB\nDimensions:      (latitude: 913, longitude: 967, time: 10)\nCoordinates:\n  * latitude     (latitude) float64 7kB 48.41 48.41 48.41 ... 47.86 47.86 47.86\n  * longitude    (longitude) float64 8kB 16.32 16.32 16.32 ... 16.9 16.9 16.9\n    spatial_ref  int32 4B 4326\n  * time         (time) datetime64[ns] 80B 2024-05-01T09:57:21.858000 ... 202...\nData variables:\n    scl          (time, latitude, longitude) uint8 9MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    red          (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    green        (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    blue         (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    nir          (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;xarray.DatasetDimensions:latitude: 913longitude: 967time: 10Coordinates: (4)latitude(latitude)float6448.41 48.41 48.41 ... 47.86 47.86units :degrees_northresolution :-0.0006crs :EPSG:4326array([48.4071, 48.4065, 48.4059, ..., 47.8611, 47.8605, 47.8599], shape=(913,))longitude(longitude)float6416.32 16.32 16.32 ... 16.9 16.9units :degrees_eastresolution :0.0006crs :EPSG:4326array([16.3203, 16.3209, 16.3215, ..., 16.8987, 16.8993, 16.8999], shape=(967,))spatial_ref()int324326spatial_ref :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]crs_wkt :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensemblegrid_mapping_name :latitude_longitudeGeoTransform :16.320000000000000284217094 0.000599999999999999947438 0 48.407399999999995543475961 0 -0.000599999999999999947438array(4326, dtype=int32)time(time)datetime64[ns]2024-05-01T09:57:21.858000 ... 2...array(['2024-05-01T09:57:21.858000000', '2024-05-01T09:57:24.892000000',\n       '2024-05-04T10:07:18.103000000', '2024-05-04T10:07:22.389000000',\n       '2024-05-06T09:57:19.789000000', '2024-05-06T09:57:22.823000000',\n       '2024-05-09T10:07:16.090000000', '2024-05-09T10:07:20.373000000',\n       '2024-05-11T09:57:22.239000000', '2024-05-11T09:57:25.274000000'],\n      dtype='datetime64[ns]')Data variables: (5)scl(time, latitude, longitude)uint8dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n8.42 MiB\n1.72 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint8 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nred(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\ngreen(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nblue(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nnir(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nIndexes: (3)latitudePandasIndexPandasIndex(Index([ 48.40709999999999, 48.406499999999994, 48.405899999999995,\n        48.40529999999999,  48.40469999999999,  48.40409999999999,\n       48.403499999999994, 48.402899999999995,  48.40229999999999,\n        48.40169999999999,\n       ...\n        47.86529999999999,  47.86469999999999,  47.86409999999999,\n       47.863499999999995, 47.862899999999996,  47.86229999999999,\n        47.86169999999999,  47.86109999999999, 47.860499999999995,\n       47.859899999999996],\n      dtype='float64', name='latitude', length=913))longitudePandasIndexPandasIndex(Index([           16.3203, 16.320899999999998,            16.3215,\n                  16.3221,            16.3227,            16.3233,\n                  16.3239,            16.3245,            16.3251,\n                  16.3257,\n       ...\n                  16.8945,            16.8951, 16.895699999999998,\n                  16.8963,            16.8969,            16.8975,\n                  16.8981, 16.898699999999998,            16.8993,\n                  16.8999],\n      dtype='float64', name='longitude', length=967))timePandasIndexPandasIndex(DatetimeIndex(['2024-05-01 09:57:21.858000', '2024-05-01 09:57:24.892000',\n               '2024-05-04 10:07:18.103000', '2024-05-04 10:07:22.389000',\n               '2024-05-06 09:57:19.789000', '2024-05-06 09:57:22.823000',\n               '2024-05-09 10:07:16.090000', '2024-05-09 10:07:20.373000',\n               '2024-05-11 09:57:22.239000', '2024-05-11 09:57:25.274000'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/Classification.html#data-visualization",
    "href": "chapters/Classification.html#data-visualization",
    "title": "2  Classification of Sentinel-2 imagery",
    "section": "2.2 Data Visualization",
    "text": "2.2 Data Visualization\n\n2.2.1 RGB Image\nWith the image data now in our possession, we can proceed with computations and visualizations.\nFirst, we define a mask to exclude cloud cover and areas with missing data. Subsequently, we create a composite median image, where each pixel value represents the median value across all the scenes we have identified. This approach helps to eliminate clouds and outliers present in some of the images, thereby providing a clearer and more representative visualization of the scene.\n\n# define a mask for valid pixels (non-cloud)\ndef is_valid_pixel(data):\n    # include only vegetated, not_vegitated, water, and snow\n    return ((data &gt; 3) & (data &lt; 7)) | (data == 11)\n\n\ndc[\"valid\"] = is_valid_pixel(dc.scl)\n\n# compute the masked median\nrgb_median = (\n    dc[[\"red\", \"green\", \"blue\"]]\n    .where(dc.valid)\n    .to_dataarray(dim=\"band\")\n    .median(dim=\"time\")\n    .astype(int)\n)\n\n# plot the median composite\ntitle_rgb = (\n    \"RGB - Median Composite\"\n    + f\"\\n{start_date.strftime('%d.%m.%Y')} - {end_date.strftime('%d.%m.%Y')}\"\n)\nrgb_median.plot.imshow(robust=True).axes.set_title(title_rgb)\nplt.show()\n\n/usr/share/miniconda/envs/Classification/lib/python3.12/site-packages/rasterio/warp.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n  dest = _reproject(\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 False Color Image\nIn addition to the regular RGB Image, we can swap any of the bands from the visible spectrum with any other bands. In this specific case the red band has been changed to the near infrared band. This allows us to see vegetated areas more clearly, since they now appear in a bright red color. This is due to the fact that plants absorb regular red light while reflecting near infrared light (NASA 2020).\n\n# compute a false color image\n# near infrared instead of red\nfc_median = (\n    dc[['nir', 'green', 'blue']]\n    .where(dc.valid)\n    .to_dataarray(dim=\"band\")\n    .transpose(..., \"band\")\n    .median(dim=\"time\")\n    .astype(int)\n)\n\ntitle_fc = (\n    \"False color - Median Composite\"+\n    f\"\\n{start_date.strftime('%d.%m.%Y')} - {end_date.strftime('%d.%m.%Y')}\"\n)\nfc_median.plot.imshow(robust=True).axes.set_title(title_fc)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.2.3 NDVI Image\nTo get an first impression of the data, we can calculate the NDVI (Normalized Difference Vegetation Index) and plot it. The NDVI is calculated by useing the following formula. (Rouse et al. 1974)\n\\[\nNDVI = \\frac{NIR - Red}{NIR + Red}\n\\]\nThis gives us a good overview of the vegetation in the area. The values can range from -1 to 1 where the following meanings are associated with these values:\n\n-1 to 0 indicate dead plants or inanimate objects\n0 to 0.33 are unhealthy plants\n0.33 to 0.66 are moderatly healthy plants\n0.66 to 1 are very healthy plants\n\n\n# Normalized Difference Vegetation Index (NDVI)\ndef normalized_difference(a, b):\n    return (a - b * 1.0) / (a + b)\n\n\nndvi = normalized_difference(dc.nir, dc.red)\nndvi.median(dim=\"time\").plot.imshow(\n    cmap=\"cmc.cork\", vmin=-1, vmax=1\n).axes.set_title(\"NDVI\")\nplt.show()",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/Classification.html#classification",
    "href": "chapters/Classification.html#classification",
    "title": "2  Classification of Sentinel-2 imagery",
    "section": "2.3 Classification",
    "text": "2.3 Classification\nIn this chapter, we will classify the satellite data to identify forested areas within the scene. By using supervised machine learning techniques, we can train classifiers to distinguish between forested and non-forested regions based on the training data we provide. We will explore two different classifiers and compare their performance in accurately identifying forest areas.\n\n2.3.1 Regions of Interest\nSince this is a supervised classification, we need to have some training data. Therefore we need to define areas or regions, which we are certain represent the feature which we are classifiying. In this case we are interested in forested areas and regions that are definitly not forested. These regions will be used to train our classifiers.\n\n# Define Polygons\nforest_areas = {\n    0: [Polygon([(16.482772, 47.901753), (16.465133, 47.870124), (16.510142, 47.874382), (16.482772, 47.901753)])],\n    1: [Polygon([(16.594079, 47.938855), (16.581914, 47.894454), (16.620233, 47.910268), (16.594079, 47.938855)])],\n    2: [Polygon([(16.67984, 47.978998), (16.637263, 47.971091), (16.660376, 47.929123), (16.67984, 47.978998)])],\n    3: [Polygon([(16.756477, 48.000286), (16.723024, 47.983256), (16.739446, 47.972916), (16.756477, 48.000286)])],\n    4: [Polygon([(16.80696, 48.135923), (16.780806, 48.125583), (16.798445, 48.115243), (16.80696, 48.135923)])],\n    5: [Polygon([(16.684097, 48.144438), (16.664634, 48.124366), (16.690788, 48.118892), (16.684097, 48.144438)])],\n    6: [Polygon([(16.550894, 48.169984), (16.530822, 48.165118), (16.558801, 48.137139), (16.550894, 48.169984)])],\n    7: [Polygon([(16.588604, 48.402329), (16.556976, 48.401112), (16.580697, 48.382865), (16.588604, 48.402329)])],\n}\n\nnonforest_areas = {\n    0: [Polygon([(16.674974, 48.269126), (16.623882, 48.236281), (16.682272, 48.213168), (16.674974, 48.269126)])],\n    1: [Polygon([(16.375723, 48.228374), (16.357476, 48.188839), (16.399444, 48.185798), (16.375723, 48.228374)])],\n    2: [Polygon([(16.457834, 48.26426), (16.418907, 48.267301), (16.440804, 48.23324), (16.457834, 48.26426)])],\n    3: [Polygon([(16.519266, 48.101861), (16.470607, 48.100645), (16.500411, 48.07145), (16.519266, 48.101861)])],\n    4: [Polygon([(16.453577, 48.051986), (16.412217, 48.067192), (16.425598, 48.012451), (16.453577, 48.051986)])],\n}\n\n\n# Geoppandas Dataframe from Polygons\nforest_df = gpd.GeoDataFrame(\n    {\"geometry\": [poly[0] for poly in forest_areas.values()]}, crs=\"EPSG:4326\"\n)\nnonforest_df = gpd.GeoDataFrame(\n    {\"geometry\": [poly[0] for poly in nonforest_areas.values()]},\n    crs=\"EPSG:4326\",\n)\n\n\n# Plotting Regions of Interest\nfig, ax = plt.subplots()\nrgb_median.plot.imshow(ax=ax, robust=True)\nforest_df.plot(ax=ax, ec=\"C0\", fc=\"none\")\nnonforest_df.plot(ax=ax, ec=\"C1\", fc=\"none\")\nax.set_title(\"Regions of Interest\")\nax.set_aspect(\"equal\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n2.3.2 Data Preparation\nIn addition to the Regions of Interest we will extract the specific bands from the loaded dataset that we intend to use for the classification, which are the red, green, blue and near-infrared bands, although other bands can also be utilized. Using these bands, we will create both a training and a testing dataset. The training dataset will be used to train the classifier, while the testing dataset will be employed to evaluate its performance.\n\n# Classifiying dataset (only necessary bands)\nbands = [\"red\", \"green\", \"blue\", \"nir\"]\nds_class = dc[bands].where(dc.valid).median(dim=\"time\")\nds_class = ds_class.fillna(0)\n\n\ndef clip_array(ds: xr.Dataset, polygons):\n    clipped = ds.rio.clip(polygons, invert=False, all_touched=False, drop=True)\n    clipped_nan = clipped.where(clipped == ds)\n    return clipped_nan\n\n\n# Dictionaries with Dataarrays, each clipped by a Polygon\ndata_dict_feat = {\n    idx: clip_array(ds_class, polygon) for idx, polygon in forest_areas.items()\n}\ndata_dict_nonfeat = {\n    idx: clip_array(ds_class, polygon)\n    for idx, polygon in nonforest_areas.items()\n}\n\n\n# Reshape the polygon dataarrays to get a tuple (one value per band) of pixel values\nfeat_data = [\n    xarray.to_array().values.reshape(len(bands), -1).T\n    for xarray in data_dict_feat.values()\n]  # replaced median_data_dict_feat with data_dict_feat\nnonfeat_data = [\n    xarray.to_array().values.reshape(len(bands), -1).T\n    for xarray in data_dict_nonfeat.values()\n]  # replaced median_data_dict_feat with data_dict_feat\n\n# The rows of the different polygons are concatenated to a single array for further processing\nfeat_values = np.concatenate(feat_data)\nnonfeat_values = np.concatenate(nonfeat_data)\n\n# Drop Nan Values\nX_feat_data = feat_values[~np.isnan(feat_values).any(axis=1)]\nX_nonfeat_data = nonfeat_values[~np.isnan(nonfeat_values).any(axis=1)]\n\n\n# Creating Output Vector (1 for pixel is features; 0 for pixel is not feature)\ny_feat_data = np.ones(X_feat_data.shape[0])\ny_nonfeat_data = np.zeros(X_nonfeat_data.shape[0])\n\n# Concatenate all Classes for training\nX = np.concatenate([X_feat_data, X_nonfeat_data])\ny = np.concatenate([y_feat_data, y_nonfeat_data])\n\n# Split into Training and Testing Data.\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.5, random_state=42\n)\n\nNow that we have prepared the training and testing data, we will create an image array of the actual scene that we intend to classify. This array will serve as the input for our classification algorithms, allowing us to apply the trained classifiers to the entire scene and identify the forested and non-forested areas accurately.\n\nimage_data = (\n    ds_class[bands]\n    .to_array(dim=\"band\")\n    .transpose(\"latitude\", \"longitude\", \"band\")\n)\n\n# Reshape the image data\nnum_of_pixels = ds_class.sizes[\"longitude\"] * ds_class.sizes[\"latitude\"]\nnum_of_bands = len(bands)\nX_image_data = image_data.values.reshape(num_of_pixels, num_of_bands)\n\n\n\n2.3.3 Classifiying with Naive Bayes\nNow that we have prepared all the needed data, we can begin the actual classification process.\nWe will start with a Naive Bayes classifier. First, we will train the classifier using our training dataset. Once trained, we will apply the classifier to the actual image to identify the forested and non-forested areas.\n\n# Naive Bayes initialization and training\nnb = GaussianNB()\nnb_test = nb.fit(X_train, y_train)\nnb_predict = nb.predict(X_test)\n\n# Prediction on image\nnb_predict_img = nb.predict(X_image_data)\nnb_predict_img = nb_predict_img.reshape(\n    ds_class.sizes[\"latitude\"], ds_class.sizes[\"longitude\"]\n)\n\n# Adding the Naive Bayes Prediction to the dataset\nds_class[\"NB-forest\"] = xr.DataArray(\n    nb_predict_img,\n    dims=[\"latitude\", \"longitude\"],\n    coords={\n        \"longitude\": ds_class[\"longitude\"],\n        \"latitude\": ds_class[\"latitude\"],\n    },\n)\n\nTo evaluate the effectiveness of the classification, we will plot the image predicted by the classifier. Additionally, we will examine the Classification Report and the Confusion Matrix to gain further insights into the classifier’s performance.\n\n# Plot Naive Bayes\nalpha = 1\ncmap_green = colors.ListedColormap([(1, 1, 1, alpha), \"green\"])\n\nplot = ds_class[\"NB-forest\"].plot.imshow(\n    cmap=cmap_green, cbar_kwargs={\"ticks\": [0.25, 0.75]}\n)\ncbar = plot.colorbar\ncbar.set_ticklabels([\"non-forest\", \"forest\"])\nplot.axes.set_title(\"Naive Bayes Classification\")\nplt.show()\n\n# Print the Classification report\nprint(\"NAIVE BAYES: \\n \" + classification_report(y_test, nb_predict))\n\n# Print the confusion matrix\ncon_mat_nb = pd.DataFrame(\n    confusion_matrix(y_test, nb_predict),\n    index=[\"Actual Negative\", \"Actual Positive\"],\n    columns=[\"Predicted Negative\", \"Predicted Positive\"],\n)\ndisplay(con_mat_nb)\n\n\n\n\n\n\n\n\nNAIVE BAYES: \n               precision    recall  f1-score   support\n\n         0.0       0.95      0.82      0.88      6618\n         1.0       0.81      0.95      0.88      5487\n\n    accuracy                           0.88     12105\n   macro avg       0.88      0.88      0.88     12105\nweighted avg       0.89      0.88      0.88     12105\n\n\n\n\n\n\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\n5406\n1212\n\n\nActual Positive\n276\n5211\n\n\n\n\n\n\n\n\n\n2.3.4 Classifiying with Random Forest\nTo ensure our results are robust, we will explore an additional classifier. In this section, we will use the Random Forest classifier. The procedure for using this classifier is the same as before: we will train the classifier using our training dataset and then apply it to the actual image to classify the scene.\n\n# Random Forest initialization and training\nrf = RandomForestClassifier(n_estimators=100)\nrf_test = rf.fit(X_train, y_train)\nrf_predict = rf.predict(X_test)\n\n# Prediction on image\nrf_predict_img = rf.predict(X_image_data)\nrf_predict_img = rf_predict_img.reshape(\n    ds_class.sizes[\"latitude\"], ds_class.sizes[\"longitude\"]\n)\n\n# Adding the Random Forest Prediction to the dataset\nds_class[\"RF-forest\"] = xr.DataArray(\n    rf_predict_img,\n    dims=[\"latitude\", \"longitude\"],\n    coords={\n        \"longitude\": ds_class[\"longitude\"],\n        \"latitude\": ds_class[\"latitude\"],\n    },\n)\n\nplot = ds_class[\"RF-forest\"].plot.imshow(\n    cmap=cmap_green, cbar_kwargs={\"ticks\": [0.25, 0.75]}\n)\ncbar = plot.colorbar\ncbar.set_ticklabels([\"non-forest\", \"forest\"])\nplot.axes.set_title(\"Random Forest Classification\")\nplt.show()\n\n# Print the Classification report\nprint(\"RANDOM FOREST: \\n \" + classification_report(y_test, rf_predict))\n\n# Print the confusion matrix\ncon_mat_rf = pd.DataFrame(\n    confusion_matrix(y_test, rf_predict),\n    index=[\"Actual Negative\", \"Actual Positive\"],\n    columns=[\"Predicted Negative\", \"Predicted Positive\"],\n)\ndisplay(con_mat_rf)\n\n\n\n\n\n\n\n\nRANDOM FOREST: \n               precision    recall  f1-score   support\n\n         0.0       0.96      0.95      0.95      6618\n         1.0       0.94      0.95      0.95      5487\n\n    accuracy                           0.95     12105\n   macro avg       0.95      0.95      0.95     12105\nweighted avg       0.95      0.95      0.95     12105\n\n\n\n\n\n\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\n6297\n321\n\n\nActual Positive\n282\n5205\n\n\n\n\n\n\n\nWe can already see from the classification reports and the confusion matrices that the Random Forest classifier has outperformed the Naive Bayes classifier. This is particularly evident from the lower values in the secondary diagonal, indicating minimal False Positives and False Negatives. It appears that the Naive Bayes classifier is more sensitive to False Positives, resulting in a higher rate of incorrect classifications.\n\n\n2.3.5 Comparison of the Classificators\nTo gain a more in-depth understanding of the classifiers’ performance, we will compare their results. Specifically, we will identify the areas where both classifiers agree and the areas where they disagree. This comparison will provide valuable insights into the strengths and weaknesses of each classifier, allowing us to better assess their effectiveness in identifying forested and non-forested regions.\n\n\nCode\ncmap_trio = colors.ListedColormap(\n    [\"whitesmoke\", \"indianred\", \"goldenrod\", \"darkgreen\"]\n)\n\n\ndouble_clf = ds_class[\"NB-forest\"] + 2 * ds_class[\"RF-forest\"]\n\nfig, ax = plt.subplots()\ncax = ax.imshow(double_clf, cmap=cmap_trio, interpolation=\"none\")\n\n# Add a colorbar with custom tick labels\ncbar = fig.colorbar(cax, ticks=[1 * 0.375, 3 * 0.375, 5 * 0.375, 7 * 0.375])\ncbar.ax.set_yticklabels([\"None\", \"Naive Bayes\", \"Random Forest\", \"Both\"])\nax.set_title(\"Classification Comparisson\")\nax.set_axis_off()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe areas where both classifiers agree include the larger forested regions, such as the Nationalpark Donau-Auen and the Leithagebirge. Additionally, both classifiers accurately identified the urban areas of Vienna and correctly excluded them from being classified as forested.\n\n\nCode\n# Plot only one class, either None (0), Naive Bayes (1), Random Forest (2), or Both (3)\nfig, axs = plt.subplots(2, 2, figsize=(8, 8))\nax = axs.ravel()\n\nfor i in range(4):\n    ax[i].imshow(double_clf == i, cmap=\"cmc.oleron_r\", interpolation=\"none\")\n    category = [\n        \"by None\",\n        \"only by Naive Bayes\",\n        \"only by Random Forest\",\n        \"by Both\",\n    ][i]\n    title = \"Areas classified \" + category\n    ax[i].set_title(title)\n    ax[i].set_axis_off()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nWhen plotting the classified areas individually, we observe that the Random Forest classifier mistakenly identified the Danube River as a forested area. Conversely, the Naive Bayes classifier erroneously classified a significant amount of cropland as forest.\nFinally, by analyzing the proportion of forested areas within the scene, we find that approximately 18% of the area is classified as forest, while around 66% is classified as non-forest. The remaining areas, which include water bodies and cropland, fall into less clearly defined categories.\nThe accompanying bar chart illustrates the distribution of these classifications, highlighting the percentage of forested areas, non-forested areas, and regions classified by only one of the two classifiers. This visual representation helps to quantify the areas of agreement and disagreement between the classifiers, providing a clearer picture of their performance.\n\n\nCode\ncounts = {}\nfor num in range(0, 4):\n    num_2_class = {0: \"None\", 1: \"Naive Bayes\", 2: \"Random Forest\", 3: \"Both\"}\n    counts[num_2_class[num]] = int((double_clf == num).sum().values)\n\nclass_counts_df = pd.DataFrame(\n    list(counts.items()), columns=[\"Class\", \"Count\"]\n)\nclass_counts_df[\"Percentage\"] = (\n    class_counts_df[\"Count\"] / class_counts_df[\"Count\"].sum()\n) * 100\nax = class_counts_df.plot.bar(\n    x=\"Class\",\n    y=\"Percentage\",\n    rot=0,\n    color=\"darkgreen\",\n    ylim=(0, 100),\n    title=\"Classified Areas per Classificator (%)\",\n)\n\n# Annotate the bars with the percentage values\nfor p in ax.patches:\n    ax.annotate(\n        f\"{p.get_height():.1f}%\",\n        (p.get_x() + p.get_width() / 2.0, p.get_height()),\n        ha=\"center\",\n        va=\"center\",\n        xytext=(0, 9),\n        textcoords=\"offset points\",\n    )",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/Classification.html#conclusion",
    "href": "chapters/Classification.html#conclusion",
    "title": "2  Classification of Sentinel-2 imagery",
    "section": "2.4 Conclusion",
    "text": "2.4 Conclusion\nIn this chapter, we utilized machine learning to classify satellite imagery into forested and non-forested areas, comparing Naive Bayes and Random Forest classifiers. The Random Forest classifier generally outperformed Naive Bayes, with fewer errors in classification, although it misclassified the Danube River as forested, while Naive Bayes incorrectly identified cropland as forest. The analysis, supported by the bar chart, revealed that about 18% of the scene was classified as forest, 66% as non-forest, and the remainder included ambiguous categories. This comparison highlights the strengths and limitations of each classifier, underscoring the need for careful selection and evaluation of classification methods.\n\n\n\n\nNASA. 2020. “Earth Observatory.” 2020. https://earthobservatory.nasa.gov/features/MeasuringVegetation/measuring_vegetation_2.php.\n\n\nRouse, John Wilson, Rüdiger H Haas, John A Schell, Donald W Deering, et al. 1974. “Monitoring Vegetation Systems in the Great Plains with ERTS.” NASA Spec. Publ 351 (1): 309.",
    "crumbs": [
      "Tutorials",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html",
    "href": "chapters/Floodmapping.html",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "",
    "text": "3.1 Greece Flooding 2018\nThis notebook explains how microwave (\\(\\sigma^0\\)) backscattering can be used to map the extent of a flood. We replicate in this exercise the work of (Bauer-Marschallinger et al. 2022) on the TU Wien Bayesian-based flood mapping algorithm.\nIn this exercise we will replicate the case study of the above mentioned paper, the February 2018 flooding of the Greek region of Thessaly.\ntime_range = \"2018-02-28T04:00:00Z/2018-02-28T05:00:00Z\"\nminlon, maxlon = 21.93, 22.23\nminlat, maxlat = 39.47, 39.64\nbounding_box = [minlon, minlat, maxlon, maxlat]",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html#eodc-stac-catalog",
    "href": "chapters/Floodmapping.html#eodc-stac-catalog",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "3.2 EODC STAC Catalog",
    "text": "3.2 EODC STAC Catalog\nThe data required for TU Wien flood mapping algorithm consists of terrain corrected sigma naught backscatter data \\(\\sigma^{0}\\), the projected local incidence angle (PLIA) values of those measurements, and the harmonic parameters (HPAR) of a model fit on the pixel’s backscatter time series. The latter two datasets will needed to calculate the probability density functions over land and water for. We will be getting the required data from the EODC STAC Catalog. Specifically the collections: SENTINEL_SIG0_20M, SENTINEL1_MPLIA and SENTINEL1_HPAR. We use the pystac-client and odc_stac packages to, respectively, discover and fetch the data.\nDue to the way the data is acquired and stored, some items include “no data” areas. In our case, no data has the value -9999, but this can vary from data provider to data provider. This information can usually be found in the metadata. Furthermore, to save memory, data is often stored as integer (e.g. 25) and not in float (e.g. 2.5) format. For this reason, the backscatter values are often multiplied by a scale factor. Hence we define the function post_process_eodc_cube to correct for these factors as obtained from the STAC metadata.\n\n3.2.1 Sigma naught\n\neodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\nsearch = eodc_catalog.search(\n    collections=\"SENTINEL1_SIG0_20M\",\n    bbox=bounding_box,\n    datetime=time_range,\n)\nitems_sig0 = search.item_collection()\n\n\ndef post_process_eodc_cube(dc, items, bands):\n    \"\"\"\n    Postprocessing of EODC data cubes.\n\n    Parameters\n    ----------\n    x : xarray.Dataset\n    items: pystac.item_collection.ItemCollection\n        STAC items that concern the Xarray Dataset\n    bands: array\n        Selected bands\n\n    Returns\n    -------\n    xarray.Dataset\n    \"\"\"\n    if not isinstance(bands, tuple):\n        bands = tuple([bands])\n    for i in bands:\n        dc[i] = post_process_eodc_cube_(dc[i], items, i)\n    return dc\n\n\ndef post_process_eodc_cube_(dc, items, band):\n    scale = items[0].assets[band].extra_fields.get(\"raster:bands\")[0][\"scale\"]\n    nodata = items[0].assets[band].extra_fields.get(\"raster:bands\")[0][\"nodata\"]\n    return dc.where(dc != nodata) / scale\n\n\nbands = \"VV\"\nsig0_dc = odc_stac.load(items_sig0, bands=bands, bbox=bounding_box)\nsig0_dc = (\n    post_process_eodc_cube(sig0_dc, items_sig0, bands)\n    .rename_vars({\"VV\": \"sig0\"})\n    .dropna(dim=\"time\", how=\"all\")\n    .median(\"time\")\n)\n\nsig0_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:      (y: 977, x: 1324)\nCoordinates:\n  * y            (y) float64 8kB 6.388e+05 6.388e+05 ... 6.193e+05 6.193e+05\n  * x            (x) float64 11kB 5.658e+06 5.658e+06 ... 5.684e+06 5.684e+06\n    spatial_ref  int32 4B 27704\nData variables:\n    sig0         (y, x) float32 5MB -9.6 -9.2 -8.3 -8.7 ... -12.3 -11.6 -9.7xarray.DatasetDimensions:y: 977x: 1324Coordinates: (3)y(y)float646.388e+05 6.388e+05 ... 6.193e+05units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([638790., 638770., 638750., ..., 619310., 619290., 619270.])x(x)float645.658e+06 5.658e+06 ... 5.684e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5657530., 5657550., 5657570., ..., 5683950., 5683970., 5683990.])spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5657520 20 0 638800 0 -20array(27704, dtype=int32)Data variables: (1)sig0(y, x)float32-9.6 -9.2 -8.3 ... -12.3 -11.6 -9.7array([[ -9.6,  -9.2,  -8.3, ...,  -9.6, -10. ,  -9.9],\n       [ -9. ,  -8.2,  -7.9, ...,  -9.6,  -9.4,  -9.3],\n       [ -7.6,  -6.9,  -6.9, ..., -11.3, -10.3, -10.1],\n       ...,\n       [ -7.6,  -9.2, -10.3, ..., -11.8, -10.5,  -8.7],\n       [ -8.6,  -7.5,  -7.9, ..., -13.3, -11.5,  -9. ],\n       [ -9.3,  -7.4,  -6.2, ..., -12.3, -11.6,  -9.7]], dtype=float32)Indexes: (2)yPandasIndexPandasIndex(Index([638790.0, 638770.0, 638750.0, 638730.0, 638710.0, 638690.0, 638670.0,\n       638650.0, 638630.0, 638610.0,\n       ...\n       619450.0, 619430.0, 619410.0, 619390.0, 619370.0, 619350.0, 619330.0,\n       619310.0, 619290.0, 619270.0],\n      dtype='float64', name='y', length=977))xPandasIndexPandasIndex(Index([5657530.0, 5657550.0, 5657570.0, 5657590.0, 5657610.0, 5657630.0,\n       5657650.0, 5657670.0, 5657690.0, 5657710.0,\n       ...\n       5683810.0, 5683830.0, 5683850.0, 5683870.0, 5683890.0, 5683910.0,\n       5683930.0, 5683950.0, 5683970.0, 5683990.0],\n      dtype='float64', name='x', length=1324))Attributes: (0)\n\n\n\n\n3.2.2 Harmonic Parameters\n\nsearch = eodc_catalog.search(\n    collections=\"SENTINEL1_HPAR\",\n    bbox=bounding_box,\n    query=[\"sat:relative_orbit=80\"],\n)\n\nitems_hpar = search.item_collection()\nbands = (\"C1\", \"C2\", \"C3\", \"M0\", \"S1\", \"S2\", \"S3\", \"STD\")\nhpar_dc = odc_stac.load(\n    items_hpar,\n    bands=bands,\n    bbox=bounding_box,\n    groupby=None,\n)\nhpar_dc = post_process_eodc_cube(hpar_dc, items_hpar, bands).median(\"time\")\nhpar_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 41MB\nDimensions:      (y: 977, x: 1324)\nCoordinates:\n  * y            (y) float64 8kB 6.388e+05 6.388e+05 ... 6.193e+05 6.193e+05\n  * x            (x) float64 11kB 5.658e+06 5.658e+06 ... 5.684e+06 5.684e+06\n    spatial_ref  int32 4B 27704\nData variables:\n    C1           (y, x) float32 5MB -0.1 -0.1 0.0 0.1 0.3 ... 1.2 1.6 1.8 1.4\n    C2           (y, x) float32 5MB -0.1 -0.2 -0.2 0.0 -0.1 ... 0.2 0.2 0.6 0.6\n    C3           (y, x) float32 5MB 0.2 0.1 0.0 0.0 0.1 ... -0.4 -0.6 -0.5 -0.6\n    M0           (y, x) float32 5MB -9.0 -9.7 -10.0 -9.7 ... -11.8 -11.3 -11.5\n    S1           (y, x) float32 5MB -0.3 -0.2 -0.2 -0.1 ... -0.3 -0.2 -0.7 -1.1\n    S2           (y, x) float32 5MB -0.2 0.0 0.0 -0.2 ... -0.2 -0.3 -0.4 -0.2\n    S3           (y, x) float32 5MB -0.1 0.0 0.0 -0.1 -0.1 ... 0.0 0.1 0.1 0.4\n    STD          (y, x) float32 5MB 1.3 1.2 1.1 1.0 1.2 ... 1.9 1.9 1.8 1.8 1.9xarray.DatasetDimensions:y: 977x: 1324Coordinates: (3)y(y)float646.388e+05 6.388e+05 ... 6.193e+05units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([638790., 638770., 638750., ..., 619310., 619290., 619270.])x(x)float645.658e+06 5.658e+06 ... 5.684e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5657530., 5657550., 5657570., ..., 5683950., 5683970., 5683990.])spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5657520 20 0 638800 0 -20array(27704, dtype=int32)Data variables: (8)C1(y, x)float32-0.1 -0.1 0.0 0.1 ... 1.6 1.8 1.4array([[-0.1, -0.1,  0. , ..., -0.4, -0.2, -0.5],\n       [ 0.1,  0.2,  0.3, ..., -0.5, -0.2, -0.5],\n       [ 0.6,  0.7,  0.7, ..., -0.6, -0.5, -0.5],\n       ...,\n       [ 0.6,  1.1,  1.2, ...,  1.2,  1.3,  1.3],\n       [ 1. ,  1.2,  1.4, ...,  1.1,  1.4,  1.4],\n       [ 1.4,  1.6,  1.8, ...,  1.6,  1.8,  1.4]], dtype=float32)C2(y, x)float32-0.1 -0.2 -0.2 0.0 ... 0.2 0.6 0.6array([[-0.1, -0.2, -0.2, ..., -0.1, -0.2, -0.2],\n       [ 0. , -0.1,  0. , ..., -0.1, -0.2, -0.2],\n       [ 0.3,  0.3,  0.2, ...,  0. ,  0. , -0.1],\n       ...,\n       [ 0.4,  0.5,  0.5, ...,  0.6,  0.6,  0.6],\n       [ 0.5,  0.5,  0.6, ...,  0.3,  0.5,  0.6],\n       [ 0.5,  0.3,  0.4, ...,  0.2,  0.6,  0.6]], dtype=float32)C3(y, x)float320.2 0.1 0.0 0.0 ... -0.6 -0.5 -0.6array([[ 0.2,  0.1,  0. , ...,  0.2,  0.3,  0.3],\n       [ 0. ,  0. ,  0. , ...,  0.1,  0.2,  0.2],\n       [-0.2,  0. ,  0.1, ...,  0.1,  0. ,  0. ],\n       ...,\n       [-0.2, -0.3, -0.2, ..., -0.4, -0.3, -0.1],\n       [-0.3, -0.4, -0.3, ..., -0.3, -0.3, -0.2],\n       [-0.4, -0.5, -0.4, ..., -0.6, -0.5, -0.6]], dtype=float32)M0(y, x)float32-9.0 -9.7 -10.0 ... -11.3 -11.5array([[ -9. ,  -9.7, -10. , ...,  -8.9,  -9. ,  -8.9],\n       [ -8.6,  -9.4,  -9.9, ...,  -9. ,  -9.2,  -9.6],\n       [ -7.8,  -7.7,  -8.4, ..., -10.7, -10.1, -10.6],\n       ...,\n       [ -9. ,  -9.5,  -9.7, ..., -12.5, -12.4, -12.1],\n       [ -9.6,  -9.7,  -9.6, ..., -12.2, -11.9, -11.9],\n       [ -9.5,  -9.5,  -9.5, ..., -11.8, -11.3, -11.5]], dtype=float32)S1(y, x)float32-0.3 -0.2 -0.2 ... -0.2 -0.7 -1.1array([[-0.3, -0.2, -0.2, ...,  0. ,  0. , -0.4],\n       [-0.2, -0.3, -0.4, ...,  0. ,  0. , -0.3],\n       [ 0.1, -0.2, -0.3, ...,  0. , -0.1, -0.1],\n       ...,\n       [-1.4, -1.5, -1.1, ..., -0.6, -0.4, -0.6],\n       [-1.7, -1.9, -1.7, ..., -0.1, -0.4, -0.8],\n       [-1.6, -1.7, -1.7, ..., -0.2, -0.7, -1.1]], dtype=float32)S2(y, x)float32-0.2 0.0 0.0 ... -0.3 -0.4 -0.2array([[-0.2,  0. ,  0. , ...,  0.4,  0.3,  0.1],\n       [-0.1,  0. ,  0. , ...,  0.5,  0.3,  0.1],\n       [-0.1,  0. ,  0. , ...,  0.5,  0.6,  0.2],\n       ...,\n       [ 0.7,  0.5,  0.3, ..., -0.6, -0.5, -0.3],\n       [ 0.2,  0.4,  0.3, ..., -0.2, -0.5, -0.4],\n       [ 0. ,  0.2,  0.4, ..., -0.3, -0.4, -0.2]], dtype=float32)S3(y, x)float32-0.1 0.0 0.0 -0.1 ... 0.1 0.1 0.4array([[-0.1,  0. ,  0. , ..., -0.1, -0.1,  0. ],\n       [-0.2, -0.1,  0. , ..., -0.1,  0. ,  0. ],\n       [ 0. ,  0. ,  0. , ...,  0.1,  0. ,  0. ],\n       ...,\n       [-0.8, -0.7, -0.5, ...,  0. ,  0. ,  0. ],\n       [-0.4, -0.4, -0.4, ...,  0.2,  0.1,  0.3],\n       [-0.3, -0.4, -0.3, ...,  0.1,  0.1,  0.4]], dtype=float32)STD(y, x)float321.3 1.2 1.1 1.0 ... 1.9 1.8 1.8 1.9array([[1.3, 1.2, 1.1, ..., 1.2, 1. , 1.1],\n       [1.3, 1.2, 1.2, ..., 0.9, 0.9, 1. ],\n       [1.3, 1.3, 1.2, ..., 0.9, 0.9, 1. ],\n       ...,\n       [2.2, 2.2, 1.7, ..., 1.9, 1.8, 1.8],\n       [2.5, 2.4, 2.1, ..., 1.8, 1.8, 1.9],\n       [2.5, 2.5, 2.3, ..., 1.8, 1.8, 1.9]], dtype=float32)Indexes: (2)yPandasIndexPandasIndex(Index([638790.0, 638770.0, 638750.0, 638730.0, 638710.0, 638690.0, 638670.0,\n       638650.0, 638630.0, 638610.0,\n       ...\n       619450.0, 619430.0, 619410.0, 619390.0, 619370.0, 619350.0, 619330.0,\n       619310.0, 619290.0, 619270.0],\n      dtype='float64', name='y', length=977))xPandasIndexPandasIndex(Index([5657530.0, 5657550.0, 5657570.0, 5657590.0, 5657610.0, 5657630.0,\n       5657650.0, 5657670.0, 5657690.0, 5657710.0,\n       ...\n       5683810.0, 5683830.0, 5683850.0, 5683870.0, 5683890.0, 5683910.0,\n       5683930.0, 5683950.0, 5683970.0, 5683990.0],\n      dtype='float64', name='x', length=1324))Attributes: (0)\n\n\n\n\n3.2.3 Projected Local Incidence Angles\n\nsearch = eodc_catalog.search(\n    collections=\"SENTINEL1_MPLIA\",\n    bbox=bounding_box,\n    query=[\"sat:relative_orbit=80\"],\n)\n\nitems_plia = search.item_collection()\n\nbands = \"MPLIA\"\nplia_dc = odc_stac.load(\n    items_plia,\n    bands=bands,\n    bbox=bounding_box,\n)\n\nplia_dc = post_process_eodc_cube(plia_dc, items_plia, bands).median(\"time\")\nplia_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:      (y: 977, x: 1324)\nCoordinates:\n  * y            (y) float64 8kB 6.388e+05 6.388e+05 ... 6.193e+05 6.193e+05\n  * x            (x) float64 11kB 5.658e+06 5.658e+06 ... 5.684e+06 5.684e+06\n    spatial_ref  int32 4B 27704\nData variables:\n    MPLIA        (y, x) float32 5MB 27.32 29.22 32.16 ... 33.79 34.02 34.27xarray.DatasetDimensions:y: 977x: 1324Coordinates: (3)y(y)float646.388e+05 6.388e+05 ... 6.193e+05units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([638790., 638770., 638750., ..., 619310., 619290., 619270.])x(x)float645.658e+06 5.658e+06 ... 5.684e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5657530., 5657550., 5657570., ..., 5683950., 5683970., 5683990.])spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5657520 20 0 638800 0 -20array(27704, dtype=int32)Data variables: (1)MPLIA(y, x)float3227.32 29.22 32.16 ... 34.02 34.27array([[27.32, 29.22, 32.16, ..., 38.68, 37.31, 36.56],\n       [21.78, 24.62, 29.13, ..., 39.57, 38.85, 38.75],\n       [17.  , 20.55, 26.17, ..., 40.32, 40.23, 40.57],\n       ...,\n       [35.4 , 35.38, 35.39, ..., 33.86, 34.16, 34.63],\n       [35.41, 35.41, 35.41, ..., 33.77, 34.17, 34.65],\n       [35.41, 35.41, 35.41, ..., 33.79, 34.02, 34.27]], dtype=float32)Indexes: (2)yPandasIndexPandasIndex(Index([638790.0, 638770.0, 638750.0, 638730.0, 638710.0, 638690.0, 638670.0,\n       638650.0, 638630.0, 638610.0,\n       ...\n       619450.0, 619430.0, 619410.0, 619390.0, 619370.0, 619350.0, 619330.0,\n       619310.0, 619290.0, 619270.0],\n      dtype='float64', name='y', length=977))xPandasIndexPandasIndex(Index([5657530.0, 5657550.0, 5657570.0, 5657590.0, 5657610.0, 5657630.0,\n       5657650.0, 5657670.0, 5657690.0, 5657710.0,\n       ...\n       5683810.0, 5683830.0, 5683850.0, 5683870.0, 5683890.0, 5683910.0,\n       5683930.0, 5683950.0, 5683970.0, 5683990.0],\n      dtype='float64', name='x', length=1324))Attributes: (0)\n\n\nFinally, we merged the datasets as one big dataset and reproject the data in EPSG 4326 for easier visualizing of the data.\n\nflood_dc = xr.merge([sig0_dc, plia_dc, hpar_dc])\nflood_dc = flood_dc.rio.reproject(\"EPSG:4326\").rio.write_crs(\"EPSG:4326\")\nflood_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 49MB\nDimensions:      (x: 1443, y: 846)\nCoordinates:\n  * x            (x) float64 12kB 21.92 21.92 21.92 21.93 ... 22.23 22.23 22.23\n  * y            (y) float64 7kB 39.65 39.65 39.65 39.65 ... 39.46 39.46 39.46\n    spatial_ref  int64 8B 0\nData variables:\n    sig0         (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    MPLIA        (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    C1           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    C2           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    C3           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    M0           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    S1           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    S2           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    S3           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    STD          (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nanxarray.DatasetDimensions:x: 1443y: 846Coordinates: (3)x(x)float6421.92 21.92 21.92 ... 22.23 22.23axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([21.924527, 21.924742, 21.924957, ..., 22.234298, 22.234513, 22.234728])y(y)float6439.65 39.65 39.65 ... 39.46 39.46axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([39.645899, 39.645684, 39.645469, ..., 39.464554, 39.464339, 39.464124])spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :21.92441968968017 0.0002151185728747185 0.0 39.64600661223929 0.0 -0.0002151185728747185array(0)Data variables: (10)sig0(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)MPLIA(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)C1(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)C2(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)C3(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)M0(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)S1(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)S2(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)S3(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)STD(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)Indexes: (2)xPandasIndexPandasIndex(Index([ 21.92452724896661, 21.924742367539483,  21.92495748611236,\n       21.925172604685233,  21.92538772325811, 21.925602841830983,\n       21.925817960403858, 21.926033078976733, 21.926248197549608,\n        21.92646331612248,\n       ...\n        22.23279216389608, 22.233007282468954,  22.23322240104183,\n       22.233437519614704,  22.23365263818758, 22.233867756760453,\n        22.23408287533333, 22.234297993906203,  22.23451311247908,\n       22.234728231051953],\n      dtype='float64', name='x', length=1443))yPandasIndexPandasIndex(Index([39.645899052952856,  39.64568393437998,  39.64546881580711,\n        39.64525369723423,  39.64503857866136,  39.64482346008848,\n        39.64460834151561,  39.64439322294273,  39.64417810436986,\n        39.64396298579698,\n       ...\n       39.466059926029594,  39.46584480745672, 39.465629688883844,\n        39.46541457031097, 39.465199451738094,  39.46498433316522,\n       39.464769214592344,  39.46455409601947, 39.464338977446594,\n        39.46412385887372],\n      dtype='float64', name='y', length=846))Attributes: (0)",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html#from-backscattering-to-flood-mapping",
    "href": "chapters/Floodmapping.html#from-backscattering-to-flood-mapping",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "3.3 From Backscattering to Flood Mapping",
    "text": "3.3 From Backscattering to Flood Mapping\nIn the following lines we create a map with microwave backscattering values.\n\nmrs_view = flood_dc.sig0.hvplot.image(\n    x=\"x\", y=\"y\", cmap=\"viridis\", geo=True, tiles=True\n).opts(frame_height=400)\nmrs_view\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Area targeted for \\(\\sigma^0\\) backscattering is the Greek region of Thessaly, which experienced a major flood in February of 2018.\n\n\n\n\n\nFigure 3.1",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html#microwave-backscattering-over-land-and-water",
    "href": "chapters/Floodmapping.html#microwave-backscattering-over-land-and-water",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "3.4 Microwave Backscattering over Land and Water",
    "text": "3.4 Microwave Backscattering over Land and Water\nReverend Bayes was concerned with two events, one (the hypothesis) occurring before the other (the evidence). If we know its cause, it is easy to logically deduce the probability of an effect. However, in this case we want to deduce the probability of a cause from an observed effect, also known as “reversed probability”. In the case of flood mapping, we have \\(\\sigma^0\\) backscatter observations over land (the effect) and we want to deduce the probability of flooding (\\(F\\)) and non-flooding (\\(NF\\)).\nIn other words, we want to know the probability of flooding \\(P(F)\\) given a pixel’s \\(\\sigma^0\\):\n\\[P(F|\\sigma^0)\\]\nand the probability of a pixel being not flooded \\(P(NF)\\) given a certain \\(\\sigma^0\\):\n\\[P(NF|\\sigma^0).\\]\nBayes showed that these can be deduced from the observation that forward and reversed probability are equal, so that:\n\\[P(F|\\sigma^0)P(\\sigma^0) = P(\\sigma^0|F)P(F)\\]\nand\n\\[P(NF|\\sigma^0)P(\\sigma^0) = P(\\sigma^0|NF)P(NF).\\]\nThe forward probability of \\(\\sigma^0\\) given the occurrence of flooding (\\(P(\\sigma^0|F)\\)) and \\(\\sigma^0\\) given no flooding (\\(P(\\sigma^0|NF)\\)) can be extracted from past information on backscattering over land and water surfaces. As seen in the sketch below (Figure 3.2), the characteristics of backscattering over land and water differ considerably.\n\n\n\n\n\n\nFigure 3.2: Schematic backscattering over land and water. Image from Geological Survey Ireland",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html#likelihoods",
    "href": "chapters/Floodmapping.html#likelihoods",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "3.5 Likelihoods",
    "text": "3.5 Likelihoods\nThe so-called likelihoods of \\(P(\\sigma^0|F)\\) and \\(P(\\sigma^0|NF)\\) can thus be calculated from past backscattering information. In the following code chunk we define the functions calc_water_likelihood and calc_land_likelihood to calculate the water and land likelihood’s of a pixel, based on the Xarray datasets for the PLIA and HPAR, respectively.\n\ndef calc_water_likelihood(sigma, x=None, y=None):\n    \"\"\"\n    Calculate water likelihoods.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    numpy array\n    \"\"\"\n    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n    wbsc_mean = point.MPLIA * -0.394181 + -4.142015\n    wbsc_std = 2.754041\n    return norm.pdf(sigma, wbsc_mean.to_numpy(), wbsc_std)\n\n\ndef expected_land_backscatter(data, dtime_str):\n    w = np.pi * 2 / 365\n    dt = datetime.datetime.strptime(dtime_str, \"%Y-%m-%d\")\n    t = dt.timetuple().tm_yday\n    wt = w * t\n\n    M0 = data.M0\n    S1 = data.S1\n    S2 = data.S2\n    S3 = data.S3\n    C1 = data.C1\n    C2 = data.C2\n    C3 = data.C3\n    hm_c1 = (M0 + S1 * np.sin(wt)) + (C1 * np.cos(wt))\n    hm_c2 = (hm_c1 + S2 * np.sin(2 * wt)) + C2 * np.cos(2 * wt)\n    hm_c3 = (hm_c2 + S3 * np.sin(3 * wt)) + C3 * np.cos(3 * wt)\n    return hm_c3\n\n\ndef calc_land_likelihood(sigma, x=None, y=None):\n    \"\"\"\n    Calculate land likelihoods.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    numpy array\n    \"\"\"\n    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n    lbsc_mean = expected_land_backscatter(point, \"2018-02-01\")\n    lbsc_std = point.STD\n    return norm.pdf(sigma, lbsc_mean.to_numpy(), lbsc_std.to_numpy())\n\nWithout going into the details of how these likelihoods are calculated, you can hover over a pixel of the map to plot the likelihoods of \\(\\sigma^0\\) being governed by land or water. For reference we model the water and land likelihoods (model_likelihoods) over a range of \\(\\sigma^0\\) values.\n\ndef model_likelihoods(sigma=(-30, 0), x=None, y=None):\n    \"\"\"\n    Model likelihoods over a range of sigma naught.\n\n    Parameters\n    ----------\n    sigma: tuple\n        Minimum and maximum for range of sigma naught values\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Pandas Datafrane\n    \"\"\"\n    sigma = np.arange(sigma[0], sigma[1], 0.1)\n    land_likelihood = calc_land_likelihood(sigma=sigma, x=x, y=y)\n    water_likelihood = calc_water_likelihood(sigma=sigma, x=x, y=y)\n    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n    return pd.DataFrame(\n        {\n            \"sigma\": sigma,\n            \"water_likelihood\": water_likelihood,\n            \"land_likelihood\": land_likelihood,\n            \"observed\": np.repeat(point.sig0.values, len(land_likelihood)),\n        }\n    )\n\n\npointer = hv.streams.PointerXY(source=mrs_view.get(1), x=22.1, y=39.5)\n\nlikelihood_pdi = hvplot.bind(\n    model_likelihoods, x=pointer.param.x, y=pointer.param.y\n).interactive()\n\nview_likelihoods = (\n    likelihood_pdi.hvplot(\"sigma\", \"water_likelihood\", ylabel=\"likelihoods\").dmap()\n    * likelihood_pdi.hvplot(\"sigma\", \"land_likelihood\").dmap()\n    * likelihood_pdi.hvplot(\"observed\", \"land_likelihood\").dmap()\n).opts(frame_height=200, frame_width=300)\n\nview_likelihoods + mrs_view.get(1)\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Likelihoods for \\(\\sigma^0\\) being associated with land or water for 1 pixel in the Greek area of Thessaly. Likelihoods are calculated over a range of \\(\\sigma^0\\). The pixel’s observed \\(\\sigma^0\\) is given with a vertical line. Hover on the map to re-calculate and update this figure for another pixel in the study area.\n\n\n\n\n\nFigure 3.3",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html#posteriors",
    "href": "chapters/Floodmapping.html#posteriors",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "3.6 Posteriors",
    "text": "3.6 Posteriors\nHaving calculated the likelihoods, we can now move on to calculate the probability of (non-)flooding given a pixel’s \\(\\sigma^0\\). These so-called posteriors need one more piece of information, as can be seen in the equation above. We need the probability that a pixel is flooded \\(P(F)\\) or not flooded \\(P(NF)\\). Of course, these are the figures we’ve been trying to find this whole time. We don’t actually have them yet, so what can we do? In Bayesian statistics, we can just start with our best guess. These guesses are called our “priors”, because they are the beliefs we hold prior to looking at the data. This subjective prior belief is the foundation Bayesian statistics, and we use the likelihoods we just calculated to update our belief in this particular hypothesis. This updated belief is called the “posterior”.\nLet’s say that our best estimate for the chance of flooding versus non-flooding of a pixel is 50-50: a coin flip. We now can also calculate the probability of backscattering \\(P(\\sigma^0)\\), as the weighted average of the water and land likelihoods, ensuring that our posteriors range between 0 to 1.\nThe following code block shows how we calculate the priors.\n\ndef calc_posteriors(sigma, x=None, y=None):\n    \"\"\"\n    Calculate posterior probability.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Tuple of two Numpy arrays\n    \"\"\"\n    land_likelihood = calc_land_likelihood(sigma=sigma, x=x, y=y)\n    water_likelihood = calc_water_likelihood(sigma=sigma, x=x, y=y)\n    evidence = (water_likelihood * 0.5) + (land_likelihood * 0.5)\n    return (water_likelihood * 0.5) / evidence, (land_likelihood * 0.5) / evidence\n\nWe can plot the posterior probabilities of flooding and non-flooding again and compare these to pixel’s measured \\(\\sigma^0\\). For reference we model the flood and non-flood posteriors (model_posteriors) over a range of \\(\\sigma^0\\) values. Hover on a pixel to calculate the posterior probability.\n\ndef model_posteriors(sigma=(-30, 0), x=None, y=None):\n    \"\"\"\n    Model posterior probabilities over a range of sigma naught.\n\n    Parameters\n    ----------\n    sigma: tuple\n        Minimum and maximum for range of sigma naught values\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Pandas Datafrane\n    \"\"\"\n    bays_pd = model_likelihoods(sigma=sigma, x=x, y=y)\n    sigma = np.arange(sigma[0], sigma[1], 0.1)\n    bays_pd[\"f_post_prob\"], bays_pd[\"nf_post_prob\"] = calc_posteriors(\n        sigma=sigma, x=x, y=y\n    )\n    return bays_pd\n\n\nposterior_pdi = hvplot.bind(\n    model_posteriors, x=pointer.param.x, y=pointer.param.y\n).interactive()\n\nview_posteriors = (\n    posterior_pdi.hvplot(\"sigma\", \"f_post_prob\", ylabel=\"posteriors\").dmap()\n    * posterior_pdi.hvplot(\"sigma\", \"nf_post_prob\").dmap()\n    * posterior_pdi.hvplot(\"observed\", \"nf_post_prob\").dmap()\n).opts(frame_height=200, frame_width=300)\n\n(view_likelihoods + view_posteriors).cols(1) + mrs_view.get(1)\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Posterior probabilities for \\(\\sigma^0\\) of 1 pixel being associated with land for water in the Greek area of Thessaly. Hover on the map to re-calculate and update this figure for another pixel in the study area.\n\n\n\n\n\nFigure 3.4",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/Floodmapping.html#flood-classification",
    "href": "chapters/Floodmapping.html#flood-classification",
    "title": "3  Reverend Bayes updates our Belief in Flood Detection",
    "section": "3.7 Flood Classification",
    "text": "3.7 Flood Classification\nWe are now ready to combine all this information and classify the pixels according to the probability of flooding given the backscatter value of each pixel. Here we just look whether the probability of flooding is higher than non-flooding:\n\ndef bayesian_flood_decision(sigma, x=None, y=None):\n    \"\"\"\n    Bayesian decision.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Xarray DataArray\n    \"\"\"\n    f_post_prob, nf_post_prob = calc_posteriors(sigma=sigma, x=x, y=y)\n    return xr.where(\n        np.isnan(f_post_prob) | np.isnan(nf_post_prob),\n        np.nan,\n        np.greater(f_post_prob, nf_post_prob),\n    )\n\nHover on a point in the below map to see the likelihoods and posterior distributions (in the left-hand subplots).\n\nflood_dc[\"decision\"] = (\n    (\"y\", \"x\"),\n    bayesian_flood_decision(flood_dc.sig0, flood_dc.x, flood_dc.y),\n)\n\ncolorbar_opts = {\n    \"major_label_overrides\": {\n        0: \"non-flood\",\n        1: \"flood\",\n    },\n    \"ticker\": FixedTicker(ticks=[0, 1]),\n}\nflood_view = flood_dc.decision.hvplot.image(\n    x=\"x\", y=\"y\", rasterize=True, geo=True, cmap=[\"rgba(0, 0, 1, 0.1)\", \"darkred\"]\n).opts(frame_height=400, colorbar_opts={**colorbar_opts})\nmrs_view.get(0) * flood_view\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Flood extent of the Greek region of Thessaly based on Bayesian probabilities are shown on the map superimposed on an open street map. Hover over a pixel to generate the point’s water and land likelihoods as well as the posterior probabilities.\n\n\n\n\n\nFigure 3.5\n\n\n\n\n\n\n\n\nBauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian Roth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang Wagner. 2022. “Satellite-Based Flood Mapping Through Bayesian Inference from a Sentinel-1 SAR Datacube.” Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.",
    "crumbs": [
      "Lessons",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "References",
    "section": "",
    "text": "Bauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian\nRoth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang\nWagner. 2022. “Satellite-Based Flood\nMapping Through Bayesian\nInference from a Sentinel-1 SAR\nDatacube.” Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.\n\n\nNASA. 2020. “Earth Observatory.” 2020. https://earthobservatory.nasa.gov/features/MeasuringVegetation/measuring_vegetation_2.php.\n\n\nRouse, John Wilson, Rüdiger H Haas, John A Schell, Donald W Deering, et\nal. 1974. “Monitoring Vegetation Systems in the Great Plains with\nERTS.” NASA Spec. Publ 351 (1): 309.",
    "crumbs": [
      "References"
    ]
  }
]