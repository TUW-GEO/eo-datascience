[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Earth Observation Datascience",
    "section": "",
    "text": "Preface\nThis is a collection of Jupyter notebooks showcasing earth observation (EO) data products and common workflows for handling the data. It is a demonstration of the shared capabilities of the EODC/TU Wien digital learning environment.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing.html",
    "href": "chapters/courses/microwave-remote-sensing.html",
    "title": "Microwave Remote Sensing",
    "section": "",
    "text": "This course at the TU Wien teaches students to read, visualize and analyze Synthetic Aperture Radar (SAR) data. This will aid interpretation of SAR data based upon a physical understanding of sensing principles and the interaction of microwaves with natural objects.\n\n\n\nConcepts\nImportance\nNotes\n\n\n\n\nIntro to xarray\nNecessary\n\n\n\nDask Arrays\nNecessary\n\n\n\nIntake\nHelpful\n\n\n\nMatplotlib\nHelpful\nPloting in Python\n\n\nDocumentation hvPlot\nHelpful\nInteractive plotting\n\n\nDocumentation odc-stac\nHelpful\nData access\n\n\n\n\nTime to learn: 90 min\n\n\n\n\n\n\n\nNote\n\n\n\nThese notebooks contain interactive elements. The full interactive elements can only be viewed on Binder by clicking on the Binder badge or ðŸš€ button.",
    "crumbs": [
      "Microwave Remote Sensing"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/01_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/01_in_class_exercise.html",
    "title": "1Â  Discover and Read SAR Data",
    "section": "",
    "text": "1.1 Data Discovery\nThis notebook demonstrates how to access radar data in a SpatioTemporal Asset Catalog (STAC) Catalogue using the pystac library. In this example, we use Sentinel-1 data from the EODC (earth observation data and high performance computing service provider based in Vienna) STAC catalog. In the further process, we will learn how to query a STAC catalog, select specific items, and display the metadata and the actual image.\neodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n\neodc_catalog\n\n\n\n\n\n\n    &lt;Client id=stac-fastapi&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Catalog\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"stac-fastapi\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"A STAC-compliant API to query for metadata within the EODC Data Catalogue.\"\n        \n    \n                \n            \n                \n                    \n        links[] 9 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Root\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"data\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Collections available for this Catalog\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"conformance\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/conformance\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC/OGC conformance classes implemented by this server\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search [GET]\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"search\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/search\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"STAC search [POST]\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"POST\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables available for this Catalog\"\n        \n    \n            \n        \n            \n                \n        \n            method\n            \"GET\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \n        \n            \n                \n        \n            rel\n            \"service-desc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/openapi.json\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/vnd.oai.openapi+json;version=3.0\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service description\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \n        \n            \n                \n        \n            rel\n            \"service-doc\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/docs\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"text/html\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"OpenAPI service documentation\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        conformsTo[] 28 items\n        \n            \n        \n            \n                \n        \n            0\n            \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"http://www.opengis.net/spec/ogcapi-common-2/1.0/conf/simple-query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/geojson\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            6\n            \"http://www.opengis.net/spec/ogcapi-features-1/1.0/conf/oas30\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            7\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/features-filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            8\n            \"http://www.opengis.net/spec/ogcapi-features-3/1.0/conf/filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            9\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            10\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            11\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            12\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#free-text\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            13\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            14\n            \"https://api.stacspec.org/v1.0.0-rc.1/collection-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            15\n            \"https://api.stacspec.org/v1.0.0-rc.2/item-search#filter\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            16\n            \"https://api.stacspec.org/v1.0.0/collections\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            17\n            \"https://api.stacspec.org/v1.0.0/collections/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            18\n            \"https://api.stacspec.org/v1.0.0/core\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            19\n            \"https://api.stacspec.org/v1.0.0/item-search\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            20\n            \"https://api.stacspec.org/v1.0.0/item-search#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            21\n            \"https://api.stacspec.org/v1.0.0/item-search#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            22\n            \"https://api.stacspec.org/v1.0.0/item-search#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            23\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            24\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#fields\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            25\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#query\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            26\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            27\n            \"https://api.stacspec.org/v1.0.0/ogcapi-features/extensions/transaction\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"EODC Data Catalogue\"\nThe URL https://stac.eodc.eu/api/v1, served over Hypertext Transfer Protocol (HTTP), is a STAC-compliant API endpoint (specific URL address where an API service is available) that leads to the EODC Catalogue. Besides EODCâ€™s, other catalogues can be found on STAC Index, such as United States Geological Survey (USGS) Landsat imagery, Sentinel Hub, Copernicus Data Space Ecosystem, and so on. Briefly spoken, STAC can be used to search, discover, and access metadata of these datasets with the same code. The EODC Catalogue can be accessed on the web via this link as well.\nEach STAC catalog, composed by different providers, has many collections. To get all collections of a catalog, we can print all of them and their ids, which are used to fetch them from the catalog.\ncollections = eodc_catalog.get_collections()\n\n# length of string of collection.id, for pretty print\nmax_length = max(len(collection.id) for collection in collections)\n\nfor collection in eodc_catalog.get_collections():\n    print(f\"{collection.id.ljust(max_length)}: {collection.title}\")\n\nAI4SAR_SIG0                      : AI4SAR Despeckled Sentinel-1 Sigma0 (20m)\nASA_IMP_1P                       : Envisat ASAR Image Mode Precision Level-1\nASA_IMS_1P                       : Envisat ASAR Image Mode Single Look Complex Level-1\nAUSTRIA_GROUND_MOTION            : Austria Ground Motion\nAUT_DEM                          : Austrian High Resolution DEM\nBOA_LANDSAT_8                    : Bottom of Atmosphere Landsat-8 at 30m resolution.\nBOA_SENTINEL_2                   : Bottom of Atmosphere Sentinel-2 at 10m resolution.\nCGLS_SSM_1KM                     : Copernicus Global Land Surface Soil Moisture\nCOP_DEM                          : Copernicus Digital Elevation Model (DEM)\nCORINE_LAND_COVER                : Corine Land Cover\nDOP_AUT_K_KLAGENFURT             : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Klagenfurt\nDOP_AUT_K_OSTTIROL               : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Osttirol\nDOP_AUT_K_TAMSWEG                : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Tamsweg\nDOP_AUT_K_VILLACH                : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Villach\nDOP_AUT_K_WOLFSBERG              : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Wolfsberg\nDOP_AUT_K_ZELL_AM_SEE            : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Zell am See\nDOP_AUT_K_ZELTWEG                : Digital Orthophotos (DOP) Austria - Land KÃ¤rnten: Orthofotos Flugblock Zeltweg\nDOP_AUT_ST_BISCHOFSHOFEN         : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Bischofshofen\nDOP_AUT_ST_GRAZ                  : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Graz\nDOP_AUT_ST_KLAGENFURT            : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Klagenfurt\nDOP_AUT_ST_MARIAZELL             : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Mariazell\nDOP_AUT_ST_MURTAL                : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Murtal\nDOP_AUT_ST_SUEDBURGENLAND        : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Suedburgenland\nDOP_AUT_ST_VILLACH               : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Villach\nDOP_AUT_ST_WINDISCHGARSTEN       : Digital Orthophotos (DOP) Austria - Land Steiermark: Orthophotos Flugblock Windischgarsten\nDROUGHT_VULNERABILITY            : Drought Vulnerability\nDSM_AUT                          : Austrian Digital Surface Model\nERS_ENVISAT_NRB                  : ERS-1/2 SAR and ENVISAT ASAR ARD Normalized Radar Backscatter (NRB)\nGFM                              : Global Flood Monitoring\nincal-hourly                     : INCA analysis hourly data (1km)\nINTRA_FIELD_CROP_GROWTH_POTENTIAL: Intra-field Crop Growth Potential\nRUCIO_SENTINEL2_MFCOVER          : Monthly Composite of Fraction of Vegetation Cover\nSAR_IMP_1P                       : ERS-1/2 SAR Image Mode Precision Level-1\nSAR_IMS_1P                       : ERS-1/2 SAR Image Mode Single Look Complex Level-1\nSENTINEL1_ALPS_WETSNOW           : Sentinel-1 Alps WetSnow\nSENTINEL1_GMR0                   : SENTINEL1 Radiometric Terrain Corrected Gamma Nought\nSENTINEL1_GRD                    : Sentinel-1 SAR L1 GRD\nSENTINEL1_GRD_COVERAGE           : Sentinel-1 Coverage Maps\nSENTINEL1_HPAR                   : SENTINEL1 Harmonic Parameters\nSentinel-1_Lacken_Extent         : SENTINEL-1 Lacken Extent\nSENTINEL1_MPLIA                  : SENTINEL1 Mean PLIA\nSentinel-1_Reed_Extent           : SENTINEL-1 Reed Extent\nSENTINEL1_SIG0_20M               : SENTINEL1 Sigma Nought (SIG0) Backscatter in 20 meter resolution\nSENTINEL1_SLC                    : Sentinel-1 SLC\nSentinel-2-Greenness-Austria     : Sentinel-2 Greenness Austria\nSENTINEL2_GRI_L1C                : Multi-Layer Copernicus Sentinel-2 GRI in L1C\nSENTINEL2_L1C                    : Sentinel-2 MSI Products: Level-1C data\nSENTINEL2_L1C_COVERAGE           : Sentinel-2 L1C Coverage Maps\nSENTINEL2_L2A                    : Sentinel-2 MSI Products: Level-2A data\nsentinel2-landsat8-l2f           : Harmonized Landsat and Sentinel 2 L2F\nSENTINEL2_MFCOVER                : Monthly Composite of Fraction of Vegetation Cover\nSENTINEL3_SRAL_L2                : Sentinel-3 Products: SRAL Level-2 data\nspartacus-daily                  : Spartacus Analysis Daily (1 km)\nSSM-RT0-SIG0-R-EXTR              : SSM-RT0-SIG0-R-EXTR\ntopo-dc-austria                  : Topographic datacube Austria\nVEGETATION_CHANGE_AUSTRIA        : Vegetation-Change-Austria\nTo get a specific collection from the catalog, we can use the client.get_collection() method and provide the collection name. We can then display its description, id, temporal and spatial extent, license, etc. In this notebook, we will work with the Sentinel-1 sigma naught 20m collection.\ncolllection_id = \"SENTINEL1_SIG0_20M\"\n\ncollection = eodc_catalog.get_collection(colllection_id)\ncollection\n\n\n\n\n\n\n    &lt;CollectionClient id=SENTINEL1_SIG0_20M&gt;\n\n\n    \n        \n            \n                \n                    \n        \n            type\n            \"Collection\"\n        \n    \n                \n            \n                \n                    \n        \n            id\n            \"SENTINEL1_SIG0_20M\"\n        \n    \n                \n            \n                \n                    \n        \n            stac_version\n            \"1.1.0\"\n        \n    \n                \n            \n                \n                    \n        \n            description\n            \"Sentinel-1 Sigma Nought (SIG0) Products are radiometric calibrated and georeferenced backscatter data generated from Sentinel-1 level-1 Interferometric Wide (IW) Swath Ground Range Detected (GRD) High resolution products using TUWien Sentinel-1 preprocesssing workflow. The preprocessing workflow includes following steps: applying precise orbit file, radiometric calibration, thermal noise removal, and range doppler terrain correction. In the end, Sigma0 backscatter image is reprojected and resampled into Equi7 Grid system at 20m pixels spacing.\"\n        \n    \n                \n            \n                \n                    \n        links[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections/SENTINEL1_SIG0_20M/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            rel\n            \"parent\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            rel\n            \"root\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"EODC Data Catalogue\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            rel\n            \"self\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections/SENTINEL1_SIG0_20M\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \n        \n            \n                \n        \n            rel\n            \"items\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/ingestion/v1/collections/SENTINEL1_SIG0_20M/items\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/geo+json\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \n        \n            \n                \n        \n            rel\n            \"http://www.opengis.net/def/rel/ogc/1.0/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            href\n            \"https://stac.eodc.eu/api/v1/collections/SENTINEL1_SIG0_20M/queryables\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"application/schema+json\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Queryables\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        stac_extensions[] 6 items\n        \n            \n        \n            \n                \n        \n            0\n            \"https://stac-extensions.github.io/sat/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"https://stac-extensions.github.io/sar/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \"https://stac-extensions.github.io/eo/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \"https://stac-extensions.github.io/projection/v1.1.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            4\n            \"https://stac-extensions.github.io/item-assets/v1.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            5\n            \"https://stac-extensions.github.io/datacube/v2.0.0/schema.json\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            cube:dimensions\n            \n        \n            \n                \n        \n            x\n            \n        \n            \n                \n        \n            axis\n            \"x\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -180\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            180\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            y\n            \n        \n            \n                \n        \n            axis\n            \"y\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"spatial\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            -90\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            90\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            time\n            \n        \n            \n                \n        \n            type\n            \"temporal\"\n        \n    \n            \n        \n            \n                \n        extent[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2014-10-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            title\n            \"SENTINEL1 Sigma Nought (SIG0) Backscatter in 20 meter resolution\"\n        \n    \n                \n            \n                \n                    \n        \n            extent\n            \n        \n            \n                \n        \n            spatial\n            \n        \n            \n                \n        bbox[] 1 items\n        \n            \n        \n            \n                \n        0[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            -180\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            -90\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            180\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            90\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            temporal\n            \n        \n            \n                \n        interval[] 1 items\n        \n            \n        \n            \n                \n        0[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"2014-10-01T00:00:00Z\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            None\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            license\n            \"proprietary\"\n        \n    \n                \n            \n                \n                    \n        providers[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"TU Wien\"\n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"licensor\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://www.tuwien.at/mg/geo\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"EODC\"\n        \n    \n            \n        \n            \n                \n        roles[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"processor\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"host\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            url\n            \"https://eodc.eu/\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            summaries\n            \n        \n            \n                \n        gsd[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            20\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        eo:bands[] 4 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"VV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VV\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VV polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \n        \n            \n                \n        \n            name\n            \"VH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VH\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VH polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            2\n            \n        \n            \n                \n        \n            name\n            \"HH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HH\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HH polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            3\n            \n        \n            \n                \n        \n            name\n            \"HV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HV\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HV polarization\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        platform[] 2 items\n        \n            \n        \n            \n                \n        \n            0\n            \"sentinel-1a\"\n        \n    \n            \n        \n    \n        \n            \n        \n            \n                \n        \n            1\n            \"sentinel-1b\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            item_assets\n            \n        \n            \n                \n        \n            HH\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (HH)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"HH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HH\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HH polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            HV\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (HV)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"HV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_HV\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in HV polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            VH\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (VH)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"VH\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VH\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VH polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            VV\n            \n        \n            \n                \n        \n            type\n            \"image/tiff; application=geotiff\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Sigma Nought (VV)\"\n        \n    \n            \n        \n            \n                \n        eo:bands[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \n        \n            \n                \n        \n            name\n            \"VV\"\n        \n    \n            \n        \n            \n                \n        \n            common_name\n            \"Sigma0_VV\"\n        \n    \n            \n        \n            \n                \n        \n            center_wavelength\n            55465.76\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            description\n            \"Sigma Nought in VV polarization\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            title\n            \"Thumbnail\"\n        \n    \n            \n        \n            \n                \n        \n            description\n            \"A medium sized thumbnail\"\n        \n    \n            \n        \n    \n        \n    \n            \n        \n    \n        \n    \n            \n        \n            \n                \n        \n            constellation\n            \"sentinel-1\"\n        \n    \n            \n        \n    \n        \n    \n                \n            \n                \n                    \n        \n            assets\n            \n        \n            \n                \n        \n            thumbnail\n            \n        \n            \n                \n        \n            href\n            \"https://objectstore.eodc.eu:2222/swift/v1/AUTH_68e13833a1624f43ba2cac01376a18af/thumbnails/SENTINEL1_SIG0_20M.png\"\n        \n    \n            \n        \n            \n                \n        \n            type\n            \"image/png\"\n        \n    \n            \n        \n            \n                \n        \n            title\n            \"SENTINEL1_SIG0_20M collection thumbnail.\"\n        \n    \n            \n        \n            \n                \n        roles[] 1 items\n        \n            \n        \n            \n                \n        \n            0\n            \"thumbnail\"\nEach collection has multiple items. An item is one spatio-temporal instance in the collection, for instance a satellite image. If items are needed for a specific timeframe or for a specific region of interest, we can define this as a query.\ntime_range = \"2022-10-01/2022-10-07\"  # a closed range\n# time_range = \"2022-01\"  # whole month, same can be done for a year and a day\n# time_range = \"2022-01-01/..\"  # up to the current date, an open range\n# time_range = \"2022-01-01T05:34:46\"  # a specific time instance\nA spatial region of interest can be defined in different ways. One option is to define a simple bounding box:\nlatmin, latmax = 46.3, 49.3  # South to North\nlonmin, lonmax = 13.8, 17.8  # West to East\n\nbounding_box = [lonmin, latmin, lonmax, latmax]\nIf the region of interest is not rectangular, we can also define a polygon:\n# GEOJSON can be created on geojson.io\n\n# This specific area of interest is a rectangle, but since it is\n# a closed polygon it seems like it has five nodes\n\narea_of_interest = {\n    \"coordinates\": [\n        [\n            [17.710928010825853, 49.257630084442496],\n            [13.881798300915221, 49.257630084442496],\n            [13.881798300915221, 46.34747715326259],\n            [17.710928010825853, 46.34747715326259],\n            [17.710928010825853, 49.257630084442496],\n        ]\n    ],\n    \"type\": \"Polygon\",\n}\nUsing our previously loaded STAC catalog, we can now search for items fullfilling our query. In this example we are using the bounding box. If we want to use an area of interest specified in the geojson format - one has to use the intersects parameter as documented in the comment below.\nsearch = eodc_catalog.search(\n    collections=colllection_id,  # can also be a list of several collections\n    bbox=bounding_box,  # search by bounding box\n    # intersects=area_of_interest,  # GeoJSON search\n    datetime=time_range,\n    # max_items=1  # number of max items to load\n)\n\n# If we comment everything besides colllection_id, we will load whole\n# collection for available region and time_range\n\nitems_eodc = search.item_collection()\nprint(f\"On EODC we found {len(items_eodc)} items for the given search query\")\n\nOn EODC we found 52 items for the given search query\nNow, we can fetch a single item, in this case a Sentinel-1 image, from the query results. A good practice is to always check what metadata the data provider has stored on the item level. This can be done by looking into the item properties.\nitem = items_eodc[0]\nitem.properties\n\n{'gsd': 20,\n 'parent': 'S1A_IW_GRDH_1SDV_20221007T170811_20221007T170836_045339_056BBA_D830.zip',\n 'checksum': '576abe68a715e5ee177d8b640871e873',\n 'datetime': '2022-10-07T17:08:11Z',\n 'blocksize': {'x': 15000, 'y': 5},\n 'proj:bbox': [4800000, 1500000, 5100000, 1800000],\n 'proj:wkt2': 'PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]',\n 'proj:shape': [15000, 15000],\n 'Equi7_TileID': 'EU020M_E048N015T3',\n 'constellation': 'sentinel-1',\n 'proj:geometry': {'type': 'Polygon',\n  'coordinates': [[[4800000.0, 1500000.0],\n    [4800000.0, 1800000.0],\n    [5100000.0, 1800000.0],\n    [5100000.0, 1500000.0],\n    [4800000.0, 1500000.0]]]},\n 'proj:transform': [20, 0, 4800000, 0, -20, 1800000],\n 'sat:orbit_state': 'ascending',\n 'sar:product_type': 'GRD',\n 'slice_gap_filled': False,\n 'sar:polarizations': ['VH', 'VV'],\n 'sar:frequency_band': 'C',\n 'sat:relative_orbit': 117,\n 'sar:instrument_mode': 'IW',\n 'border_noise_removed': True,\n 'sar:center_frequency': 5.405,\n 'sar:resolution_range': 40,\n 'thermal_noise_removed': True,\n 'sar:resolution_azimuth': 40,\n 'sar:pixel_spacing_range': 20,\n 'sar:observation_direction': 'right',\n 'sar:pixel_spacing_azimuth': 20,\n 'sat:platform_international_designator': '2014-016A'}\nFor now, letâ€™s display only the vertical-vertical (VV) polarized band of the item and some information about the data.\nitem.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0]\n\n{'scale': 10,\n 'nodata': -9999,\n 'offset': 0,\n 'data_type': 'int16',\n 'spatial_resolution': 20}\nIn the EODC STAC catalogue an item can conveniently be displayed using its thumbnail.\nitem.assets[\"thumbnail\"].href\n\n'https://data.eodc.eu/collections/SENTINEL1_SIG0_20M/V1M1R1/EQUI7_EU020M/E048N015T3/SIG0_20221007T170811__VV_A117_E048N015T3_EU020M_V1M1R1_S1AIWGRDH_TUWIEN.tif/thumbnail'\nNow we will plot the data on a map using the thumbnail and the python package folium. This is an easy way to quickly check how the data found by a search query looks on a map.\nmap = folium.Map(\n    location=[(latmin + latmax) / 2, (lonmin + lonmax) / 2],\n    zoom_start=7,\n    zoom_control=False,\n    scrollWheelZoom=False,\n    dragging=False,\n)\n\nfolium.GeoJson(area_of_interest, name=\"Area of Interest\").add_to(map)\n\nfor item in items_eodc:\n    # url leading to display of an item, can also be used as hyperlink\n    image_url = item.assets[\"thumbnail\"].href\n    bounds = item.bbox\n    folium.raster_layers.ImageOverlay(\n        image=image_url,\n        bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n    ).add_to(map)\n\nfolium.LayerControl().add_to(map)\n\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\nFigure 1: Map of study area. Blue rectangle is the area covered by the discovered data.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Discover and Read SAR Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/01_in_class_exercise.html#data-reading",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/01_in_class_exercise.html#data-reading",
    "title": "1Â  Discover and Read SAR Data",
    "section": "1.2 Data Reading",
    "text": "1.2 Data Reading\nSTAC can also be a useful tool for the discovery of data, however it only loads metadata. This saves memory, but if one would like to do further analysis, the data has to be loaded into memory or downloaded on disk.\nIn the following, we will demonstrate this with the library odc-stac. Here we can define what data will loaded as bands; in this case VV sigma naught. Moreover we can resample the data by providing any coordinate reference system (CRS) and resolution as well as a method for resampling of continuos data (e.g.Â bilinear resampling). In the example below we use the EQUI7 Grid of Europe and a 20 meter sampling. This is the native format of sigma naught stored at EODC, so there will be no actual resampling. Note, also, that resampling is not advisable for this data, as it is provided on a logarithmic scale. More about this in the notebook â€œBackscattering Coefficientsâ€.\nThe chunks argument is an advancement method for performing parallel computations on the data. We will not cover this in further detail.\n\nbands = \"VV\"  # Vertical-vertical polarized\ncrs = \"EPSG:27704\"  # Coordinate Reference System: EQUI7 Grid of Europe\nres = 20  # 20 meter\nchunks = {\"time\": 1, \"latitude\": 1000, \"longitude\": 1000}\nsig0_dc = odc_stac.load(\n    items_eodc,\n    bands=bands,\n    crs=crs,\n    resolution=res,\n    bbox=bounding_box,\n    chunks=chunks,\n    resampling=\"bilinear\",\n)\n\nLetâ€™s have a look at the VV polarized band of the dataset.\n\nsig0_dc.VV\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'VV' (time: 31, y: 18269, x: 16725)&gt; Size: 19GB\ndask.array&lt;VV, shape=(31, 18269, 16725), dtype=int16, chunksize=(1, 18269, 16725), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * y            (y) float64 146kB 1.762e+06 1.762e+06 ... 1.396e+06 1.396e+06\n  * x            (x) float64 134kB 5.052e+06 5.052e+06 ... 5.387e+06 5.387e+06\n    spatial_ref  int32 4B 27704\n  * time         (time) datetime64[ns] 248B 2022-10-01T05:09:56 ... 2022-10-0...\nAttributes:\n    nodata:   -9999xarray.DataArray'VV'time: 31y: 18269x: 16725dask.array&lt;chunksize=(1, 18269, 16725), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n17.64 GiB\n582.79 MiB\n\n\nShape\n(31, 18269, 16725)\n(1, 18269, 16725)\n\n\nDask graph\n31 chunks in 3 graph layers\n\n\nData type\nint16 numpy.ndarray\n\n\n\n\n                                                             16725 18269 31\n\n\n\n\nCoordinates: (4)y(y)float641.762e+06 1.762e+06 ... 1.396e+06units :metreresolution :-20.0crs :EPSG:27704array([1761670., 1761650., 1761630., ..., 1396350., 1396330., 1396310.],\n      shape=(18269,))x(x)float645.052e+06 5.052e+06 ... 5.387e+06units :metreresolution :20.0crs :EPSG:27704array([5052090., 5052110., 5052130., ..., 5386530., 5386550., 5386570.],\n      shape=(16725,))spatial_ref()int3227704spatial_ref :PROJCRS[\"WGS 84 / Equi7 Europe\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Equi7 projection - Europe\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.82,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.696,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Continental mapping of raster data.\"],AREA[\"Europe including Russia west of the Ural Mountains.\"],BBOX[29.24,-42.52,83.67,51.73]],ID[\"EPSG\",27704]]crs_wkt :PROJCRS[\"WGS 84 / Equi7 Europe\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Equi7 projection - Europe\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.82,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.696,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Continental mapping of raster data.\"],AREA[\"Europe including Russia west of the Ural Mountains.\"],BBOX[29.24,-42.52,83.67,51.73]],ID[\"EPSG\",27704]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensembleprojected_crs_name :WGS 84 / Equi7 Europegrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.82false_northing :2121415.696GeoTransform :5052080 20 0 1761680 0 -20array(27704, dtype=int32)time(time)datetime64[ns]2022-10-01T05:09:56 ... 2022-10-...array(['2022-10-01T05:09:56.000000000', '2022-10-01T05:10:21.000000000',\n       '2022-10-01T05:10:46.000000000', '2022-10-01T05:11:11.000000000',\n       '2022-10-01T05:11:36.000000000', '2022-10-02T16:58:39.000000000',\n       '2022-10-02T16:59:04.000000000', '2022-10-02T16:59:29.000000000',\n       '2022-10-02T16:59:54.000000000', '2022-10-03T04:53:37.000000000',\n       '2022-10-03T04:54:02.000000000', '2022-10-03T04:54:27.000000000',\n       '2022-10-03T04:54:52.000000000', '2022-10-03T18:02:55.000000000',\n       '2022-10-04T05:34:54.000000000', '2022-10-04T05:35:19.000000000',\n       '2022-10-04T16:42:01.000000000', '2022-10-04T16:42:26.000000000',\n       '2022-10-04T16:42:51.000000000', '2022-10-04T16:43:16.000000000',\n       '2022-10-04T16:43:41.000000000', '2022-10-06T05:18:07.000000000',\n       '2022-10-06T05:18:32.000000000', '2022-10-06T05:18:57.000000000',\n       '2022-10-06T05:19:22.000000000', '2022-10-06T05:19:47.000000000',\n       '2022-10-07T17:06:31.000000000', '2022-10-07T17:06:56.000000000',\n       '2022-10-07T17:07:21.000000000', '2022-10-07T17:07:46.000000000',\n       '2022-10-07T17:08:11.000000000'], dtype='datetime64[ns]')Attributes: (1)nodata :-9999\n\n\nAs we can see, the data is stored as a xarray DataArray. Xarray is a convenient package for multidimensional labeled arrays, like temperature, humidity, pressure, different bands of satellite imagery, and so on. The link provides detailed documentation. In a later notebook we will explore some more of the functionality of xarray. As we can see in the coordinates, the data here consists of 21 time steps.\nIn general, data from STAC is â€œlazilyâ€ loaded, which means that the structure of the DataArray is constructed, but the data is not loaded yet. It is loaded only at instance when it is needed, for example, for plotting, computations, and so on.\nSince the DataArray has currently a size of almost 18 GiB, we will subset it to the region of Vienna.\n\n# Create a bounding box covering the region of Vienna\nlatmin_smaller, latmax_smaller = 48, 48.4\nlonmin_smaller, lonmax_smaller = 16, 16.5\n\nsmaller_bounding_box = [\n    [latmin_smaller, lonmin_smaller],\n    [latmax_smaller, lonmax_smaller],\n]\n\nmap = folium.Map(\n    location=[\n        (latmin_smaller + latmax_smaller) / 2,\n        (lonmin_smaller + lonmax_smaller) / 2,\n    ],\n    zoom_start=8,\n    zoom_control=False,\n    scrollWheelZoom=False,\n    dragging=False,\n)\n\nfolium.GeoJson(area_of_interest, name=\"Area of Interest\").add_to(map)\n\nfolium.Rectangle(\n    bounds=smaller_bounding_box,\n    color=\"red\",\n).add_to(map)\n\nfor item in items_eodc:\n    image_url = item.assets[\"thumbnail\"].href\n    bounds = item.bbox\n    folium.raster_layers.ImageOverlay(\n        image=image_url,\n        bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n    ).add_to(map)\n\nfolium.LayerControl().add_to(map)\n\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFigure 2: Map of study area. Blue rectangle is the area covered by the discovered data. Red rectangle covers the selected data.\nCreate a new dataset with the smaller bounding box covering the region of Vienna. We will leave out the arguments for resampling and directly use the native format as defined in the metadata.\n\nsig0_dc = odc_stac.load(\n    items_eodc,\n    bands=bands,\n    bbox=[lonmin_smaller, latmin_smaller, lonmax_smaller, latmax_smaller],\n    chunks=chunks,\n)\n\nDue to the way the data is acquired and stored, some items include â€œno dataâ€ areas. In our case, no data has the value -9999, but this can vary from data provider to data provider. This information can usually be found in the metadata. Furthermore, to save memory, data is often stored as integer (e.g.Â 25) and not in float (e.g.Â 2.5) format. For this reason, the backscatter values are often multiplied by a scale factor, in this case factor 10.\nAs Sentinel-1 satellites overpasses Austria every few days, only some time steps of the dataset will have physical data. As a final step, we will now decode the data and create a plot of two consecutive Sentinel-1 acquisitions of Vienna.\n\n# Retrieve the scale factor and NoData value from the metadata. raster:bands is\n# a STAC raster extension\nscale = item.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"scale\"]\nnodata = item.assets[\"VV\"].extra_fields.get(\"raster:bands\")[0][\"nodata\"]\n\n# Decode data with the NoData value and the scale factor\nsig0_dc = sig0_dc.where(sig0_dc != nodata) / scale\n\n# We should remove unnecessary dates when there was no data\n# (no satellite overpass)\nsig0_dc = sig0_dc.dropna(dim=\"time\")\n\n\nsig0_dc.VV.plot(col=\"time\", robust=True, cmap=\"Greys_r\", aspect=1, size=10)\n\n\n\n\n\n\n\n\nFigure 3: Sentinel-1 microwave backscatter image for two timeslices.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Discover and Read SAR Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html",
    "title": "2Â  Unit Conversion",
    "section": "",
    "text": "2.1 Exploring the Data\nIn this notebook, we are going to have a look at the conversion of units. Sentinel-1 data, and most other SAR data, is usually provided in decibels (dB). In this notebook, we will discover the advantages of displaying SAR data in decibels and why we need to convert the data to a linear scale in order to make meaningful calculations. Letâ€™s start with importing some libraries.\n\\[\n\\text{logarithmic} \\longleftrightarrow \\text{linear}\n\\] \\[\n[\\text{dB}] \\longleftrightarrow [\\text{m}^2 \\cdot \\text{m}^{-2}]\n\\]\nLetâ€™s start by loading some sample data, in order to demonstrate why this conversion is important. Here we will have a look at some SAR data from the Sentinel-1. The data is provided in decibels (dB). In the following example, we will:",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Unit Conversion</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#exploring-the-data",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#exploring-the-data",
    "title": "2Â  Unit Conversion",
    "section": "",
    "text": "load data from Sentinel-1\nvisualize the data in logarithmic scale\ncompare the data with linear scale",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Unit Conversion</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#search-for-some-data",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#search-for-some-data",
    "title": "2Â  Unit Conversion",
    "section": "2.2 Search for some Data",
    "text": "2.2 Search for some Data\nNow, we start by loading data from Sentinel-1 from the EODC STAC Catalogue. We do this in the same way as in the previous notebook â€œDiscover and Read SAR Dataâ€.\n\nlatmin, latmax = 48, 48.5\nlonmin, lonmax = 16, 17\nbounds = (lonmin, latmin, lonmax, latmax)\n\ntime_range = \"2022-07-01/2022-07-31\"\n\nitems = (\n    pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\n    .search(\n        bbox=bounds,\n        collections=[\"SENTINEL1_SIG0_20M\"],\n        datetime=time_range,\n        limit=100,\n    )\n    .item_collection()\n)\n\nprint(len(items), \"scenes found\")\n\n60 scenes found\n\n\n\nbands = \"VV\"\n\nsig0_dc = odc.stac.stac_load(\n    items,\n    bands=bands,\n    bbox=bounds,\n    chunks={\"time\": 5, \"x\": 1000, \"y\": 1000},\n)\n\nnodata = items[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0][\"nodata\"]\nscale = items[0].assets[\"VV\"].extra_fields[\"raster:bands\"][0][\"scale\"]\n\nsig0_dc = (sig0_dc.where(sig0_dc != nodata) / scale).VV\nsig0_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'VV' (time: 60, y: 3150, x: 3978)&gt; Size: 3GB\ndask.array&lt;truediv, shape=(60, 3150, 3978), dtype=float32, chunksize=(5, 1000, 1000), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * y            (y) float64 25kB 1.653e+06 1.653e+06 ... 1.59e+06 1.59e+06\n  * x            (x) float64 32kB 5.241e+06 5.241e+06 ... 5.32e+06 5.32e+06\n    spatial_ref  int32 4B 27704\n  * time         (time) datetime64[ns] 480B 2022-07-02T05:18:03 ... 2022-07-3...xarray.DataArray'VV'time: 60y: 3150x: 3978dask.array&lt;chunksize=(5, 1000, 1000), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n2.80 GiB\n19.07 MiB\n\n\nShape\n(60, 3150, 3978)\n(5, 1000, 1000)\n\n\nDask graph\n192 chunks in 7 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           3978 3150 60\n\n\n\n\nCoordinates: (4)y(y)float641.653e+06 1.653e+06 ... 1.59e+06units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([1653150., 1653130., 1653110., ..., 1590210., 1590190., 1590170.],\n      shape=(3150,))x(x)float645.241e+06 5.241e+06 ... 5.32e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5240690., 5240710., 5240730., ..., 5320190., 5320210., 5320230.],\n      shape=(3978,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5240680 20 0 1653160 0 -20array(27704, dtype=int32)time(time)datetime64[ns]2022-07-02T05:18:03 ... 2022-07-...array(['2022-07-02T05:18:03.000000000', '2022-07-02T05:18:28.000000000',\n       '2022-07-02T05:18:53.000000000', '2022-07-04T05:01:44.000000000',\n       '2022-07-04T05:02:09.000000000', '2022-07-04T05:02:34.000000000',\n       '2022-07-05T16:50:50.000000000', '2022-07-05T16:51:15.000000000',\n       '2022-07-05T16:51:40.000000000', '2022-07-07T16:34:45.000000000',\n       '2022-07-07T16:35:10.000000000', '2022-07-07T16:35:35.000000000',\n       '2022-07-09T05:09:52.000000000', '2022-07-09T05:10:17.000000000',\n       '2022-07-09T05:10:42.000000000', '2022-07-10T16:59:00.000000000',\n       '2022-07-10T16:59:25.000000000', '2022-07-10T16:59:50.000000000',\n       '2022-07-11T04:53:33.000000000', '2022-07-11T04:53:58.000000000',\n       '2022-07-11T04:54:23.000000000', '2022-07-12T16:42:47.000000000',\n       '2022-07-12T16:43:12.000000000', '2022-07-12T16:43:37.000000000',\n       '2022-07-14T05:18:03.000000000', '2022-07-14T05:18:28.000000000',\n       '2022-07-14T05:18:53.000000000', '2022-07-16T05:01:45.000000000',\n       '2022-07-16T05:02:10.000000000', '2022-07-16T05:02:35.000000000',\n       '2022-07-17T16:50:51.000000000', '2022-07-17T16:51:16.000000000',\n       '2022-07-17T16:51:41.000000000', '2022-07-19T16:34:46.000000000',\n       '2022-07-19T16:35:11.000000000', '2022-07-19T16:35:36.000000000',\n       '2022-07-21T05:09:52.000000000', '2022-07-21T05:10:17.000000000',\n       '2022-07-21T05:10:42.000000000', '2022-07-22T16:59:01.000000000',\n       '2022-07-22T16:59:26.000000000', '2022-07-22T16:59:51.000000000',\n       '2022-07-23T04:53:34.000000000', '2022-07-23T04:53:59.000000000',\n       '2022-07-23T04:54:24.000000000', '2022-07-24T16:42:48.000000000',\n       '2022-07-24T16:43:13.000000000', '2022-07-24T16:43:38.000000000',\n       '2022-07-26T05:18:04.000000000', '2022-07-26T05:18:29.000000000',\n       '2022-07-26T05:18:54.000000000', '2022-07-28T05:01:45.000000000',\n       '2022-07-28T05:02:10.000000000', '2022-07-28T05:02:35.000000000',\n       '2022-07-29T16:50:51.000000000', '2022-07-29T16:51:16.000000000',\n       '2022-07-29T16:51:41.000000000', '2022-07-31T16:34:46.000000000',\n       '2022-07-31T16:35:11.000000000', '2022-07-31T16:35:36.000000000'],\n      dtype='datetime64[ns]')",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Unit Conversion</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#comparison-of-the-data-in-db-and-linear-scale",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#comparison-of-the-data-in-db-and-linear-scale",
    "title": "2Â  Unit Conversion",
    "section": "2.3 Comparison of the Data in dB and Linear Scale",
    "text": "2.3 Comparison of the Data in dB and Linear Scale\nIn the next two cells we will select a subset of the data. This is done to reduce the amount of data we are working with. The precise workflow is not important for now, since the theory is explained after the cells. They are just here to show the data we are working with.\n\nsubset = sig0_dc.sel(time=slice(\"2022-07-01\", \"2022-07-07\"))\nsubset = subset.dropna(\"time\", how=\"all\")\n\nNow plot the data.\n\naoi = subset.isel(time=0, x=slice(0, 500), y=slice(0, 500))\naoi_lin = 10 ** (aoi / 10)\n\nfig, ax = plt.subplots(2, 3, figsize=(14, 8))\n# upper left\nax_ul = ax[0, 0]\naoi.plot.imshow(robust=True, ax=ax_ul, cmap=\"Greys_r\")\nax_ul.set_title(r\"$\\sigma^0$ [$dB$] (robust plot)\")\nax_ul.axes.set_aspect(\"equal\")\n\n# upper middle\nax_um = ax[0, 1]\naoi.plot.imshow(robust=False, ax=ax_um, cmap=\"Greys_r\")\nax_um.set_title(r\"$\\sigma^0$ [$dB$] (not robust plot)\")\nax_um.axes.set_aspect(\"equal\")\n\n# upper right\nax_ur = ax[0, 2]\naoi.plot.hist(bins=50, ax=ax_ur, edgecolor=\"black\")\nax_ur.set_xlabel(r\"$\\sigma^0$ [$dB$]\")\nax_ur.set_title(r\"$\\sigma^0$ [$dB$] distribution\")\nax_ur.set_ylabel(\"n (number of pixels)\")\n\n# lower left\nax_ll = ax[1, 0]\naoi_lin.plot.imshow(robust=True, ax=ax_ll, cmap=\"Greys_r\")\nax_ll.set_title(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$] (robust plot)\")\nax_ll.axes.set_aspect(\"equal\")\n\n# lower middle\nax_lm = ax[1, 1]\naoi_lin.plot.imshow(robust=False, ax=ax_lm, cmap=\"Greys_r\")\nax_lm.set_title(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$] (not robust plot)\")\nax_lm.axes.set_aspect(\"equal\")\n\n# lower right\nax_lr = ax[1, 2]\naoi_lin.plot.hist(bins=50, ax=ax_lr, edgecolor=\"black\")\nax_lr.set_xlabel(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$]\")\nax_lr.set_ylabel(\"n (number of pixels)\")\nax_lr.set_title(r\"$\\sigma^0$ [$m^2 \\cdot m^{-2}$] distribution\")\n\ntitle = (\n    r\"Sentinel-1 backscatter $\\sigma^0$ comparison\"\n    r\" in linear and logarithmic domain\"\n)\nfig.suptitle(title, horizontalalignment=\"center\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nFigure 1: Visually comparing \\(\\sigma^0\\) on a logarithmic and linear scale (left column). In addition, the benefit of using the robust plotting method is shown (middle column). The robust argument uses the 2nd and 98th percentiles of the data to compute the color limits to eliminate washing out the plot due to data outliers.\nIn the plot above you can see the difference between the two scales. The values in dB are more evenly distributed and are therefore easier to plot. The values in linear scale are more spread out and are therefore harder to interpret. This is why we use the dB scale for plotting/visualization.\nWhile the logarithmic scale facilitates visual interpretation, it has implications for mathematical operations. In the following, weâ€™ll have a closer look at this. But first, letâ€™s see how we can convert between the linear and the logarithmic domains.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Unit Conversion</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#conversion-formulas",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#conversion-formulas",
    "title": "2Â  Unit Conversion",
    "section": "2.4 Conversion Formulas",
    "text": "2.4 Conversion Formulas\nThe decibel (dB) is a logarithmic unit used to express the ratio of two values of a physical quantity, often power or intensity. In the case of SAR data, the backscatter coefficient is often expressed in dB to facilitate visualization.\nIn order to convert the data from dB to linear scale, we use the following formula. Let \\(D\\) be the original value (dB) and \\(I\\) the converted value (\\(m^2m^{-2}\\)). The conversion of units can be expressed as: \\[\nD =  10  \\cdot \\log_{10} (I) = 10 \\cdot \\log_{10} (e) \\cdot \\ln (I)\\longrightarrow [dB]\n\\] Similarly, the conversion back to the original unit can be expressed as: \\[\nI = e^{\\frac{D}{10\\cdot \\log_{10}(e)}} = 10^{\\frac{D}{10}} \\longrightarrow [m^2m^{-2}]\n\\] You can find these formulas in the script for Microwave Remote Sensing on page 136 (equation 6.40).\nNow letâ€™s implement the conversion in Python.\n\ndef lin2db(val: float) -&gt; float:\n    \"\"\"Converts value from linear to dB units.\n\n    :param val: Value in linear units.\n    :type val: float|int\n    :return: Value in dB.\n    :rtype: float\n    \"\"\"\n    return 10 * np.log10(val)\n\n\ndef db2lin(val: float) -&gt; float:\n    \"\"\"Converts value from dB to linear units.\n\n    :param val: Value in dB.\n    :type val: float|int\n    :return: Value in linear units.\n    :rtype: float\n    \"\"\"\n    return 10 ** (val / 10)\n\nWhen performing mathematical operations with SAR data it is important to be aware, that adding values in the logarithmic scale doesnâ€™t work in the same way as adding regular (linear) values. This is because in the logarithmic scale, each unit step represents an equal multiplication. This means that an addition of two values in the logarithmic scale equals a multiplication of the values in the linear scale. Vice versa, a subtraction in a logarithmic scale equals a division in a linear scale. Letâ€™s have a look at an example, where we add two values, once without the conversion to linear scale and once with the conversion to linear scale.\n\n# Logarithmic addition\n# Values in linear and decibel units\nval1_db, val2_db = 10, 12\n\n# Logarithmic addition\nsum_db = val1_db + val2_db\nprint(\"Logarithmic Addition:\")\nprint(f\"Logarithmic values: \\t{val1_db: &lt;5}, {val2_db: &lt;5} [dB]\")\nprint(f\"Logarithmic sum: \\t{val1_db} + {val2_db} = {sum_db: &lt;5} [dB]\")\n\n# Linear addition\nval1_lin, val2_lin = db2lin(val1_db), db2lin(val2_db)\nsum_lin = val1_lin + val2_lin\nprint(\"\\nLinear Addition:\")\nprint(\n    f\"\"\"Linear values: \\t\\t{val1_lin: &lt;5}, {val2_lin: &lt;5.2f} [lin]\n      \\t\\t\\t(converted from dB)\"\"\"\n)\nprint(f\"Linear sum: \\t\\t{val1_lin} + {val2_lin: .2f} = {sum_lin: .2f} [lin]\")\nprint(f\"\\t\\t\\t= {lin2db(sum_lin): .2f} [dB]\")\n\nLogarithmic Addition:\nLogarithmic values:     10   , 12    [dB]\nLogarithmic sum:    10 + 12 = 22    [dB]\n\nLinear Addition:\nLinear values:      10.0 , 15.85 [lin]\n                (converted from dB)\nLinear sum:         10.0 +  15.85 =  25.85 [lin]\n            =  14.12 [dB]\n\n\nAs you can see, the values in dB and in linear scale differ quite a bit. In the example above, the values differ by a factor of around 6 when looked at in linear scale.\nNow that we have some data, we will have a look at some practical examples where we will convert the data to linear scale. When we try to calculate the average \\(\\sigma^0\\) value across the scene, we need to do this by converting the data to linear scale first and then calculating the average and converting it back to dB.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Unit Conversion</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#creating-a-monthly-mosaic",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/02_in_class_exercise.html#creating-a-monthly-mosaic",
    "title": "2Â  Unit Conversion",
    "section": "2.5 Creating a Monthly Mosaic",
    "text": "2.5 Creating a Monthly Mosaic\nSo in the beginning we have lazily loaded data for an area across a whole year. We therefore have around 700 images. We will now essentially compress the data of each month into one timestamp. This is done by using the resampling method together with an operation method like mean that includes summation. Since the data is in dB we need to convert it to linear scale first, then we can resample the data and convert it back to dB.\n\n# Convert to linear scale and calculate monthly means\n# Conversion by calculating with the xarray Object\nsig0_lin = 10 ** (sig0_dc / 10)\n\n# Resample to monthly means. Time accepts intervals identical to the pandas\n# resample function. 'D' for days, 'W' for weeks, 'ME' for months.\nsig0_lin_monthly = sig0_lin.resample(time=\"1ME\").mean()\n\n# Convert back to dB scale\n# Conversion by applying a function\nsig0_monthly = lin2db(sig0_lin_monthly)\nsig0_monthly\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'VV' (time: 1, y: 3150, x: 3978)&gt; Size: 50MB\ndask.array&lt;mul, shape=(1, 3150, 3978), dtype=float32, chunksize=(1, 1000, 1000), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * y            (y) float64 25kB 1.653e+06 1.653e+06 ... 1.59e+06 1.59e+06\n  * x            (x) float64 32kB 5.241e+06 5.241e+06 ... 5.32e+06 5.32e+06\n    spatial_ref  int32 4B 27704\n  * time         (time) datetime64[ns] 8B 2022-07-31xarray.DataArray'VV'time: 1y: 3150x: 3978dask.array&lt;chunksize=(1, 1000, 1000), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n47.80 MiB\n3.81 MiB\n\n\nShape\n(1, 3150, 3978)\n(1, 1000, 1000)\n\n\nDask graph\n16 chunks in 15 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                     3978 3150 1\n\n\n\n\nCoordinates: (4)y(y)float641.653e+06 1.653e+06 ... 1.59e+06units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([1653150., 1653130., 1653110., ..., 1590210., 1590190., 1590170.],\n      shape=(3150,))x(x)float645.241e+06 5.241e+06 ... 5.32e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5240690., 5240710., 5240730., ..., 5320190., 5320210., 5320230.],\n      shape=(3978,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5240680 20 0 1653160 0 -20array(27704, dtype=int32)time(time)datetime64[ns]2022-07-31array(['2022-07-31T00:00:00.000000000'], dtype='datetime64[ns]')\n\n\nThe dataset has now only 12 timestamps, one for each month. Next, we want to calculate the average \\(\\sigma^0\\) value across a subset of the scene for one month. We will do this again by converting the data to linear scale first and then calculating the average and converting it back to dB.\n\n# Lets take a data array with db values\ndb_array = (\n    sig0_monthly.sel(time=\"2022-07-30\", method=\"nearest\")\n    .isel(x=slice(300, 400), y=slice(500, 600))\n    .compute()\n)\n\n# Compute the linear values\nlin_array = db2lin(db_array)\n\n\n# Compute the average backscatter value in linear units across the whole scene\nlin_mean = lin_array.mean()\nprint(f\"Average backscatter value in linear units: {lin_mean.values: .3f}\")\ndb_from_lin_mean = lin2db(lin_mean)\nprint(f\"That value in dB: {db_from_lin_mean.values: .3f}\\n\")\n\n# Compute the average backscatter value in dB across the whole scene\ndb_mean = db_array.mean()\nprint(f\"Average backscatter value in dB: {db_mean.values: .3f}\")\n\nAverage backscatter value in linear units:  0.114\nThat value in dB: -9.424\n\nAverage backscatter value in dB: -10.392\n\n\nAs you can see in the example, the mean values across the scene are different in dB and linear scale. Therefore, it is important to be aware in which scale the data is stored to perform the correct type of mathematical operation or always convert the data to linear scale before doing any calculations.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>Unit Conversion</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/03_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/03_in_class_exercise.html",
    "title": "3Â  Backscattering Coefficients",
    "section": "",
    "text": "3.1 Loading Backscatter Data\nIn this notebook, we will introduce some of the steps involved in the processing of Sentinel-1 Level1 Ground Range Detected (GRD) data to \\(\\sigma^0\\) (sig0) and \\(\\gamma^0\\) (gmr). Moreover, the notebook illustrates the importance and impact of geometric and radiometric terrain correction. As the processing of SAR data is a very time and hardware-intense task, we wonâ€™t perform the actual processing in this notebook. Instead, data at different processing steps is illustrated to highlight the impact of the processing steps.\nWe first load our data from the following intake catalog. Intake is somewhat similar to STAC in that it makes it easy to discover and load data. More importantly, this package allows us to hide some of the complexities involved with getting the data in the right format, which are not of concern in this notebook.\nuri = \"https://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\"\ncat = intake.open_catalog(uri)\ngtc_dc = cat[\"gtc\"].read().compute()\ngtc_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 116MB\nDimensions:      (band: 2, y: 3800, x: 3801)\nCoordinates:\n  * band         (band) &lt;U8 64B 'grd' 'sig0_gtc'\n    spatial_ref  int64 8B 0\n  * x            (x) float64 30kB 9.5 9.5 9.5 9.5 9.501 ... 10.0 10.0 10.0 10.0\n  * y            (y) float64 30kB 47.5 47.5 47.5 47.5 ... 47.0 47.0 47.0 47.0\nData variables:\n    band_data    (band, y, x) float32 116MB 151.0 119.0 119.0 ... nan nan nanxarray.DatasetDimensions:band: 2y: 3800x: 3801Coordinates: (4)band(band)&lt;U8'grd' 'sig0_gtc'array(['grd', 'sig0_gtc'], dtype='&lt;U8')spatial_ref()int640GeoTransform :9.499960609331326 0.000131556088961555 0.0 47.499939478018426 0.0 -0.00013155608896155463crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]geographic_crs_name :WGS 84grid_mapping_name :latitude_longitudehorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]array(0)x(x)float649.5 9.5 9.5 9.5 ... 10.0 10.0 10.0array([9.500026, 9.500158, 9.500289, ..., 9.999676, 9.999808, 9.99994 ],\n      shape=(3801,))y(y)float6447.5 47.5 47.5 ... 47.0 47.0 47.0array([47.499874, 47.499742, 47.499611, ..., 47.000355, 47.000224, 47.000092],\n      shape=(3800,))Data variables: (1)band_data(band, y, x)float32151.0 119.0 119.0 ... nan nan nanarray([[[151.      , 119.      , 119.      , ...,  88.      ,\n          82.      ,  78.      ],\n        [113.      , 121.      , 110.      , ..., 129.      ,\n         127.      , 105.      ],\n        [ 98.      ,  96.      , 115.      , ..., 119.      ,\n         119.      , 109.      ],\n        ...,\n        [  0.      ,   0.      ,   0.      , ...,        nan,\n                nan,        nan],\n        [  0.      ,   0.      ,   0.      , ...,        nan,\n                nan,        nan],\n        [  0.      ,   0.      ,   0.      , ...,        nan,\n                nan,        nan]],\n\n       [[-12.86    , -12.21    , -11.66    , ...,  -8.639999,\n          -8.849999,  -9.15    ],\n        [-14.21    , -13.61    , -14.2     , ...,  -9.059999,\n         -12.2     , -13.66    ],\n        [-11.42    , -12.19    , -13.65    , ..., -13.44    ,\n         -13.549999, -12.57    ],\n        ...,\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan],\n        [       nan,        nan,        nan, ...,        nan,\n                nan,        nan]]], shape=(2, 3800, 3801), dtype=float32)\ngtc_dc.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    robust=True,\n    data_aspect=1,\n    cmap=\"Greys_r\",\n    groupby=\"band\",\n    rasterize=True,\n).opts(frame_height=600, framewise=False, aspect=\"equal\")\nFigure 2: The ground range detected values and geometrically terrain corrected values can be selected on the right-hand side of the graphic.\nThe geometrically terrain corrected values from the gtc_dc object (Figure 1) can be approximated to a certain extent, as we have sufficiently detailed information of topography in this area. This corrects for at least one typically occurring distortion in mountainous regions: â€œforeshorteningâ€.\nFigure 3: Side Looking radar distortions (script Chapter 4).\nForeshortening can be spotted by eye, as it often has a radiometric consequence, where unusually bright areas fringe mountain ridges; a phenomenon called â€œhighlightingâ€. This geometric artifact occurs due to the compression of the distance in the image of slopes facing the radar system and the consequentially higher density of scatterers per unit length. Now letâ€™s zoom in on an example from the same datacube and display the original and corrected values side-by-side.\nfor_dc = gtc_dc.sel(x=slice(9.651, 9.706), y=slice(47.134, 47.079)).band_data\n\nfig, ax = plt.subplots(1, 2, figsize=(20, 8))\n\nbbox = dict(boxstyle=\"round\", fc=\"0.8\")\n\n\nax[1].annotate(\n    \"foreshortening/layover\",\n    xy=(9.674, 47.092),\n    xytext=(0.574, 0.192),\n    textcoords=\"subfigure fraction\",\n    bbox=bbox,\n    arrowprops=dict(facecolor=\"red\", shrink=0.05),\n)\nax[1].annotate(\n    \"radar shadows\",\n    xy=(9.68, 47.119),\n    xytext=(0.6, 0.625),\n    textcoords=\"subfigure fraction\",\n    bbox=bbox,\n    arrowprops=dict(facecolor=\"red\", shrink=0.05),\n)\n\nax[0].axes.set_aspect(\"equal\")\nax[1].axes.set_aspect(\"equal\")\n\nfor_dc.sel(band=\"grd\").plot(ax=ax[0], robust=True, cmap=\"Greys_r\")\nfor_dc.sel(band=\"sig0_gtc\").plot(ax=ax[1], robust=True, cmap=\"Greys_r\")\nFigure 4: Close-up inspection of geometric distortions in side-looking radar\nAs we can see, not all the geometric distortions can be corrected by the algorithm. Some of the pixels at the mountain ranges appear stretched, as in these areas not enough valid measurements are available. Moreover, we can see dark areas which are indicating radar shadows. These are image areas that could not be captured by the radar sensor and have values close to the noise floor of the Sensor (minimum detectable signal strength) ~ -28dB. It is important to note, that radar shadows are not the same for every image, as they depend on the acquisition geometry, in particular, the incidence angle and the flight direction of the satellite.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_01/03_in_class_exercise.html#backscattering-coefficients",
    "href": "chapters/courses/microwave-remote-sensing/unit_01/03_in_class_exercise.html#backscattering-coefficients",
    "title": "3Â  Backscattering Coefficients",
    "section": "3.2 Backscattering Coefficients",
    "text": "3.2 Backscattering Coefficients\nIn this chapter, we will look at some of the different backscatter coefficients in more detail (\\(\\sigma^0_E\\) or \\(\\gamma^0_E\\)), where both coefficients are geometrically terrain corrected. The difference is the plane of the reference area, which is the ground area as a tangent on an ellipsoidal Earth model for \\(\\sigma^0_E\\) and perpendicular to the line of sight for \\(\\gamma^0_E\\) (Figure 5). For this, we load a new datacube which includes \\(\\sigma^0_E\\) and the Incidence Angle for each pixel. We visualize the cube with the same method as before.\n\ncoef_dc = cat.coef.read().compute()\ncoef_dc.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    robust=True,\n    data_aspect=1,\n    cmap=\"Greys_r\",\n    groupby=\"band\",\n    rasterize=True,\n).opts(frame_height=600, framewise=False, aspect=\"equal\")\n\n\n\n\n\n  \n\n\n\n\nFigure 5: The \\(\\sigma^0_E\\) and the incidence angle can be selected on the right-hand side of the graphic.\nIn Figure 5 we can see the incidence angle image of our scene. We can see, that it depicts the differences between near to far range, but not the actual terrain as it refers to the ellipsoid. The slight patterns of the terrain that are visible are originating from the geometric terrain correction. We will use this information now to convert our (\\(\\sigma^0_E\\) to \\(\\gamma^0_E\\)) with the following equation (equation 6.20 in the script):\n\\[ \\gamma^0_E = \\sigma^0_E / \\cos(\\theta_i) \\]\nWe can perform this transformation with basic numpy operations on the xarray datacube.\n\n# linear scale\nsig0_db = coef_dc.sel(band=\"sig0_gtc\") / 10\nsig0_lin = 10 ** (coef_dc.sel(band=\"sig0_gtc\") / 10)\n# conversion to gamma\ngam0_lin = sig0_lin / np.cos(np.radians(coef_dc.sel(band=\"incidence_angle\")))\n# dB scale\ngam0_db = 10 * np.log(gam0_lin)\n# add to existing cube\ncoef_dc = xr.concat(\n    [coef_dc.sel(band=\"sig0_gtc\"), gam0_db.expand_dims(band=[\"gam0_gtc\"])], dim=\"band\"\n)\n\ncoef_dc.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    robust=False,\n    data_aspect=1,\n    cmap=\"Greys_r\",\n    groupby=\"band\",\n    rasterize=True,\n).opts(frame_height=600, framewise=False, aspect=\"equal\")\n\n\n\n\n\n  \n\n\n\n\nFigure 6: \\(\\sigma^0_E\\), and \\(\\gamma^0_E\\) can be selected on the right-hand side of the graphic.\nComparing \\(\\sigma^0_E\\) and \\(\\gamma^0_E\\) in the figure, we can see that both look identical except for the range. This is because the only difference between \\(\\sigma^0_E\\) and \\(\\gamma^0_E\\) is the change of the reference area. While \\(\\sigma^0_E\\) is defined to be ground range, \\(\\gamma^0_E\\) is defined to be in the plane perpendicular to the line of sight from the sensor. This way, \\(\\gamma^0_E\\) mitigates the impact of the incidence angle. However, \\(\\gamma^0_E\\) is still based on the ellipsoid and does not account for the impact of the terrain on the radiometry.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>Backscattering Coefficients</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html",
    "title": "4Â  Datacubes",
    "section": "",
    "text": "4.1 Download Data\nIn this notebook we discuss how we can easily compare images of two or more different time slices, satellites or other earth observation products. We limit our selves to products on a regular grid with an associated coordinate reference system (CRS), known as a raster. This means that each cell of the raster contains an attribute value and location coordinates. The process of combining such rasters to form datacubes is called raster stacking. We can have datacubes in many forms, such as the spatiotemporal datacube:\n\\[Z = f(x,y,t) \\quad \\text{,}\\]\nor when dealing with electromagnetic spectrum, the spectral wavelengths may form an additional dimension of a cube:\n\\[Z = f(x,y,t, \\lambda ) \\quad \\text{.} \\]\nWe also have already encountered the case where \\(Z\\) consists of multiple variables, such as seen in the xarray dataset.\n\\[{Z_1,Z_2,...,Z_3} = f(x,y,t) \\]\nTo perform raster stacking, we generally follow a certain routine (see also Figure 1).\nTo get the same projection, resolution, and region we have to resample one (or more) products. The desired projection, resolution, and region can be adopted from one of the original rasters or it can be a completely new projection of the data.\nFigure 1: Stacking of arrays to form datacubes (source: https://eox.at).\nIn this notebook we will study two different SAR products. SAR data from the Advanced Land Observing Satellite (Alos-2), which is a Japanese platform with an L-band sensor from the Japan Aerospace Exploration Agency (JAXA), and C-band data from the Copernicus Sentinel-1 mission. It is our goal to compare C- with L-band, so we need to somehow stack these arrays.\nFor this exercise we will need to find the correct url to download each of the GeoTIFF files for both Sentinel-1 and Alos-2, where each image has itâ€™s own timestamp for the acquisition.\ndef make_gitlab_urls(sensor):\n    gl = gitlab.Gitlab(\"https://git.geo.tuwien.ac.at\")\n    gl_project = gl.projects.get(1264)\n    l = []\n    root = \"https://git.geo.tuwien.ac.at/api/v4/projects/1264/repository/files/\"\n    end = \"/raw?ref=main&lfs=true\"\n    for object in gl_project.repository_tree(\n        sensor, ref=\"main\", recursive=True, iterator=True\n    ):\n        if object[\"path\"].endswith(\".tif\"):\n            l.append(root + urllib.parse.quote_plus(object[\"path\"]) + end)\n    return l",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#loading-data",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#loading-data",
    "title": "4Â  Datacubes",
    "section": "4.2 Loading Data",
    "text": "4.2 Loading Data\nBefore loading the data into memory we will first look at the area covered by the Sentinel-1 dataset on a map. This way we can select a region of interest for our hypothetical study. We will extract and transform the bounds of the data to longitude and latitude.\n\nbbox = xr.open_mfdataset(\n    make_gitlab_urls(\"sentinel-1\"),\n    engine=\"rasterio\",\n    combine=\"nested\",\n    concat_dim=\"band\",\n).rio.transform_bounds(\"EPSG:4326\")\n\nbbox = box(*bbox)\n\nmap = folium.Map(\n    max_bounds=True,\n    location=[bbox.centroid.y, bbox.centroid.x],\n    scrollWheelZoom=False,\n)\n\n# bounds of image\nfolium.GeoJson(mapping(bbox), name=\"Area of Interest\", color=\"red\").add_to(map)\n\n# minimum longitude, minimum latitude, maximum longitude, maximum latitude\narea_of_interest = box(10.3, 45.5, 10.6, 45.6)\n\nfolium.GeoJson(mapping(area_of_interest), name=\"Area of Interest\").add_to(map)\n\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFigure 2: Map of study area. Red rectangle is the area covered by the Sentinel-1 raster. Blue rectangle is the area of interest.\nOn the map we have drawn rectangles of the area covered by the images and of our selected study area. To prevent loading too much data we will now only load the data as defined by the blue rectangle on the folium map.\nThe Sentinel-1 data is now stored on disk as separate two-dimensional GeoTIFF files with a certain timestamp. The following s1_preprocess function allows to load all files in one go as a spatiotemporal datacube. Basically, the preprocessing function helps reading the timestamp from the file and adds this as a new dimension to the array. The latter allows a concatenation procedure where all files are joined along the new time dimension. In addition by providing area_of_interest.bounds to the parameter bbox we will only load the data of the previously defined area of interest.\n\ndef s1_preprocess(x, bbox, scale):\n    \"\"\"Preprocess file.\n\n    Parameters\n    ----------\n    x : xarray.Dataset\n    bbox: tuple\n      minimum longitude minimum latitude maximum longitude maximum latitude\n    scale: float\n      scaling factor\n\n    Returns\n    -------\n    xarray.Dataset\n\n    \"\"\"\n    path = Path(urllib.parse.unquote_plus(x.encoding[\"source\"]))\n    filename = path.parent.name\n    x = x.rio.clip_box(*bbox, crs=\"EPSG:4326\")\n\n    date_str = filename.split(\"_\")[0][1:]\n    time_str = filename.split(\"_\")[1][:6]\n    datetime_str = date_str + time_str\n    date = pd.to_datetime(datetime_str, format=\"%Y%m%d%H%M%S\")\n    x = x.expand_dims(dim={\"time\": [date]})\n\n    x = (\n        x.rename({\"band_data\": \"s1_\" + path.parent.parent.stem})\n        .squeeze(\"band\")\n        .drop_vars(\"band\")\n    )\n\n    return x * scale\n\nWe load the data again with open_mfdataset and by providing the preprocess function, including the bounds of the area of interest and the scaling factor, as follows:\n\npartial_ = partial(s1_preprocess, bbox=area_of_interest.bounds, scale=0.01)\n\ns1_ds = xr.open_mfdataset(\n    make_gitlab_urls(\"sentinel-1\"),\n    engine=\"rasterio\",\n    combine=\"nested\",\n    chunks=-1,\n    preprocess=partial_,\n)\n\n/tmp/ipykernel_3656/3111316590.py:3: FutureWarning: In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): 'time' ('time',) The recommendation is to set join explicitly for this case.\n  s1_ds = xr.open_mfdataset(\n/tmp/ipykernel_3656/3111316590.py:3: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  s1_ds = xr.open_mfdataset(\n/tmp/ipykernel_3656/3111316590.py:3: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  s1_ds = xr.open_mfdataset(\n/tmp/ipykernel_3656/3111316590.py:3: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  s1_ds = xr.open_mfdataset(",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#unlocking-geospatial-information",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#unlocking-geospatial-information",
    "title": "4Â  Datacubes",
    "section": "4.3 Unlocking Geospatial Information",
    "text": "4.3 Unlocking Geospatial Information\nTo enable further stacking of ALOS-2 and Sentinel-1 data we need to know some more information about the raster. Hence we define the following function print_raster to get the projection (CRS), resolution, and region (bounds). The function leverages the functionality of rioxarray; a package for rasters.\n\ndef print_raster(raster, name):\n    \"\"\"Print Raster Metadata\n\n    Parameters\n    ----------\n    raster: xarray.DataArray|xarray.DataSet\n        raster to process\n    y: string\n        name of product\n\n    \"\"\"\n    print(\n        f\"{name} Raster: \\n----------------\\n\"\n        f\"resolution: {raster.rio.resolution()} {raster.rio.crs.units_factor}\\n\"\n        f\"bounds: {raster.rio.bounds()}\\n\"\n        f\"CRS: {raster.rio.crs}\\n\"\n    )\n\n\nprint_raster(s1_ds, \"Sentinel-1\")\n\nSentinel-1 Raster: \n----------------\nresolution: (10.0, -10.0) ('metre', 1.0)\nbounds: (4769370.0, 1382090.0, 4794450.0, 1397370.0)\nCRS: EPSG:27704\n\n\n\nThe CRS â€œEPSG 27704â€ is part of the EQUI7Grid. This grid provides equal-area tiles, meaning each tile represents the same area, which helps reducing distorsions. This feature is important for remote sensing as it reduces the so-called oversampling due to geometric distortions when projecting on a sphere. This particular projection is developed by TUWien.\nNow we will proceed with loading the ALOS-2 L-band data in much the same fashion as for Sentinel-1. Again timeslices are stored separately as individual GeoTIFFS and they need to be concatenated along the time dimension. We use a slightly different preprocessing function alos_preprocess for this purpose. The most notable difference of this function is the inclusion of a scaling factor for the 16-bit digital numbers (DN):\n\\[\\gamma^0_T = 10 * log_{10}(\\text{DN}^2) - 83.0 \\,dB\\]\nto correctly convert the integers to \\(\\gamma^0_T\\) in the dB range.\n\ndef alos_preprocess(x, bbox):\n    \"\"\"Preprocess file.\n\n    Parameters\n    ----------\n    x : xarray.Dataset\n    bbox: tuple\n      minimum longitude minimum latitude maximum longitude maximum latitude\n\n    Returns\n    -------\n    xarray.Dataset\n\n    \"\"\"\n    path = Path(urllib.parse.unquote_plus(x.encoding[\"source\"]))\n    filename = path.parent.name\n    x = x.rio.clip_box(*bbox, crs=\"EPSG:4326\")\n\n    date_str = filename.split(\"_\")[0][15:22]\n    date = pd.to_datetime(date_str, format=\"%y%m%d\")\n    x = x.expand_dims(dim={\"time\": [date]})\n\n    x = (\n        x.rename({\"band_data\": \"alos_\" + path.parent.parent.stem})\n        .squeeze(\"band\")\n        .drop_vars(\"band\")\n    )\n\n    # conversion to dB scale of alos\n    return 10 * np.log10(x**2) - 83.0\n\nNow we load the data with the open_mfdataset function of xarray and we provide the preprocessing function (see above), which includes the selection of the bounds of an area of interest and the extraction of time stamps from the file name.\n\narea_of_interest = affinity.scale(area_of_interest, xfact=1.7, yfact=1.7)\npartial_ = partial(alos_preprocess, bbox=area_of_interest.bounds)\n\nalos_ds = xr.open_mfdataset(\n    make_gitlab_urls(\"alos-2\"),\n    engine=\"rasterio\",\n    combine=\"nested\",\n    chunks=-1,\n    preprocess=partial_,\n)\n\n/tmp/ipykernel_3656/704052508.py:4: FutureWarning: In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): 'time' ('time',) The recommendation is to set join explicitly for this case.\n  alos_ds = xr.open_mfdataset(\n/tmp/ipykernel_3656/704052508.py:4: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  alos_ds = xr.open_mfdataset(\n/tmp/ipykernel_3656/704052508.py:4: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  alos_ds = xr.open_mfdataset(\n/tmp/ipykernel_3656/704052508.py:4: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  alos_ds = xr.open_mfdataset(\n\n\nAlso, for this dataset we will look at the metadata in order to compare it with Sentinel-1.\n\nprint_raster(alos_ds, \"ALOS-2\")\n\nALOS-2 Raster: \n----------------\nresolution: (25.0, -25.0) ('metre', 1.0)\nbounds: (593137.5, 5035287.5, 633312.5, 5054912.5)\nCRS: EPSG:32632",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#reprojecting",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#reprojecting",
    "title": "4Â  Datacubes",
    "section": "4.4 Reprojecting",
    "text": "4.4 Reprojecting\nThe ALOS-2 is projected on an UTM grid. We would therefore like to reproject this data to match the projection of Sentinel-1. Furthermore, we will upsample the data to match the Sentinel-1 sampling. The rioxarray package has a very convenient method that can do this all in one go:reproject_match. For continuous data it is best to use a bilinear resampling strategy. As always you have to consider again that we deal with values in the dB range, so we need to convert to the linear scale before bilinear resampling.\n\nalos_ds_lin = 10 ** (alos_ds / 10)\nalos_ds_lin = alos_ds_lin.rio.reproject_match(\n    s1_ds,\n    resampling=Resampling.bilinear,\n)\nalos_ds = 10 * np.log10(alos_ds_lin)\n\nWe will overwrite the coordinate values of ALOS-2 with those of Sentinel-1. If we would not do this last step, small errors in how the numbers are stored would prevent stacking of the rasters.\n\nalos_ds = alos_ds.assign_coords(\n    {\n        \"x\": s1_ds.x.data,\n        \"y\": s1_ds.y.data,\n    }\n)\n\nLastly, we will turn the xarray.DataSet to an xarray.DataArray where a new dimension will constitute the sensor for measurement (satellite + polarization).\n\ns1_da = s1_ds.to_array(dim=\"sensor\")\nalos_da = alos_ds.to_array(dim=\"sensor\")\ns1_da\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (sensor: 2, time: 9, y: 1528, x: 2508)&gt; Size: 276MB\ndask.array&lt;stack, shape=(2, 9, 1528, 2508), dtype=float32, chunksize=(1, 1, 1528, 2508), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\n  * time         (time) datetime64[ns] 72B 2022-06-25T05:27:26 ... 2022-10-11...\n    spatial_ref  int64 8B 0\n  * sensor       (sensor) object 16B 's1_VH' 's1_VV'xarray.DataArraysensor: 2time: 9y: 1528x: 2508dask.array&lt;chunksize=(1, 1, 1528, 2508), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n263.14 MiB\n14.62 MiB\n\n\nShape\n(2, 9, 1528, 2508)\n(1, 1, 1528, 2508)\n\n\nDask graph\n18 chunks in 223 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n          2 1                                          2508 1528 9\n\n\n\n\nCoordinates: (5)x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))time(time)datetime64[ns]2022-06-25T05:27:26 ... 2022-10-...array(['2022-06-25T05:27:26.000000000', '2022-07-07T05:27:27.000000000',\n       '2022-07-19T05:27:28.000000000', '2022-07-31T05:27:29.000000000',\n       '2022-08-12T05:27:29.000000000', '2022-09-05T05:27:31.000000000',\n       '2022-09-17T05:27:31.000000000', '2022-09-29T05:27:31.000000000',\n       '2022-10-11T05:27:31.000000000'], dtype='datetime64[ns]')spatial_ref()int640crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0array(0)sensor(sensor)object's1_VH' 's1_VV'array(['s1_VH', 's1_VV'], dtype=object)",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#stacking-of-multiple-arrays",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/04_in_class_exercise.html#stacking-of-multiple-arrays",
    "title": "4Â  Datacubes",
    "section": "4.5 Stacking of Multiple Arrays",
    "text": "4.5 Stacking of Multiple Arrays\nNow we are finally ready to stack Sentinel-1 C-band and ALOS-2 L-band arrays with the function concat of xarray. Now we can use the newly defined \"sensor\" dimension to concatenate the two arrays.\n\nfused_da = xr.concat([s1_da, alos_da], dim=\"sensor\").rename(\"gam0\")\nfused_da\n\n/tmp/ipykernel_3656/1606272018.py:1: FutureWarning: In a future version of xarray the default value for join will change from join='outer' to join='exact'. This change will result in the following ValueError: cannot be aligned with join='exact' because index/labels/sizes are not equal along these coordinates (dimensions): 'time' ('time',) The recommendation is to set join explicitly for this case.\n  fused_da = xr.concat([s1_da, alos_da], dim=\"sensor\").rename(\"gam0\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'gam0' (sensor: 4, time: 14, y: 1528, x: 2508)&gt; Size: 858MB\ndask.array&lt;concatenate, shape=(4, 14, 1528, 2508), dtype=float32, chunksize=(2, 1, 1094, 1094), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\n  * time         (time) datetime64[ns] 112B 2022-06-25 ... 2022-10-15\n  * sensor       (sensor) object 32B 's1_VH' 's1_VV' 'alos_HH' 'alos_HV'\n    spatial_ref  int64 8B 0xarray.DataArray'gam0'sensor: 4time: 14y: 1528x: 2508dask.array&lt;chunksize=(1, 1, 1094, 1094), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n818.65 MiB\n9.13 MiB\n\n\nShape\n(4, 14, 1528, 2508)\n(2, 1, 1094, 1094)\n\n\nDask graph\n252 chunks in 241 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n           4 1                                                          2508 1528 14\n\n\n\n\nCoordinates: (5)x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))time(time)datetime64[ns]2022-06-25 ... 2022-10-15array(['2022-06-25T00:00:00.000000000', '2022-06-25T05:27:26.000000000',\n       '2022-07-07T05:27:27.000000000', '2022-07-19T05:27:28.000000000',\n       '2022-07-31T05:27:29.000000000', '2022-08-12T05:27:29.000000000',\n       '2022-08-20T00:00:00.000000000', '2022-09-05T05:27:31.000000000',\n       '2022-09-17T00:00:00.000000000', '2022-09-17T05:27:31.000000000',\n       '2022-09-29T05:27:31.000000000', '2022-10-01T00:00:00.000000000',\n       '2022-10-11T05:27:31.000000000', '2022-10-15T00:00:00.000000000'],\n      dtype='datetime64[ns]')sensor(sensor)object's1_VH' 's1_VV' 'alos_HH' 'alos_HV'array(['s1_VH', 's1_VV', 'alos_HH', 'alos_HV'], dtype=object)spatial_ref()int640crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0array(0)\n\n\nThe measurements for both satellites donâ€™t occur at the same time. Hence the cube is now padded with 2-D arrays entirely filled with NaN (Not A Number) for some time slices. As we have learned in notebook 2 we can use the resample method to make temporally coherent timeslices for each month. To deal with the dB scale backscatter values as well as the low number of observations per month we use a median of the samples. As taking the median only sorts the samples according to the sample quantiles we do not have to convert the observations to the linear scale.\n\nfused_da = fused_da.resample(time=\"ME\", skipna=True).median().compute()\n\nWe can plot each of the variables: â€œALOS-2â€ and â€œSentinel-1â€ to check our results.\n\nfused_da.hvplot.image(robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True).opts(\n    frame_height=600, aspect=\"equal\"\n)\n\n\n\n\n\n  \n\n\n\n\nFigure 3: Stacked array with ALOS-2 L-band and Sentinel-1 C-band \\(\\gamma^0_T (dB)\\).",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Datacubes</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/05_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/05_in_class_exercise.html",
    "title": "5Â  Wavelength and Polarization",
    "section": "",
    "text": "5.1 Data Loading\nIn this notebook, we aim to demonstrate how C-band (4â€“8 GHz, wavelengths of approximately 3.75â€“7.5 cm) and L-band (1â€“2 GHz, wavelengths of approximately 15â€“30 cm) radio frequencies differ for different land covers and times of the year. In addition, weâ€™ll look at co- and cross-polarized backscattering:\nWe load the data again with the help of intake.\nuri = \"https://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\"\ncat = intake.open_catalog(uri)\nfused_ds = cat.fused.read()\nfused_ds\n\n/home/runner/work/eo-datascience/eo-datascience/.conda_envs/microwave-remote-sensing/lib/python3.11/site-packages/intake/readers/readers.py:1327: UserWarning: The specified chunks separate the stored chunks along dimension \"time\" starting at index 1. This could degrade performance. Instead, consider rechunking after loading.\n  return open_dataset(data.url, **kw)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 460MB\nDimensions:      (time: 5, y: 1528, x: 2508, sensor: 4)\nCoordinates:\n    crs          int64 8B ...\n  * sensor       (sensor) object 32B 's1_VH' 's1_VV' 'alos_HV' 'alos_HH'\n    spatial_ref  int64 8B ...\n  * time         (time) datetime64[ns] 40B 2022-06-30 2022-07-31 ... 2022-10-31\n  * x            (x) float64 20kB 4.769e+06 4.769e+06 ... 4.794e+06 4.794e+06\n  * y            (y) float64 12kB 1.397e+06 1.397e+06 ... 1.382e+06 1.382e+06\nData variables:\n    LAI          (time, y, x) float64 153MB dask.array&lt;chunksize=(1, 1528, 2508), meta=np.ndarray&gt;\n    gam0         (time, sensor, y, x) float32 307MB dask.array&lt;chunksize=(1, 4, 1528, 2508), meta=np.ndarray&gt;xarray.DatasetDimensions:time: 5y: 1528x: 2508sensor: 4Coordinates: (6)crs()int64...GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]][1 values with dtype=int64]sensor(sensor)object's1_VH' 's1_VV' 'alos_HV' 'alos_HH'array(['s1_VH', 's1_VV', 'alos_HV', 'alos_HH'], dtype=object)spatial_ref()int64...GeoTransform :4769370.0 10.0 0.0 1397370.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]][1 values with dtype=int64]time(time)datetime64[ns]2022-06-30 ... 2022-10-31array(['2022-06-30T00:00:00.000000000', '2022-07-31T00:00:00.000000000',\n       '2022-08-31T00:00:00.000000000', '2022-09-30T00:00:00.000000000',\n       '2022-10-31T00:00:00.000000000'], dtype='datetime64[ns]')x(x)float644.769e+06 4.769e+06 ... 4.794e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([4769375., 4769385., 4769395., ..., 4794425., 4794435., 4794445.],\n      shape=(2508,))y(y)float641.397e+06 1.397e+06 ... 1.382e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1397365., 1397355., 1397345., ..., 1382115., 1382105., 1382095.],\n      shape=(1528,))Data variables: (2)LAI(time, y, x)float64dask.array&lt;chunksize=(1, 1528, 2508), meta=np.ndarray&gt;long_name :Leaf Area Index 333mstandard_name :leaf_area_indexunits :m^2/m^2valid_range :[0, 210]\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n146.19 MiB\n29.24 MiB\n\n\nShape\n(5, 1528, 2508)\n(1, 1528, 2508)\n\n\nDask graph\n5 chunks in 2 graph layers\n\n\nData type\nfloat64 numpy.ndarray\n\n\n\n\n                                 2508 1528 5\n\n\n\n\ngam0(time, sensor, y, x)float32dask.array&lt;chunksize=(1, 4, 1528, 2508), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n292.38 MiB\n58.48 MiB\n\n\nShape\n(5, 4, 1528, 2508)\n(1, 4, 1528, 2508)\n\n\nDask graph\n5 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n             5 1                          2508 1528 4\nThe loaded data contains the Leaf Area Index (LAI), which is used as an estimate of foliage cover of forest canopies. So high LAI is interpreted as forested area, whereas low values account for less vegetated areas (shrubs, grass-land, and crops).\nFirst weâ€™ll have a look at the mean and standard deviation of LAI over all timeslices. This can be achieved by using the mean and std methods of the xarray object and by supplying a dimension over which these aggregating operations will be applied. We use the dimension â€œtimeâ€, thereby flattening the cube to a 2-D array with dimensions x and y.\nfig, ax = plt.subplots(1, 2, figsize=(15, 6))\n\nLAI_dc = fused_ds.LAI\nLAI_mean = LAI_dc.mean(\"time\")\nLAI_std = LAI_dc.std(\"time\")\n\nLAI_mean.plot(ax=ax[0], vmin=0, vmax=6).axes.set_aspect(\"equal\")\nLAI_std.plot(ax=ax[1], vmin=0, vmax=3).axes.set_aspect(\"equal\")\nplt.tight_layout()\n\n/home/runner/work/eo-datascience/eo-datascience/.conda_envs/microwave-remote-sensing/lib/python3.11/site-packages/dask/array/numpy_compat.py:57: RuntimeWarning: invalid value encountered in divide\n  x = np.divide(x1, x2, out)\nFigure 1: Map of mean LAI (left) and the associated standard deviation (right) for each pixel over time around Lake Garda.\nIt appears that the northern parts of our study area contain more and variable amounts of green elements per unit area. This might indicate a more complete coverage of foliage and thus forest.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/05_in_class_exercise.html#timeseries",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/05_in_class_exercise.html#timeseries",
    "title": "5Â  Wavelength and Polarization",
    "section": "5.2 Timeseries",
    "text": "5.2 Timeseries\nNow that we have detected possible forested areas, letâ€™s delve a bit deeper into the data. Remember that we deal with a spatiotemporal datacube. This gives us the possibility to study changes for each time increment. Hence we can show what happens to LAI for areas marked with generally low values as well as high values. We can achieve this by filtering the datacube with the where method for areas marked with low and high mean LAI values. In turn we will aggregate the remaining datacube over the spatial dimensions (â€œxâ€ and â€œyâ€) to get a mean values for each time increment.\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 4))\n\nLAI_low = LAI_dc.where(LAI_mean &lt; 4)\nLAI_high = LAI_dc.where(LAI_mean &gt; 4)\n\nLAI_low.mean([\"x\", \"y\"]).plot.scatter(x=\"time\", ax=ax[0], ylim=(0, 6))\nLAI_high.mean([\"x\", \"y\"]).plot.scatter(x=\"time\", ax=ax[1], ylim=(0, 6))\nax[0].set_title(\"Low Mean LAI ($\\\\bar{LAI} &lt; 4$)\")\nax[1].set_title(\"High Mean LAI ($\\\\bar{LAI} &gt; 4$)\")\nplt.tight_layout()\n\n\n\n\n\n\n\n\nFigure 2: Timeseries of mean LAI per timeslice for areas with low (left) and high (right) mean LAI of Figure1.\nNow we can see that areas with high mean LAI values (Figure 1) show a drop-off to values as low as those for areas with low mean LAI during the autumn months (Figure 2 ; right panel). Hence we might deduce that we deal with deciduous forest that becomes less green during autumn, as can be expected for the study area.\nRemember that longer wavelengths like L-bands are more likely to penetrate through a forest canopy and would interact more readily with larger object like tree trunks and the forest floor. In turn, C-band microwaves are more likely to interact with sparse and shrub vegetation. The polarization of the emitted and received microwaves is on the other hand dependent on the type of backscattering with co-polarization (HH and VV) happening more frequently with direct backscatter or double bounce scattering. Whereas volume scattering occurs when the radar signal is subject to multiple reflections within 3-dimensional matter, as the orientation of the main scatterers is random, the polarization of the backscattered signal is also random. Volume scattering can therefore cause an increase of cross-polarized intensity.\nLetâ€™s put this to the test by checking the microwave backscatter signatures over forested and sparsely vegetated areas as well as water bodies (Lake Garda). Letâ€™s first look at the different sensor readings for the beginning of summer and autumn.\n\nhv.output(widget_location=\"bottom\")\n\nt1 = (\n    fused_ds.gam0.isel(time=2)\n    .hvplot.image(\n        robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True, clim=(-25, 0)\n    )\n    .opts(frame_height=400, aspect=\"equal\")\n)\n\nt2 = (\n    fused_ds.gam0.isel(time=-1)\n    .hvplot.image(\n        robust=True, data_aspect=1, cmap=\"Greys_r\", rasterize=True, clim=(-25, 0)\n    )\n    .opts(frame_height=400, aspect=\"equal\")\n)\n\nt1 + t2\n\n\n\n\n\n  \n\n\n\n\nFigure 3: Maps of Sentinel-1 and Alos-2 \\(\\gamma^0_T \\,[dB]\\) for the beginning of summer (left) and autumn (right).\nThe most notable difference is the lower energy received for cross-polarized than for co-polarized microwaves for both Sentinel-1 and Alos-2. The latter differences are independent of the time of year. However, one can also note small changes in the received energy for the same satellite dependent on the time of year. To get a better feel for these changes over time we generate the following interactive plot. On the following plot one can select areas of a certain mean LAI (by clicking on the map) and see the associated timeseries of \\(\\gamma^0_T\\) for each of the sensors.\n\nLAI_image = LAI_mean.hvplot.image(rasterize=True, cmap=\"viridis\", clim=(0, 6)).opts(\n    title=\"Mean LAI (Selectable)\", frame_height=400, aspect=\"equal\"\n)\n\n\ndef get_timeseries(x, y):\n    \"\"\"Callback Function Holoviews\n\n    Parameters\n    ----------\n    x: float\n        numeric value for x selected on LAI map\n    y: float\n        numeric value for y selected on LAI map\n\n    \"\"\"\n    lai_value = LAI_mean.sel(x=x, y=y, method=\"nearest\").values\n\n    if np.isnan(lai_value):\n        select = fused_ds.where(LAI_mean.isnull())\n        label = \"Water\"\n    else:\n        mask = np.isclose(LAI_mean, lai_value, atol=0.05)\n        select = fused_ds.where(mask)\n        label = \"Mean LAI: \" + str(np.round(lai_value, 1))\n\n    time_series = (\n        select.gam0.to_dataset(\"sensor\")\n        .median([\"x\", \"y\"], skipna=True)\n        .hvplot.scatter(ylim=(-30, 5))\n        .opts(title=label, frame_height=400)\n    )\n\n    return time_series\n\n\npoint_stream = hv.streams.SingleTap(source=LAI_image)\ntime_series = hv.DynamicMap(get_timeseries, streams=[point_stream])\nLAI_image + time_series\n\nWARNING:param.RasterPlot01207: Due to internal constraints, when aspect and width/height is set, the bokeh backend uses those values as frame_width/frame_height instead. This ensures the aspect is respected, but means that the plot might be slightly larger than anticipated. Set the frame_width/frame_height explicitly to suppress this warning.\n\n\n\n\n\n\n  \n\n\n\n\nFigure 4: Map of MEAN LAI around Lake Garda. The pixel values can be seen by hovering your mouse over the pixels. Clicking on the pixel will generate the timeseries for the associated mean LAI on the right hand-side. (Right) Timeseries of for Sentinel-1 and Alos-2 \\(\\gamma^0_T [dB]\\).\nCan you see some patterns when analyzing the different wavelengths and polarizations?\nRemember again that we deal with a logarithmic scale. A measurement of 10 dB is 10 times brighter than the intensity measured at 0 dB, and 100 times brighter at 20 dB. The most notable difference is that the offset between cross- and co-polarised signals becomes larger at low LAI and lower at higher LAI. This might indicate the effect of volume scattering in forested areas where co- and cross-polarization render backscattering values more equal. You will study the differences among cross- and co-polarized backscattering in more detail in the homework exercise.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>Wavelength and Polarization</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html",
    "title": "6Â  Dielectric Properties",
    "section": "",
    "text": "6.1 Load Sentinel-1 Data\nIn this notebook, we will investigate the varying backscatter values associated with different land surfaces like water bodies, forests, grasslands and urban areas. We will use backscatter data from the Sentinel-1 satellite and we will utilize the CORINE Land Cover dataset to classify and extrapolate these surfaces, enabling us to analyze how different land cover types influence backscatter responses.\nFor our analysis we are using sigma naught backscatering data from Sentinel-1. The images we are analyzing cover the region south of Vienna and west of Lake Neusiedl. We load the data and and apply again a preprocessing function. Here we extract the scaling factor and the date the image was taken from the metadata. We will focus our attention to a smaller area containing a part of the Lake Neusiedl Lake and its surrounding land. The obtainedxarray dataset and is then converted to an array, because we only have one variable, the VV backscatter values.\nuri = \"https://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\"\ncat = intake.open_catalog(uri)\nsig0_da = cat.neusiedler.read().sig0.compute()\nLetâ€™s have a look at the data by plotting the first timeslice.\nsig0_da.isel(time=0).plot(robust=True, cmap=\"Greys_r\").axes.set_aspect(\"equal\")",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Dielectric Properties</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html#load-corine-landcover-data",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html#load-corine-landcover-data",
    "title": "6Â  Dielectric Properties",
    "section": "6.2 Load CORINE Landcover Data",
    "text": "6.2 Load CORINE Landcover Data\nWe will load the CORINE Land Cover, which is a pan-European land cover and land use inventory with 44 thematic classes. The resolution of this classification is 100 by 100m and the file was created in 2018 (CORINE Land Cover).\n\ncor_da = cat.corine.read().land_cover.compute()\n\n\n6.2.1 Colormapping and Encoding\nFor the different land cover types we use the official color encoding which can be found in CORINE Land Cover.\n\n# Load encoding\nwith cat.corine_cmap.read()[0] as f:\n    color_mapping_data = json.load(f)\n\n# Get mapping\ncolor_mapping = {item[\"value\"]: item for item in color_mapping_data[\"land_cover\"]}\n\n# Create cmap and norm for plotting\ncolors = [info[\"color\"] for info in color_mapping.values()]\ncategories = [info[\"value\"] for info in color_mapping.values()]\ncmap = ListedColormap(colors)\nnorm = BoundaryNorm(categories + [max(categories) + 1], len(categories))\n\nNow we can plot the CORINE Land Cover dataset.\n\n# Get landcover codes present in the image\npresent_landcover_codes = np.unique(cor_da.values[~np.isnan(cor_da.values)].astype(int))\n\n# Get colors + text for legend\nhandles = [\n    mpatches.Patch(color=info[\"color\"], label=(f\"{info['value']} - \" + (info[\"label\"])))\n    for info in color_mapping.values()\n    if info[\"value\"] in present_landcover_codes\n]\n\n# Create the plot\ncor_da.plot(figsize=(10, 10), cmap=cmap, norm=norm, add_colorbar=False).axes.set_aspect(\n    \"equal\"\n)\n\nplt.legend(\n    handles=handles,\n    bbox_to_anchor=(1.01, 1),\n    loc=\"upper left\",\n    borderaxespad=0,\n    fontsize=7,\n)\nplt.title(\"CORINE Land Cover (EPSG:27704)\")\n\nText(0.5, 1.0, 'CORINE Land Cover (EPSG:27704)')\n\n\n\n\n\n\n\n\n\nNow we are ready to merge the backscatter data (sig0_da) with the land cover dataset (cor_da) to have one dataset combining all data.\n\nvar_ds = xr.merge([sig0_da, cor_da]).drop_vars(\"band\")\nvar_ds\n\n/tmp/ipykernel_3823/125755716.py:1: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  var_ds = xr.merge([sig0_da, cor_da]).drop_vars(\"band\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 108MB\nDimensions:      (time: 8, x: 1230, y: 1221)\nCoordinates:\n    spatial_ref  int64 8B 0\n  * time         (time) datetime64[ns] 64B 2023-08-05T16:51:22 ... 2023-10-28...\n  * x            (x) float64 10kB 5.282e+06 5.282e+06 ... 5.294e+06 5.294e+06\n  * y            (y) float64 10kB 1.571e+06 1.571e+06 ... 1.559e+06 1.559e+06\nData variables:\n    sig0         (time, y, x) float64 96MB -6.99 -7.32 -8.78 ... -14.32 -14.22\n    land_cover   (y, x) float64 12MB 12.0 12.0 12.0 12.0 ... 41.0 41.0 41.0 41.0xarray.DatasetDimensions:time: 8x: 1230y: 1221Coordinates: (4)spatial_ref()int640GeoTransform :5281990.0 10.0 0.0 1570960.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)time(time)datetime64[ns]2023-08-05T16:51:22 ... 2023-10-...array(['2023-08-05T16:51:22.000000000', '2023-08-17T16:51:22.000000000',\n       '2023-08-29T16:51:23.000000000', '2023-09-10T16:51:24.000000000',\n       '2023-09-22T16:51:24.000000000', '2023-10-04T16:51:24.000000000',\n       '2023-10-16T16:51:24.000000000', '2023-10-28T16:51:24.000000000'],\n      dtype='datetime64[ns]')x(x)float645.282e+06 5.282e+06 ... 5.294e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([5281995., 5282005., 5282015., ..., 5294265., 5294275., 5294285.],\n      shape=(1230,))y(y)float641.571e+06 1.571e+06 ... 1.559e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1570955., 1570945., 1570935., ..., 1558775., 1558765., 1558755.],\n      shape=(1221,))Data variables: (2)sig0(time, y, x)float64-6.99 -7.32 -8.78 ... -14.32 -14.22array([[[ -6.99,  -7.32,  -8.78, ..., -26.06, -21.29, -18.64],\n        [ -6.37,  -8.79,  -8.78, ..., -26.2 , -21.8 , -21.18],\n        [ -6.96,  -8.36,  -9.  , ..., -26.2 , -24.44, -24.31],\n        ...,\n        [ -7.82,  -4.94,  -4.8 , ...,  -8.78,  -8.02,  -7.3 ],\n        [ -7.41,  -9.33,  -8.67, ..., -10.69,  -6.36,  -5.22],\n        [-11.11, -11.8 , -11.55, ..., -14.89,  -6.95,  -3.89]],\n\n       [[ -8.5 , -10.65, -12.07, ..., -22.27, -20.91, -21.92],\n        [ -9.  , -10.03, -10.82, ..., -16.46, -16.9 , -21.84],\n        [ -6.74,  -7.87,  -8.1 , ..., -17.41, -22.64, -23.01],\n        ...,\n        [ -8.74,  -7.44,  -6.69, ..., -10.85,  -8.39,  -7.08],\n        [ -9.39,  -9.55,  -8.9 , ..., -13.  , -11.03,  -9.15],\n        [-10.86, -10.84,  -9.7 , ..., -17.47, -14.58, -10.65]],\n\n       [[-10.39, -11.92, -11.74, ..., -19.02, -20.28, -17.92],\n        [ -8.65, -14.64, -12.34, ..., -21.77, -19.55, -16.67],\n        [ -8.11, -11.29, -10.25, ..., -23.16, -20.23, -16.73],\n        ...,\n...\n        [ -9.82,  -9.11,  -8.73, ...,  -9.79,  -7.33,  -6.92],\n        [-12.23, -11.64,  -9.59, ..., -12.29,  -7.65,  -8.14],\n        [-13.6 , -13.41, -11.73, ..., -19.82, -12.53, -11.83]],\n\n       [[-12.49, -12.55, -12.89, ..., -21.35, -23.29, -23.87],\n        [-12.15, -12.38, -14.03, ..., -18.07, -23.53, -23.23],\n        [-12.41, -12.52, -14.08, ..., -18.7 , -21.47, -22.17],\n        ...,\n        [ -6.87,  -5.98,  -5.32, ..., -18.47, -12.26, -11.2 ],\n        [-11.18,  -6.31,  -6.12, ..., -20.17, -12.56, -11.61],\n        [-11.98,  -9.02,  -8.46, ..., -13.06, -10.4 ,  -9.  ]],\n\n       [[ -6.41,  -6.59,  -7.16, ..., -22.25, -25.96, -25.45],\n        [ -6.75,  -9.42,  -9.54, ..., -20.65, -26.34, -23.53],\n        [ -8.24, -12.04, -10.46, ..., -20.65, -20.63, -21.05],\n        ...,\n        [ -6.64,  -5.06,  -4.89, ..., -13.67, -12.26,  -9.96],\n        [ -9.62,  -8.06, -10.02, ..., -16.11, -14.74, -10.64],\n        [-11.93, -11.41, -12.68, ..., -19.01, -14.32, -14.22]]],\n      shape=(8, 1221, 1230))land_cover(y, x)float6412.0 12.0 12.0 ... 41.0 41.0 41.0AREA_OR_POINT :AreaDataType :ThematicRepresentationType :THEMATICSTATISTICS_COVARIANCES :136.429646247598STATISTICS_MAXIMUM :48STATISTICS_MEAN :25.753373398066STATISTICS_MINIMUM :1STATISTICS_SKIPFACTORX :1STATISTICS_SKIPFACTORY :1STATISTICS_STDDEV :11.680310194836array([[12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       ...,\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.]], shape=(1221, 1230))",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Dielectric Properties</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html#backscatter-variability",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html#backscatter-variability",
    "title": "6Â  Dielectric Properties",
    "section": "6.3 Backscatter Variability",
    "text": "6.3 Backscatter Variability\nWith this combined dataset we can study backscatter variability in relation to natural media. For example we can look at the backscatter variability for water by clipping the dataset to only contain the land cover class water, like so:\n\n# 41 = encoded value for water bodies\nwaterbodies_mask = var_ds.land_cover == 41\nwaterbodies_mask.plot().axes.set_aspect(\"equal\")\n\n\n\n\n\n\n\n\nThis gives use backscatter values over water only.\n\nwaterbodies_sig0 = var_ds.sig0.isel(time=0).where(waterbodies_mask)\nwaterbodies_sig0.plot(robust=True, cmap=\"Greys_r\").axes.set_aspect(\"equal\")\n\n\n\n\n\n\n\n\nTo get an idea of the variability we can create a histogram. Radar backscatter from water bodies fluctuates with surface roughness, which changes with wind conditions, creating spatial and temporal variations in signal intensity.\n\nwaterbodies_sig0.plot.hist(bins=50, edgecolor=\"black\")\n\n(array([5.0000e+00, 5.0000e+00, 8.0000e+00, 1.4000e+01, 3.5000e+01,\n        7.8000e+01, 1.5600e+02, 3.0500e+02, 5.4000e+02, 1.0380e+03,\n        1.9550e+03, 3.6850e+03, 6.9910e+03, 1.2269e+04, 1.9088e+04,\n        2.6859e+04, 3.6217e+04, 4.5276e+04, 5.0939e+04, 4.9020e+04,\n        3.9729e+04, 2.5400e+04, 1.2426e+04, 5.4390e+03, 2.6990e+03,\n        2.0500e+03, 2.1330e+03, 2.6890e+03, 3.1490e+03, 3.9510e+03,\n        4.2970e+03, 4.1110e+03, 3.6350e+03, 2.5900e+03, 1.6020e+03,\n        7.5000e+02, 3.5200e+02, 1.2300e+02, 5.6000e+01, 3.7000e+01,\n        2.8000e+01, 2.1000e+01, 1.3000e+01, 9.0000e+00, 1.0000e+01,\n        8.0000e+00, 1.0000e+01, 5.0000e+00, 6.0000e+00, 4.0000e+00]),\n array([-37.91  , -36.9202, -35.9304, -34.9406, -33.9508, -32.961 ,\n        -31.9712, -30.9814, -29.9916, -29.0018, -28.012 , -27.0222,\n        -26.0324, -25.0426, -24.0528, -23.063 , -22.0732, -21.0834,\n        -20.0936, -19.1038, -18.114 , -17.1242, -16.1344, -15.1446,\n        -14.1548, -13.165 , -12.1752, -11.1854, -10.1956,  -9.2058,\n         -8.216 ,  -7.2262,  -6.2364,  -5.2466,  -4.2568,  -3.267 ,\n         -2.2772,  -1.2874,  -0.2976,   0.6922,   1.682 ,   2.6718,\n          3.6616,   4.6514,   5.6412,   6.631 ,   7.6208,   8.6106,\n          9.6004,  10.5902,  11.58  ]),\n &lt;BarContainer object of 50 artists&gt;)",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Dielectric Properties</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html#variability-over-time",
    "href": "chapters/courses/microwave-remote-sensing/unit_02/06_in_class_exercise.html#variability-over-time",
    "title": "6Â  Dielectric Properties",
    "section": "6.4 Variability over Time",
    "text": "6.4 Variability over Time\nNext we will look at the changes in variability in backscatter values over time for each of the CORINE Land Cover types. We do this by creating the following interactive plot. We can spot that backscatter in agricultural fields varies due to seasonal cycles like planting, growing, and harvesting, each of which changes vegetation structure. Changes in backscatter are strongly related to soil moisture content from irrigation or rainfall. Ultimately, phenological stages of crops and canopy moisture dynamics can affect the backscatter signal.\n\nrobust_min = var_ds.sig0.quantile(0.02).item()\nrobust_max = var_ds.sig0.quantile(0.98).item()\n\nbin_edges = [\n    i + j * 0.5\n    for i in range(int(robust_min) - 2, int(robust_max) + 2)\n    for j in range(2)\n]\n\nland_cover = {\"\\xa0\\xa0\\xa0 Complete Land Cover\": 1}\nland_cover.update(\n    {\n        f\"{int(value): 02} {color_mapping[value]['label']}\": int(value)\n        for value in present_landcover_codes\n    }\n)\ntime = var_ds.sig0[\"time\"].values\n\nrangexy = RangeXY()\n\n\ndef load_image(time, land_cover, x_range, y_range):\n    \"\"\"Callback Function Landcover.\n\n    Parameters\n    ----------\n    time: panda.datatime\n        time slice\n    landcover: int\n        land cover type\n    x_range: array_like\n        longitude range\n    y_range: array_like\n        latitude range\n\n    Returns\n    -------\n    holoviews.Image\n\n    \"\"\"\n    if land_cover == \"\\xa0\\xa0\\xa0 Complete Land Cover\":\n        sig0_selected_ds = var_ds.sig0.sel(time=time)\n\n    else:\n        land_cover_value = int(land_cover.split()[0])\n        mask_ds = var_ds.land_cover == land_cover_value\n        sig0_selected_ds = var_ds.sig0.sel(time=time).where(mask_ds)\n\n    hv_ds = hv.Dataset(sig0_selected_ds)\n    img = hv_ds.to(hv.Image, [\"x\", \"y\"])\n\n    if x_range and y_range:\n        img = img.select(x=x_range, y=y_range)\n\n    return hv.Image(img)\n\n\ndmap = (\n    hv.DynamicMap(load_image, kdims=[\"Time\", \"Landcover\"], streams=[rangexy])\n    .redim.values(Time=time, Landcover=land_cover)\n    .hist(normed=True, bins=bin_edges)\n)\n\nimage_opts = hv.opts.Image(\n    cmap=\"Greys_r\",\n    colorbar=True,\n    tools=[\"hover\"],\n    clim=(robust_min, robust_max),\n    aspect=\"equal\",\n    framewise=False,\n    frame_height=500,\n    frame_width=500,\n)\n\nhist_opts = hv.opts.Histogram(width=350, height=555)\n\ndmap.opts(image_opts, hist_opts)",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Dielectric Properties</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/07_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/07_in_class_exercise.html",
    "title": "7Â  Speckle Statistics",
    "section": "",
    "text": "7.1 Lake Neusiedl data\nThis notebook will provide an empirical demonstration of speckle - how it originates, how it visually and statistically looks like, and some of the most common approaches to filter it.\nSpeckle is defined as a kind of noise that affects all radar images. Given the multiple scattering contributions originating from the various elementary objects present within a resolution cell, the resulting backscatter signal can be described as a random constructive and destructive interference of wavelets. As a consequence, speckle is the reason why a granular pattern normally affects SAR images, making it more challenging to interpret and analyze them.\nCredits: ESRI\nLetâ€™s make an example of a cornfield (with a typical backscattering value of about -10 dB). According to the following equation:\n\\[\n\\sigma^0 = \\frac{1}{\\text{area}} \\sum_{n \\in \\text{area}} \\sigma_n\n\\]\nWe should ideally have a uniform discrete sigma naught \\(\\sigma^0\\) value, given that the cornfield pixel is the only individual contributor.\nHowever, since we already learned from the previous notebooks that a pixelâ€™s ground size can be in the order of tens of meters (i.e., 10 meters for Sentinel-1), we can imagine that different distributed targets in the scene contribute to the global backscattered information.\nLetÂ´s replicate this behavior with an ideal uniform area constituted by 100 pixels and then by adding 30% of speckle.\nFigure 1: Synthetic data that emulates speckles in microwave backscattering\nWe can imagine that the second plot represents a real SAR acquisition over a cornfield, while the first plot represents an ideal uniform SAR image over a cornfield land (no speckle). The introduction of a simulated 30% speckle noise could be related to the presence of distributed scatterers of any sort present in the scene, which would cause a pixel-to-pixel variation in terms of intensity.\nAll the random contributions (such as the wind) would result in a different speckle pattern each time a SAR scene is acquired over the same area. Many subpixel contributors build up a complex scattered pattern in any SAR image, making it erroneous to rely on a single pixel intensity for making reliable image analysis. In order to enhance the degree of usability of a SAR image, several techniques have been put in place to mitigate speckle. We will now show two of the most common approaches: the temporal and the spatial filter.\nWe load a dataset that contains the CORINE land cover and Sentinel-1 \\(\\sigma^0_E\\) at a 20 meter resolution. This is the same data presented in notebook 6.\nuri = \"https://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\"\ncat = intake.open_catalog(uri)\nfused_ds = cat.speckle.read().compute()\nfused_ds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 108MB\nDimensions:      (y: 1221, x: 1230, time: 8)\nCoordinates:\n    spatial_ref  int64 8B 0\n  * time         (time) datetime64[ns] 64B 2023-08-05T16:51:22 ... 2023-10-28...\n  * x            (x) float64 10kB 5.282e+06 5.282e+06 ... 5.294e+06 5.294e+06\n  * y            (y) float64 10kB 1.571e+06 1.571e+06 ... 1.559e+06 1.559e+06\nData variables:\n    land_cover   (y, x) float64 12MB 12.0 12.0 12.0 12.0 ... 41.0 41.0 41.0 41.0\n    sig0         (time, y, x) float64 96MB -6.99 -7.32 -8.78 ... -14.32 -14.22xarray.DatasetDimensions:y: 1221x: 1230time: 8Coordinates: (4)spatial_ref()int640GeoTransform :5281990.0 10.0 0.0 1570960.0 0.0 -10.0crs_wkt :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]false_easting :5837287.81977false_northing :2121415.69617geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984inverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :Azimuthal_Equidistantreference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH]]array(0)time(time)datetime64[ns]2023-08-05T16:51:22 ... 2023-10-...array(['2023-08-05T16:51:22.000000000', '2023-08-17T16:51:22.000000000',\n       '2023-08-29T16:51:23.000000000', '2023-09-10T16:51:24.000000000',\n       '2023-09-22T16:51:24.000000000', '2023-10-04T16:51:24.000000000',\n       '2023-10-16T16:51:24.000000000', '2023-10-28T16:51:24.000000000'],\n      dtype='datetime64[ns]')x(x)float645.282e+06 5.282e+06 ... 5.294e+06axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinateunits :metrearray([5281995., 5282005., 5282015., ..., 5294265., 5294275., 5294285.],\n      shape=(1230,))y(y)float641.571e+06 1.571e+06 ... 1.559e+06axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinateunits :metrearray([1570955., 1570945., 1570935., ..., 1558775., 1558765., 1558755.],\n      shape=(1221,))Data variables: (2)land_cover(y, x)float6412.0 12.0 12.0 ... 41.0 41.0 41.0AREA_OR_POINT :AreaDataType :ThematicRepresentationType :THEMATICSTATISTICS_COVARIANCES :136.429646247598STATISTICS_MAXIMUM :48STATISTICS_MEAN :25.753373398066STATISTICS_MINIMUM :1STATISTICS_SKIPFACTORX :1STATISTICS_SKIPFACTORY :1STATISTICS_STDDEV :11.680310194836array([[12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       [12., 12., 12., ..., 41., 41., 41.],\n       ...,\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.],\n       [ 2.,  2.,  2., ..., 41., 41., 41.]], shape=(1221, 1230))sig0(time, y, x)float64-6.99 -7.32 -8.78 ... -14.32 -14.22array([[[ -6.99,  -7.32,  -8.78, ..., -26.06, -21.29, -18.64],\n        [ -6.37,  -8.79,  -8.78, ..., -26.2 , -21.8 , -21.18],\n        [ -6.96,  -8.36,  -9.  , ..., -26.2 , -24.44, -24.31],\n        ...,\n        [ -7.82,  -4.94,  -4.8 , ...,  -8.78,  -8.02,  -7.3 ],\n        [ -7.41,  -9.33,  -8.67, ..., -10.69,  -6.36,  -5.22],\n        [-11.11, -11.8 , -11.55, ..., -14.89,  -6.95,  -3.89]],\n\n       [[ -8.5 , -10.65, -12.07, ..., -22.27, -20.91, -21.92],\n        [ -9.  , -10.03, -10.82, ..., -16.46, -16.9 , -21.84],\n        [ -6.74,  -7.87,  -8.1 , ..., -17.41, -22.64, -23.01],\n        ...,\n        [ -8.74,  -7.44,  -6.69, ..., -10.85,  -8.39,  -7.08],\n        [ -9.39,  -9.55,  -8.9 , ..., -13.  , -11.03,  -9.15],\n        [-10.86, -10.84,  -9.7 , ..., -17.47, -14.58, -10.65]],\n\n       [[-10.39, -11.92, -11.74, ..., -19.02, -20.28, -17.92],\n        [ -8.65, -14.64, -12.34, ..., -21.77, -19.55, -16.67],\n        [ -8.11, -11.29, -10.25, ..., -23.16, -20.23, -16.73],\n        ...,\n...\n        [ -9.82,  -9.11,  -8.73, ...,  -9.79,  -7.33,  -6.92],\n        [-12.23, -11.64,  -9.59, ..., -12.29,  -7.65,  -8.14],\n        [-13.6 , -13.41, -11.73, ..., -19.82, -12.53, -11.83]],\n\n       [[-12.49, -12.55, -12.89, ..., -21.35, -23.29, -23.87],\n        [-12.15, -12.38, -14.03, ..., -18.07, -23.53, -23.23],\n        [-12.41, -12.52, -14.08, ..., -18.7 , -21.47, -22.17],\n        ...,\n        [ -6.87,  -5.98,  -5.32, ..., -18.47, -12.26, -11.2 ],\n        [-11.18,  -6.31,  -6.12, ..., -20.17, -12.56, -11.61],\n        [-11.98,  -9.02,  -8.46, ..., -13.06, -10.4 ,  -9.  ]],\n\n       [[ -6.41,  -6.59,  -7.16, ..., -22.25, -25.96, -25.45],\n        [ -6.75,  -9.42,  -9.54, ..., -20.65, -26.34, -23.53],\n        [ -8.24, -12.04, -10.46, ..., -20.65, -20.63, -21.05],\n        ...,\n        [ -6.64,  -5.06,  -4.89, ..., -13.67, -12.26,  -9.96],\n        [ -9.62,  -8.06, -10.02, ..., -16.11, -14.74, -10.64],\n        [-11.93, -11.41, -12.68, ..., -19.01, -14.32, -14.22]]],\n      shape=(8, 1221, 1230))\nWe also create the same dashboard for backscatter of different landcover types over time. In order to make this code reusable and adaptable we will define the following function plot_variability, which allows the injection of a spatial and/or temporal filter. It is not important to understand all the code of the following cell!\n# Load encoding\nwith cat.corine_cmap.read()[0] as f:\n    color_mapping_data = json.load(f)\n\n# Get mapping\ncolor_mapping = {item[\"value\"]: item for item in color_mapping_data[\"land_cover\"]}\n\n# Get landcover codes present in the image\npresent_landcover_codes = np.unique(\n    fused_ds.land_cover.values[~np.isnan(fused_ds.land_cover.values)].astype(int)\n)\n\n\ndef load_image(var_ds, time, land_cover, x_range, y_range, filter_fun_spatial=None):\n    \"\"\"Callback Function Landcover.\n\n    Parameters\n    ----------\n    time: panda.datetime\n        time slice\n    landcover: int\n        land cover type\n    x_range: array_like\n        longitude range\n    y_range: array_like\n        latitude range\n\n    Returns\n    -------\n    holoviews.Image\n\n    \"\"\"\n    if time is not None:\n        var_ds = var_ds.sel(time=time)\n\n    if land_cover == \"\\xa0\\xa0\\xa0 Complete Land Cover\":\n        sig0_selected_ds = var_ds.sig0\n    else:\n        land_cover_value = int(land_cover.split()[0])\n        mask_ds = var_ds.land_cover == land_cover_value\n        sig0_selected_ds = var_ds.sig0.where(mask_ds)\n\n    if filter_fun_spatial is not None:\n        sig0_np = filter_fun_spatial(sig0_selected_ds.values)\n    else:\n        sig0_np = sig0_selected_ds.values\n\n    # Convert unfiltered data into Holoviews Image\n    img = hv.Dataset(\n        (sig0_selected_ds[\"x\"], sig0_selected_ds[\"y\"], sig0_np), [\"x\", \"y\"], \"sig0\"\n    )\n\n    if x_range and y_range:\n        img = img.select(x=x_range, y=y_range)\n\n    return hv.Image(img)\n\n\ndef plot_variability(var_ds, filter_fun_spatial=None, filter_fun_temporal=None):\n    robust_min = var_ds.sig0.quantile(0.02).item()\n    robust_max = var_ds.sig0.quantile(0.98).item()\n\n    bin_edges = [\n        i + j * 0.5\n        for i in range(int(robust_min) - 2, int(robust_max) + 2)\n        for j in range(2)\n    ]\n\n    land_cover = {\"\\xa0\\xa0\\xa0 Complete Land Cover\": 1}\n    land_cover.update(\n        {\n            f\"{int(value): 02} {color_mapping[value]['label']}\": int(value)\n            for value in present_landcover_codes\n        }\n    )\n    time = var_ds.sig0[\"time\"].values\n\n    rangexy = RangeXY()\n\n    if filter_fun_temporal is not None:\n        var_ds = filter_fun_temporal(var_ds)\n        load_image_ = partial(\n            load_image, var_ds=var_ds, filter_fun_spatial=filter_fun_spatial, time=None\n        )\n        dmap = (\n            hv.DynamicMap(load_image_, kdims=[\"Landcover\"], streams=[rangexy])\n            .redim.values(Landcover=land_cover)\n            .hist(normed=True, bins=bin_edges)\n        )\n\n    else:\n        load_image_ = partial(\n            load_image, var_ds=var_ds, filter_fun_spatial=filter_fun_spatial\n        )\n        dmap = (\n            hv.DynamicMap(load_image_, kdims=[\"Time\", \"Landcover\"], streams=[rangexy])\n            .redim.values(Time=time, Landcover=land_cover)\n            .hist(normed=True, bins=bin_edges)\n        )\n\n    image_opts = hv.opts.Image(\n        cmap=\"Greys_r\",\n        colorbar=True,\n        tools=[\"hover\"],\n        clim=(robust_min, robust_max),\n        aspect=\"equal\",\n        framewise=False,\n        frame_height=500,\n        frame_width=500,\n    )\n\n    hist_opts = hv.opts.Histogram(width=350, height=555)\n\n    return dmap.opts(image_opts, hist_opts)\nNow, lets work on the real-life dataset to see how speckle actually looks like.\nplot_variability(fused_ds)\nFigure 2: Lake Neusiedl \\(\\sigma^0_E\\) without any filter.\nThe speckle noise typically appears as a â€œsalt-and-pepperâ€ pattern. Also, please note the distribution of backscatter for each land cover. Even though speckle is known for following non-normal distributions (i.e., Rayleigh distribution for amplitude in the linear domain, and the Gumple for intensity in the log domain), we can assume that due to the Central Limit Theorem, the overall backscatter means (dB) tend to follow a Gaussian distribution.\nWe can mitigate speckle (it is impossible to remove it completely) by following approaches such as: - spatial filtering - taking mean backscatter value over the same land cover, or - temporal filtering - taking the average backscatter value over some time period.\nEither way, one pixel is never representative of ground truth! Therefore we need to look at samples and distributions.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/07_in_class_exercise.html#spatial-filtering",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/07_in_class_exercise.html#spatial-filtering",
    "title": "7Â  Speckle Statistics",
    "section": "7.2 Spatial filtering",
    "text": "7.2 Spatial filtering\nWe first introduce a common spatial filter. The Lee filter is an adaptive speckle filter. The filter works using a kernel window with a configurable size, which refers to the dimensions of the neighborhood over which the filter operates. The kernel slides across the data, applying the smoothing operation at each pixel position of the image. It follows three assumptions:\n\nSAR speckle is modeled as a multiplicative noise - the brighter the area the noisier the data.\nThe noise and the signal are statistically independent of each other.\nThe sample mean and sample variance of a pixel is equal to its local mean and local variance.\n\nThis approach comes with some limitations: it reduces the spatial resolution of the SAR image.\nLetâ€™s build up a function for applying a Lee filter with a kernel window size of 7 (do not forget to switch back to linear units before doing this computation and to dB after it):\n\ndef lee_filter(raster, size=7):\n    \"\"\"Parameters\n    raster: ndarray\n        2D array representing the noisy image (e.g., radar image with speckle)\n    size: int\n        Size of the kernel window for the filter (must be odd, default is 7)\n\n    Returns\n    -------\n    filtered_image (ndarray): The filtered image with reduced speckle noise\n\n    \"\"\"\n    raster = np.nan_to_num(raster)\n    raster = 10 ** (raster / 10)\n\n    # Mean and variance over local kernel window\n    mean_window = uniform_filter(raster, size=size)\n    mean_sq_window = uniform_filter(raster**2, size=size)\n    variance_window = mean_sq_window - mean_window**2\n\n    # Noise variance estimation (this could also be set manually)\n    overall_variance = np.var(raster)\n\n    # Compute the Lee filter\n    weights = variance_window / (variance_window + overall_variance)\n\n    return 10 * np.log10(mean_window + weights * (raster - mean_window))\n\n\nplot_variability(fused_ds, filter_fun_spatial=lee_filter)\n\n\n\n\n\n  \n\n\n\n\nFigure 3: Lake Neusiedl \\(\\sigma^0_E\\) with a Lee filter applied.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/07_in_class_exercise.html#temporal-filtering",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/07_in_class_exercise.html#temporal-filtering",
    "title": "7Â  Speckle Statistics",
    "section": "7.3 Temporal filtering",
    "text": "7.3 Temporal filtering\nTemporal filtering would involve taking the average of all previous (past) observations for each pixel. This approach comes with some limitations: it takes out the content-rich information tied to the temporal variability of backscatter.\n\ndef temporal_filter(raster):\n    \"\"\"Parameters\n    raster: ndarray\n        3D array representing the noisy image over time\n        (e.g., radar image with speckle)\n\n    Returns\n    -------\n    filtered_image (ndarray): The filtered image with reduced speckle noise\n\n    \"\"\"\n    return raster.mean(\"time\")\n\n\nplot_variability(fused_ds, filter_fun_temporal=temporal_filter)\n\n\n\n\n\n  \n\n\n\n\nFigure 4: Lake Neusiedl \\(\\sigma^0_E\\) with a temporal filter applied.\nLetÂ´s observe the histograms of the two plots. Especially in the region around the lake, it is clear that the distribution is now less dispersed and more centered around a central value.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Speckle Statistics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html",
    "title": "8Â  Interferograms",
    "section": "",
    "text": "8.1 Single Look Complex (SLC) Data\nOn July 5th, 2019, an earthquake with a magnitude of 7.1 mainshock struck eastern California, near the city of Ridgecrest. The seismic event produced a surface rupture spanning more than 50 kilometers with a complex vertical and horizontal offset pattern along the main fault line. SAR imagery can be employed for accurately measuring and describing ground motion through a well-established technique called SAR Interferometry. In this framework, the phase information contained in Synthetic Aperture Radar (SAR) data is employed. In this notebook, we will dive into the main interferometric SAR processing operations which involves retrieving the difference between the phase signals of repeated SAR acquisitions to analyze the shape and deformation of the Earthâ€™s surface. In our case, we will use a pair of Single Look Complex (SLC) Sentinel-1 images to obtain an interferogram of the Ridgecrest earthquake.\nThis notebook will outline the process of working with interferograms and the steps needed to extract valuable information. Here, we will focus on displaying products generated by the Sentinel Application Platform (SNAP) software from the European Space Agency (ESA).\nPhoto by Brian Olson / California Geological Survey\nWe introduce now another level-1 radar product type, which is called Single Look Complex (SLC). Interferometry can only be performed with SLC data. What are the main differences between SLC and GRD (the other level-1 radar product)? + SLC vs GRD: + SLC contains complex-value data (amplitude and phase) vs GRD contains intensity only (amplitude) + SLC geometry is Slant Range (radarâ€™s line of sight) vs GRD data are projected onto ground range + SLC resolution is full vs GRD has lower resolution (it is multi-looked) + SLC supports phase-based applications (Interferometry) vs GRD supports only amplitude-based ones + SLC has larger file sizes compared to GRD\nuri = \"https://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\"\ncat = intake.open_catalog(uri)\niw1_ds = cat.iw1.read()\niw2_ds = cat.iw2.read()\niw3_ds = cat.iw3.read()\nLetâ€™s plot all three sub-swaths to view the full scene acquired by the satellite. The acquisition times for each swath on July 10th, 2019 are the following: - IW1 at 01:50:01 - 01:50:26 - IW2 at 01:49:59 - 01:50:24 - IW3 at 01:50:00 - 01:50:25\nfig, ax = plt.subplots(1, 3, figsize=(15, 7), sharey=True)\n\ndatasets = [iw1_ds, iw2_ds, iw3_ds]\nval_range = dict(vmin=0, vmax=255, cmap=\"gray\")\n\nfor i, ds in enumerate(datasets):\n    im = ds.intensity.plot(ax=ax[i], add_colorbar=False, **val_range)\n    ax[i].tick_params(axis=\"both\", which=\"major\")\n\ncbar = fig.colorbar(im, ax=ax, orientation=\"horizontal\", shrink=0.9, pad=0.2)\n\nplt.show()\nWe donâ€™t need all three of the subswaths for our notebook, so we will focus on IW2 and display its intensity and phase measurements.\n# Compute the intensity and phase from complex data\ncmap_hls = sns.hls_palette(as_cmap=True)\n\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\nds.intensity.plot(ax=axes[0], cmap=\"gray\", robust=True)\naxes[0].set_title(\"Intensity Measurement of IW2\")\n\nds.phase.plot(ax=axes[1], cmap=cmap_hls)\naxes[1].set_title(\"Phase Measurement of IW2\")\n\nplt.tight_layout()\nIntensity is represented in an 8-bit format (ranging from 0 to 255), while phase measurements range from \\(- \\pi\\) to \\(\\pi\\) . At first glance, phase does not correspond to easily observable physical properties of the ground. However, the phase becomes incredibly valuable when, for example, it is used comparatively between two successive phase measurements (two Sentinel-1 images acquired at different times over the same area). Here are the processing steps needed to retrieve a difference between the phases of two radar acquisitions:",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#coregistering",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#coregistering",
    "title": "8Â  Interferograms",
    "section": "8.2 Coregistering",
    "text": "8.2 Coregistering\nBefore creating an interferogram, measurements from two different dates need to be coregistered. This means that each pixel from the two acquisitions must be precisely aligned so that they are representing the same ground object. Accurate and successful co-registration of the two (or more) images is vital for interferometry processing. We call the â€œmasterâ€ image the reference image (typically the earliest acquisition in time) to which we coregister the â€œslaveâ€ image (typically acquired later in time).\n\ncoregistered_ds = cat.coreg.read()\n\nfig, axes = plt.subplots(1, 2, figsize=(18, 8))\ncoregistered_ds.band_data.sel(band=1).plot(ax=axes[0], cmap=\"gray\", robust=True)\naxes[0].set_title(\"Master Phase Measurement - 28 Jun 2019\")\n\ncoregistered_ds.band_data.sel(band=2).plot(ax=axes[1], cmap=\"gray\", robust=True)\naxes[1].set_title(\"Slave Phase Measurement - 10 Jul 2019\")\n\nplt.tight_layout()",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#interferogram-formation-and-coherence-estimation",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#interferogram-formation-and-coherence-estimation",
    "title": "8Â  Interferograms",
    "section": "8.3 Interferogram Formation and Coherence Estimation",
    "text": "8.3 Interferogram Formation and Coherence Estimation\nThe interferogram formation process combines the amplitudes of both images and calculates the difference between their respective phases at each SAR image pixel (cross-multiplication of the master image with the complex conjugate of the slave image).\nAfter building up the interferogram, we have to take into account the presence of other contributing terms that could hinder our goal of measuring the surface deformation due to the earthquake. For example, we need to subtract from the interferogram the flat-earth phase contribution, which is a signal contribution due to the curvature of the Earthâ€™s surface. This is here done automatically through the SNAP software operators.\nIn general, the accuracy of interferometric measurements are influenced by many contributors that could result in a loss of coherence. But what is coherence? It is a measure of phase correlation between the master and slave image. Interferometric coherence (Î³) can be expressed as:\n\\[Î³ = Î³_{proc}*Î³_{geom}*Î³_{vol}*Î³_{SNR}*Î³_{temp}\\]\nwhere \\(Î³_{proc}\\) refers to inaccuracies in the processing (e.g., coregistration errors), \\(Î³_{geom}\\) refers to the baseline decorrelation (different position of satellites during the two acquisitions), \\(Î³_{vol}\\) refers to volume decorrelation (vegetation related), \\(Î³_{SNR}\\) refers to the radar instrument thermal noise and \\(Î³_{temp}\\) refers to the decorrelation caused by change of position of the objects in the scene during the time interval of the images acquisitions (e.g., plant growth, wind-induced movements or ground deformation due to earthquakes, landslides).\nTherefore, we can conclude that interferometric accuracy is sensitive to many processes, hence isolating the ground deformation signal involves several operations. On the other hand, interferometric coherence sensitivity could be exploited to track and map phenomena that cause its degradation (e.g., vegetation features, and water content).\n\ninterferogram_ds = cat.inter.read()\n\ncmap_hls_hex = sns.color_palette(\"hls\", n_colors=256).as_hex()\n\ninterferogram_ds = interferogram_ds.where(interferogram_ds != 0)\nigf_da = interferogram_ds.sel(band=1).band_data\ncoh_da = interferogram_ds.sel(band=2).band_data\n\n# Invert y axis\nigf_da[\"y\"] = igf_da.y[::-1]\ncoh_da[\"y\"] = coh_da.y[::-1]\n\nigf_plot = igf_da.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    cmap=cmap_hls_hex,\n    width=600,\n    height=600,\n    dynamic=False,\n)\n\ncoh_plot = coh_da.hvplot.image(\n    x=\"x\",\n    y=\"y\",\n    cmap=\"viridis\",\n    width=600,\n    height=600,\n    dynamic=False,\n).opts(clim=(0, 1))\n\n(igf_plot + coh_plot).opts(shared_axes=True)\n\n\n\n\n\n  \n\n\n\n\nNow we can observe patterns that emerged between the two acquisitions. If you look at the data range in the interferogram (left plot), youâ€™ll notice it spans approximately one wavelength, from \\(-\\pi\\) to \\(\\pi\\). On the right, you find a plot of the interferometric coherence (values ranging between 0 and 1), where low coherence is found along the ground surface ruptures caused by the earthquake. Please note, that the interferogram has already undergone a deburst operation (all bursts merged into a single image).",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#topographic-phase-removal",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#topographic-phase-removal",
    "title": "8Â  Interferograms",
    "section": "8.4 Topographic Phase Removal",
    "text": "8.4 Topographic Phase Removal\nSince the local topography is an additional phase term constituting the interferogram that we built up so far, we need to make an estimate of its impact in order to further remove it to keep only the ground deformation-related phase. For this purpose, we use a reference known DEM to simulate an interferogram and to subtract it from the original interferogram.\n\ntopo_ds = cat.topo.read()\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nigf_da.plot(ax=axes[0], cmap=cmap_hls)\naxes[0].set_title(\"Interferogram With Topographic Phase\")\n\ntopo_ds.topo.plot(ax=axes[1], cmap=\"gist_earth\")\naxes[1].set_title(\"Topography\")\n\ntopo_ds.Phase.plot(ax=axes[2], cmap=cmap_hls)\naxes[2].set_title(\"Interferogram Without Topographic Phase\")\n\nplt.tight_layout()",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#multi-looking-goldstein-phase-filtering-and-geocoding",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#multi-looking-goldstein-phase-filtering-and-geocoding",
    "title": "8Â  Interferograms",
    "section": "8.5 Multi-looking, Goldstein Phase Filtering and Geocoding",
    "text": "8.5 Multi-looking, Goldstein Phase Filtering and Geocoding\nIn order to improve the phase signatures contained within our interferogram and get a generally higher signal-to-noise (SNR) ratio, we will perform two additional operations called multi-looking and Goldstein phase filtering. Multi-looking is the process of averaging adjacent pixels using a moving window of the interferogram to reduce noise (at the cost of reducing the spatial resolution). Coherence is involved in this operation to flag and set areas to no data that are considered unreliable (low coherence) and to keep the reliable ones (high coherence).\nFinally, to make data interpretable, we geocode the wrapped interferogram. So far we performed the interferometric processing in the radar geometry. The transformation into geographic coordinates will help us to perform further comparisons in a real-world coordinate system.\n\ngeocoded_ds = cat.geocode.read()\n\nstep = 4  # if you want to zoom in, suggestion is to make this step smaller\n\ngeocoded_ds = geocoded_ds.where(geocoded_ds != 0)\nigf_data = geocoded_ds.sel(band=1).band_data\ncoh_da = geocoded_ds.sel(band=2).band_data\n\nigf_plot = igf_data.isel(x=slice(0, -1, step), y=slice(0, -1, step)).hvplot.image(\n    x=\"x\", y=\"y\", cmap=cmap_hls_hex, width=600, height=600, dynamic=False\n)\n\ncoh_plot = (\n    coh_da.isel(x=slice(0, -1, step), y=slice(0, -1, step))\n    .hvplot.image(x=\"x\", y=\"y\", cmap=\"viridis\", width=600, height=600, dynamic=False)\n    .opts(clim=(0, 1))\n)\n\n(igf_plot + coh_plot).opts(shared_axes=True)\n\n\n\n\n\n  \n\n\n\n\nIn the above plot, we can compare georeferenced data in the form of the interferogram (left) and the coherence (right). Along the earthquake fault line, low coherence between the two phase acquisitions is visible. This occurs due to extreme changes in terrain heights or displacements, which are beyond the sensitivity of the SAR sensor. This area of low coherence indicates higher uncertainty in the interferogram. However, this isnâ€™t necessarily a drawback, as it helps to clearly identify the earthquake epicenter.\nYou can also explore and zoom into regions with â€œfringe patternsâ€ to observe ground movement. Each fringe cycle (e.g., from red to red or blue to blue) corresponds to ground motion in this case. The fringe patterns indicate motion in the line-of-sight (LOS) of the satellite (Sentinel-1 has a mean incidence angle of 38Â°) in terms of either uplift (relative motion of the ground towards the satellite) or sinking (relative motion of the ground away from the satellite). If the interferogram phase changes from 0 to -3.14 (cycles in the negative direction), the surface is moving away from the satellite (i.e., sinking movement). Vice versa, if cycles go in the positive direction (from 0 to +3.14), it would mean a relative uplifting movement of the ground. In areas with no ground motion, fringe patterns disappear. The radarâ€™s sensitivity to motion depends on its wavelength. For Sentinel-1 (~5.6cm), a full fringe cycle (\\(2\\pi\\)) represents a displacement of ~2.8 cm in the LOS direction.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#visualisation-of-the-earthquake-event-on-july-5th-2019",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/08_in_class_exercise.html#visualisation-of-the-earthquake-event-on-july-5th-2019",
    "title": "8Â  Interferograms",
    "section": "8.6 Visualisation of the Earthquake Event on July 5th, 2019",
    "text": "8.6 Visualisation of the Earthquake Event on July 5th, 2019\n\nstep = 4  # Downsample data for visualization\nigf_data_subset = igf_data.isel(x=slice(0, -1, step), y=slice(0, -1, step))\n\n\ndef array_to_img(data_array, cmap):\n    fig, ax = plt.subplots(figsize=(6, 6), dpi=600)\n    data_array.plot(ax=ax, cmap=cmap, add_colorbar=False, add_labels=False)\n    ax.set_axis_off()\n    buf = BytesIO()\n    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\", pad_inches=0, transparent=True)\n    plt.close(fig)\n    return base64.b64encode(buf.getvalue()).decode(\"utf-8\")\n\n\nigf_image = array_to_img(igf_data_subset, cmap=cmap_hls)\nbounds = [\n    [float(igf_data[\"y\"].min()), float(igf_data[\"x\"].min())],\n    [float(igf_data[\"y\"].max()), float(igf_data[\"x\"].max())],\n]\n\nm = folium.Map(\n    location=[float(igf_data[\"y\"].mean()), float(igf_data[\"x\"].mean())],\n    zoom_start=10,\n)\nfolium.TileLayer(\n    tiles=(\n        \"https://server.arcgisonline.com/ArcGIS/rest/\"\n        \"services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n    ),\n    attr=\"Tiles Â© Esri\",\n    name=\"ESRI World Imagery\",\n).add_to(m)\nfolium.TileLayer(\n    tiles=(\n        \"https://server.arcgisonline.com/ArcGIS/rest/\"\n        \"services/Reference/World_Boundaries_and_Places/\"\n        \"MapServer/tile/{z}/{y}/{x}\"\n    ),\n    attr=\"Tiles Â© Esri\",\n    name=\"ESRI Labels\",\n    overlay=True,\n).add_to(m)\n\nfolium.raster_layers.ImageOverlay(\n    image=f\"data:image/png;base64,{igf_image}\",\n    bounds=bounds,\n    opacity=0.65,\n    name=\"Interferogram\",\n).add_to(m)\nfolium.LayerControl().add_to(m)\n\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>Interferograms</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html",
    "title": "9Â  Phase Unwrapping",
    "section": "",
    "text": "9.1 Loading Data\nThe goal of this notebook is to read an interferogram image (i.e., 2-D array of phase values) and unwrap it. Phase unwrapping is a critical process in interferometry, which involves recovering unambiguous phase data from the interferogram.\nA SAR interferogram represents the phase difference between two radar acquisitions (i.e., two SLC images). The phase difference is usually wrapped within a range of 0 to 2Ï€, because the phase is inherently cyclical. When the true phase difference exceeds 2Ï€, it gets â€œwrappedâ€ into this range, creating a discontinuous phase signal. Phase unwrapping refers to the process of reconstructing the continuous phase field from the wrapped phase data.\nUnwrapping an interferogram is essential for extracting correct information contained in the phase such as surface topography and earth surface deformations.\nThere are many approaches that tried to solve the unwrapping problem, tackling challenging scenarios involving noise or large phase discontinuities. Here we present the Network-flow Algorithm for phase unwrapping (C. W. Chen and H. A. Zebker, 2000), which is implemented in the snaphu package.\nThe data is stored on the Jupyterhub server, so we need to load it using their respective paths. In this notebook we will use the resulting wrapped interferogram from notebook â€œInterferogramsâ€, but we need to process it in the radar geometry in order to unwrap it (while in notebook â€œInterferogramsâ€ we end the whole process by performing the geocoding, just for better visualization purposes).\nimport contextlib\nimport os\n\nimport cmcrameri as cmc  # noqa: F401\nimport intake\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nimport snaphu\nimport xarray as xr\nfrom matplotlib import patches\nuri = \"https://git.geo.tuwien.ac.at/public_projects/microwave-remote-sensing/-/raw/main/microwave-remote-sensing.yml\"\ncat = intake.open_catalog(uri)\nds = cat.complex.read().compute()\nds[\"cmplx\"] = ds[\"real\"] + ds[\"imag\"] * 1j\n# Set cyclic and linear colormaps\ncmap_cyc = sns.color_palette(\"hls\", as_cmap=True)  # \"cmc.romaO\"\ncmap_lin = \"cmc.roma_r\"\ncmap_disp = \"cmc.vik\"\n\n# Create a mask for the areas which have no data\nmask = ds.phase.where(ds.phase == 0, True, False).astype(bool)\nLetâ€™s start by displaying the interferogram that needs to be unwrapped. Recall that due to the Slant Range geometry and the satellite acquisition pass (ascending, in our case), the image appears north/south flipped (with respect to the geocoded image)!\n# Plot Phase Interferogram Image\nfig, axs = plt.subplots(figsize=(6, 6))\n\n(\n    ds.phase.where(mask)\n    .plot.imshow(cmap=cmap_cyc, zorder=1)\n    .axes.set_title(\"Phase Interferogram Image (Wrapped)\")\n)\nplt.show()",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html#phase-unwrapping",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html#phase-unwrapping",
    "title": "9Â  Phase Unwrapping",
    "section": "9.2 Phase Unwrapping",
    "text": "9.2 Phase Unwrapping\nAs we will be doing the unwrapping multiple times in this notebook letâ€™s create a function that does the unwrapping for us on xarray DataArray objects. The actual core function where the unwrapping is happening is snaphu.unwrap_phase from the snaphu package. This function needs a 2D numpy array as input, where each pixel value is a complex number. Therefore we have to convert the xarray DataArray to a 2D numpy array with complex values. We do that by combining the phase and intensity bands to a complex array. The actual unwrapping is essentially an addition of the phase values, such that the values are continuous and not between \\(-\\pi\\) and \\(\\pi\\).\n\nFigure 1: Illustration of how the unwrapping of the phase works. (Source: ESA).\n\n@contextlib.contextmanager\ndef suppress_output():\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = os.dup(1)\n        old_stderr = os.dup(2)\n\n        os.dup2(devnull.fileno(), 1)\n        os.dup2(devnull.fileno(), 2)\n\n        try:\n            yield\n        finally:\n            os.dup2(old_stdout, 1)\n            os.dup2(old_stderr, 2)\n            os.close(old_stdout)\n            os.close(old_stderr)\n\n\ndef unwrap_array(\n    data: xr.DataArray,\n    complex_var: str = \"cmplx\",\n    ouput_var: str = \"unwrapped\",\n    mask: xr.DataArray = True,\n    coherence: xr.DataArray = None,\n    mask_nodata_value: int = 0,\n    coh_low_threshold: float = None,\n    coh_high_threshold: float = None,\n    nlooks=1.0,\n    cost=\"smooth\",\n    init=\"mcf\",\n    **kwargs,\n) -&gt; xr.DataArray:\n    \"\"\"Unwraps the phase data using the snaphu algorithm.\n\n    Parameters\n    ----------\n    data: xarray DataArray with complex numbers\n    complex_var: Name of the variable with the complex numbers\n    ouput_var: Name of the variable with the unwrapped phase\n    mask: xarray DataArray with mask values\n    coherence: xarray DataArray with coherence values (optional)\n    mask_nodata_value: Value of the no data pixels in the mask\n    coh_low_threshold: Lower threshold for the coherence values\n    coh_high_threshold: Higher threshold for the coherence values\n\n    Returns\n    -------\n    xarray DataArray with the unwrapped phase\n\n    \"\"\"\n    # Get the complex data\n    data_arr = data[complex_var]\n\n    # Create a mask for areas with no data\n    if mask is True:\n        mask = (data_arr.real != mask_nodata_value).astype(bool)\n\n    # Apply coherence thresholds if provided\n    if coherence is not None:\n        if coh_low_threshold is not None:\n            coh_mask = (coherence &gt;= coh_low_threshold).astype(bool)\n            mask = mask & coh_mask\n        if coh_high_threshold is not None:\n            coh_mask = (coherence &lt;= coh_high_threshold).astype(bool)\n            mask = mask & coh_mask\n\n    # Apply the mask to the data\n    data_arr = data_arr.where(mask)\n\n    if coherence is None:\n        coherence = np.ones_like(data_arr.real)\n\n    # Unwrap the phase (already in complex form)\n    with suppress_output():\n        unw, _ = snaphu.unwrap(\n            data_arr,\n            coherence,\n            nlooks=nlooks,\n            cost=cost,\n            init=init,\n            mask=mask,\n            **kwargs,\n        )\n\n    # Build xarray DataArray with the unwrapped phase\n    # unw_da = xr.DataArray(unw, coords=data.coords, dims=data.dims)\n    # data = data.to_dataset()\n    data[ouput_var] = ((\"y\", \"x\"), unw)\n\n    # Mask the unwrapped phase\n    # unw_da = unw_da.where(mask)\n    data[ouput_var] = data[ouput_var].where(mask)\n    return data\n\n\n9.2.1 Unwrapping on a Subset\nAs the original image is too large to unwrap in a reasonable time, we will unwrap a subset of the image. In this case, we will unwrap an area of 500x500 pixels.\n\n# Select a subset of the data\ndx, dy = 500, 500\nx0, y0 = 2800, 1700\n\n\ndef subsetting(ds, x0: int = 0, y0: int = 0, dx: int = 500, dy: int = 500):\n    return ds.isel(x=slice(x0, x0 + dx), y=slice(y0, y0 + dy))\n\n\n# Subsetting the data arrays\nsubset = subsetting(ds.where(mask), x0, y0, dx, dy)\n\n# Unwrap the subset\nsubset = unwrap_array(subset, complex_var=\"cmplx\", ouput_var=\"unwrapped\")\n\nNow letâ€™s compare the wrapped and unwrapped phase images.\n\nfig, axs = plt.subplots(1, 3, figsize=(14, 4))\n\n# Wrapped Phase\n\n(\n    subset.phase.plot.imshow(cmap=cmap_cyc, ax=axs[0]).axes.set_title(\n        \"Wrapped Phase of the Subset\"\n    )\n)\n\n# Unwrapped Phase\n(\n    subset.unwrapped.plot.imshow(\n        cmap=cmap_cyc, ax=axs[1], vmin=-80, vmax=80\n    ).axes.set_title(\"Unwrapped Phase of the Subset\")\n)\n\n# Subset inside the complete image\n(\n    ds.phase.where(mask)\n    .plot.imshow(cmap=cmap_cyc, zorder=1, ax=axs[2])\n    .axes.set_title(\"Complete Wrapped Phase Image\")\n)\n\nx_start = ds.phase.coords[\"x\"][x0].item()\ny_start = ds.phase.coords[\"y\"][y0].item()\nx_end = ds.phase.coords[\"x\"][x0 + dx].item()\ny_end = ds.phase.coords[\"y\"][y0 + dy].item()\n\nrect = patches.Rectangle(\n    (x_start, y_start),\n    x_end - x_start,\n    y_end - y_start,\n    linewidth=1,\n    edgecolor=\"r\",\n    facecolor=\"red\",\n    alpha=0.5,\n    label=\"Subset\",\n)\n\n# Add the rectangle to the plot\naxs[2].add_patch(rect)\naxs[2].legend()\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\n\n9.2.2 Unwrapping with coherence mask\nAdditionally, can we try to calculate the unwrapped image, where we are excluding pixels, where the coherence values are lower than a certain threshold. This is done by masking the coherence image with the threshold value and then unwrapping the phase image with the masked coherence image.\n\nthreshold1 = 0.3\nsubset = unwrap_array(\n    subset,\n    coherence=subset.coh,\n    coh_low_threshold=threshold1,\n    complex_var=\"cmplx\",\n    ouput_var=\"unwrapped_coh\",\n)\n\nLetâ€™s compare the unwrapped image with and without the coherence mask.\n\nfig, axs = plt.subplots(1, 2, figsize=(13, 5))\n(\n    subset.unwrapped_coh.plot.imshow(\n        cmap=cmap_cyc, ax=axs[0], vmin=-80, vmax=80\n    ).axes.set_title(f\"Unwrapped Phase with Coherence Threshold {threshold1}\")\n)\n\n(\n    subset.unwrapped.plot.imshow(\n        cmap=cmap_cyc, ax=axs[1], vmin=-80, vmax=80\n    ).axes.set_title(\"Unwrapped Phase without Coherence Threshold\")\n)\n\nplt.show()\n\n\n\n\n\n\n\n\nLetâ€™s see if another threshold value for the coherence mask gives better results.\n\nthreshold2 = 0.5\nsubset = unwrap_array(\n    subset,\n    coherence=subset.coh,\n    coh_low_threshold=threshold2,\n    complex_var=\"cmplx\",\n    ouput_var=\"unwrapped_coh2\",\n)\n\nfig, axs = plt.subplots(1, 2, figsize=(13, 5))\n(\n    subset.unwrapped_coh2.plot.imshow(\n        cmap=cmap_cyc, ax=axs[0], vmin=-80, vmax=80\n    ).axes.set_title(\"Coherence Threshold 0.5\")\n)\n\n(\n    subset.unwrapped_coh.plot.imshow(\n        cmap=cmap_cyc, ax=axs[1], vmin=-80, vmax=80\n    ).axes.set_title(\"Coherence Threshold 0.3\")\n)\nplt.show()\n\n\n\n\n\n\n\n\nA higher coherence threshold means that only pixels with a coherence value greater than 0.5 will be used for phase unwrapping. This would result in an unwrapping process that is likely more stable, with reduced noise (invalid phase information in the proximity of the earthquake faults is discarded). However, an excessive coherence threshold might have significant gaps or missing information, especially in areas where motion or surface changes have occurred. The choice of a coherence threshold depends on the balance you want to strike between the accuracy and coverage of the output unwrapped image.\nKeep in mind that in case of large displacements, such as the Ridgecrest earthquake, phase unwrapping can be problematic and lead to poor results: when the displacement is large, the phase difference becomes wrapped multiple times, leading to phase aliasing. In this case, the phase values become ambiguous, we cannot distinguish between multiple phase wraps, thus leading to incorrect results.",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html#applying-an-equation-for-the-displacement-map",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html#applying-an-equation-for-the-displacement-map",
    "title": "9Â  Phase Unwrapping",
    "section": "9.3 Applying an Equation for the Displacement Map",
    "text": "9.3 Applying an Equation for the Displacement Map\nFrom the unwrapped phase image (we will use the phase masked with a coherence threshold of 0.3) we can calculate the displacement map using the following equation:\n$ d = - _d $\nwhere: - \\(\\lambda = 0.056\\) for Sentinel-1 - \\(\\Delta \\phi_d\\) is the unwrapped image\nThis operation can be very useful for monitoring ground deformation.\n\ndef displacement(unw, lambda_val: float = 0.056) -&gt; xr.DataArray:\n    \"\"\"Calculates the displacement from the unwrapped phase\n\n    Parameters\n    ----------\n    unw: xarray DataArray with the unwrapped phase\n    unw: xr.DataArray\n    lambda_val: Wavelength of the radar signal\n    lambda_val: float\n\n    Returns\n    -------\n    xarray DataArray with the displacement\n\n    \"\"\"\n    disp = unw * -lambda_val / (4 * np.pi)\n    return disp\n\n\n# Calculate the displacement\ndisp_subset = displacement(subset.unwrapped_coh)\n\n\n# Plot the displacement map\n(\n    disp_subset.plot.imshow(\n        cmap=cmap_disp, cbar_kwargs={\"label\": \"Meters [m]\"}\n    ).axes.set_title(\"Displacement Map of the Subset\")\n)\nplt.show()",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html#coarsen-approach",
    "href": "chapters/courses/microwave-remote-sensing/unit_03/09_in_class_exercise.html#coarsen-approach",
    "title": "9Â  Phase Unwrapping",
    "section": "9.4 Coarsen Approach",
    "text": "9.4 Coarsen Approach\nAs the whole data is too large and the processing time already exceeds 20 minutes when using an image with 4000x4000 pixels, we can coarsen the image so that we can unwrap and compute the displacement for the whole scene.\n\nkernel_size = 3\nlowres = ds.coarsen(x=kernel_size, y=kernel_size, boundary=\"trim\").median()\n\n\nlowres = unwrap_array(\n    lowres,\n    ntiles=(20, 30),\n    tile_overlap=10,\n    coherence=lowres.coh,\n    coh_low_threshold=0.3,\n    complex_var=\"cmplx\",\n    ouput_var=\"unwrapped\",\n)\n\nWe can now plot the unwrapped image of the low resolution image.\n\n# Plot the unwrapped phase\n(\n    lowres.unwrapped.plot.imshow(cmap=cmap_cyc).axes.set_title(\n        \"Unwrapped Phase entire scene (coarsened)\"\n    )\n)\nplt.show()\n\n\n\n\n\n\n\n\nWe can also now calculate the displacement map and compare them.\n\nlowres_disp = displacement(lowres.unwrapped)\n\n# Plot the displacement map\n(\n    lowres_disp.plot.imshow(\n        cmap=cmap_disp, cbar_kwargs={\"label\": \"Meters [m]\"}\n    ).axes.set_title(\"Displacement Map entire scene (coarse resolution)\")\n)\nplt.show()\n\n\n\n\n\n\n\n\nPlot a summary of the previous plots:\n\n# Plot summary of previous plots\nfig, axs = plt.subplots(2, 2, figsize=(12, 10))\nax = axs.ravel()\n\n(\n    subset.unwrapped_coh.plot.imshow(\n        cmap=cmap_cyc, ax=ax[0], vmin=-80, vmax=80\n    ).axes.set_title(\"Unwrapped Phase of the subset with Coherence Threshold 0.3\")\n)\n\n(\n    disp_subset.plot.imshow(\n        cmap=cmap_disp, ax=ax[1], cbar_kwargs={\"label\": \"Meters [m]\"}\n    ).axes.set_title(\"Displacement Map of the Subset\")\n)\n\n(\n    lowres.unwrapped.plot.imshow(cmap=cmap_cyc, ax=ax[2]).axes.set_title(\n        \"Unwrapped Phase of the entire scene with Coherence Threshold 0.3 (coarsened)\"\n    )\n)\n\n(\n    lowres_disp.plot.imshow(\n        cmap=cmap_disp, ax=ax[3], cbar_kwargs={\"label\": \"Meters [m]\"}\n    ).axes.set_title(\"Displacement Map entire scene (coarse resolution)\")\n)\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\nIn the following animation, we can capture the 3D displacement caused by the Ridgecrest quake by observing the after and before elevation model.\n Credits: NASA",
    "crumbs": [
      "Microwave Remote Sensing",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>Phase Unwrapping</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing.html",
    "href": "chapters/courses/environmental-remote-sensing.html",
    "title": "Environmental Remote Sensing",
    "section": "",
    "text": "Prerequisites\nThese course materials where developed in the framework of the DrySat project: Enhancing Drought Early Warning in Mozambique through Satellite Soil Moisture Data to support food security in the context of climate change.",
    "crumbs": [
      "Environmental Remote Sensing"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing.html#prerequisites",
    "href": "chapters/courses/environmental-remote-sensing.html#prerequisites",
    "title": "Environmental Remote Sensing",
    "section": "",
    "text": "Concepts\nImportance\nNotes\n\n\n\n\nIntro to Earth Observation Data Science\nHelpful\n\n\n\nDocumentation hvPlot\nHelpful\nInteractive plotting\n\n\nDocumentation pandas\nHelpful\nTabular data wrangling\n\n\n\n\nTime to learn: 90 min\n\n\n\n\n\n\n\nNote\n\n\n\nThese notebooks contain interactive elements. The full interactive elements can only be viewed on Binder by clicking on the Binder badge or ðŸš€ button.",
    "crumbs": [
      "Environmental Remote Sensing"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "",
    "text": "10.1 Overview\nDrought Monitoring with H SAF ASCAT Surface Soil Moisture Retrievals\nIn this notebook we will examine the capabilities of the H SAF Advanced Scatterometer (ASCAT) to monitor droughts in Mozambique. ASCAT instruments are situated onboard the Metop satellites (EUMETSAT1) that are in orbit since 2007. These operational meteorological missions have yielded a continuous record of microwave backscattering and continue to produce data for the future. The longevity of the ASCAT microwave backscatter record is therefore well-suited to track climate change, such as soil moisture drying trends and droughts over Mozambique. The surface soil moisture (SSM) retrieved from the product showcased here is available at a sampling distance of 6.25\\(\\,\\)km, this means that one value of soil moisture is available for every 50\\(\\,\\)km\\(^2\\) (5000\\(\\,\\)ha).\nMore information about microwave backscattering and the fundamentals of surface soil moisture retrieval from microwave backscatter signatures can be found in this video:",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#imports",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#imports",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.2 Imports",
    "text": "10.2 Imports\n\nimport cartopy.crs as ccrs\nimport holoviews as hv\nimport hvplot.pandas  # noqa\nimport numpy as np\nimport pandas as pd\nfrom bokeh.models import FixedTicker\n\nfrom envrs.download_path import make_url\nfrom envrs.ssm_cmap import SSM_CMAP\n\nERROR 1: PROJ: proj_create_from_database: Open of /home/runner/work/eo-datascience/eo-datascience/.conda_envs/environmental-remote-sensing/share/proj failed",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#plotting-of-spatial-soil-moisture-maps",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#plotting-of-spatial-soil-moisture-maps",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.3 Plotting of Spatial Soil Moisture Maps",
    "text": "10.3 Plotting of Spatial Soil Moisture Maps\nLet us start by having a look at monthly aggregated SSM derived from ASCAT microwave backscattering over Mozambique. We can easily load the csv-file with pandas from the web, like so:\n\nurl = make_url(\"ascat-6_25_ssm_monthly.csv\")\ndf = pd.read_csv(\n    url,\n    index_col=[\"time\", \"location_id\"],\n    parse_dates=[\"time\"],\n)\n\ndf.head()\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/ascat-6_25_ssm_monthly.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nsurface_soil_moisture\nzscore\n\n\ntime\nlocation_id\n\n\n\n\n\n\n\n\n2007-01-01\n10250165\n32.674310\n-26.702084\n22.886970\n-0.399316\n\n\n10243400\n32.698105\n-26.768017\n28.497500\n-0.141156\n\n\n10246361\n32.208755\n-26.739155\n37.186670\n0.151953\n\n\n10250542\n32.247260\n-26.698412\n41.724550\n0.136301\n\n\n10278822\n32.679924\n-26.423197\n21.824375\n-1.098983\n\n\n\n\n\n\n\nThe data is presented in a long format, where each combination of time and location-id represents a unique observation. The coordinates, latitude (vertical position) and longitude (horizontal position), indicate the location on the Earthâ€™s surface. These geospatial points are one of the simplest types of geospatial data known as the Climate and Forecast (CF) Convention â€œPoint Dataâ€2. This format is well-suited for timeseries which is important for detecting droughts.\nWe will plot the results using hvplot.points. Hvplot will manage the scattered locations by employing the rasterize parameter, which resamples the data onto a selected grid representation: an Equirectangular projection (a.k.a â€˜plate carrÃ©e projectionâ€™) in this instance. By grouping the data by \"time\", we create an interactive plot that allows us to scroll through all the months from 2007 to the present. Additionally, we will overlay the SSM values onto an Open Street Map (OSM). For convenience, we have included the locations of the in-situ sensors placed in each target district of the DrySAT project.\nSSM values are reported as the degree of saturation, indicating how much of the soil pore space is filled with water. This means, values can range from 0%, completely dry soil, to 100%, fully saturated soil. If you would like to obtain absolute values of soil moisture, i.e.Â how much water is available in the soil in m\\(^3\\)/m\\(^3\\) you can use the soil porosity of your location and multiply it with the degree of saturation. This is further explained in the following notebook.\n\nlocations = {\n    \"Muanza\": {\"latitude\": -18.9064758, \"longitude\": 34.7738921},\n    \"ChokwÃ©\": {\"latitude\": -24.5894393, \"longitude\": 33.0262595},\n    \"Mabote\": {\"latitude\": -22.0530427, \"longitude\": 34.1227842},\n    \"Mabalane\": {\"latitude\": -23.4258788, \"longitude\": 32.5448211},\n    \"Buzi\": {\"latitude\": -19.9747305, \"longitude\": 34.1391065},\n}\n\ndf_locs = pd.DataFrame.from_dict(locations, \"index\").reset_index()\n\npoints = df_locs.hvplot.points(\n    x=\"longitude\", y=\"latitude\", color=\"black\", crs=ccrs.PlateCarree()\n)\nlabels = df_locs.hvplot.labels(\n    x=\"longitude\",\n    y=\"latitude\",\n    text=\"index\",\n    text_baseline=\"bottom\",\n    text_color=\"black\",\n    crs=ccrs.PlateCarree(),\n)\n\ndf.hvplot.points(\n    x=\"longitude\",\n    y=\"latitude\",\n    c=\"surface_soil_moisture\",\n    groupby=\"time\",\n    x_sampling=0.08,\n    y_sampling=0.08,\n    rasterize=True,\n    crs=ccrs.PlateCarree(),\n    tiles=True,\n    cmap=SSM_CMAP,\n    clim=(0, 100),\n    frame_width=500,\n    clabel=\"Surface soil moisture (%)\",\n) * points * labels",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#plotting-of-surface-soil-moisture-timeseries",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#plotting-of-surface-soil-moisture-timeseries",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.4 Plotting of Surface Soil Moisture Timeseries",
    "text": "10.4 Plotting of Surface Soil Moisture Timeseries\nNow let us have a closer look at the five locations marked on the SSM map and plot the SSM values against time for these 5 locationsâ€”known as timeseries. To do this we have already filtered down the full dataset to only contain the five locations for you. We read these 5 timeseries using pandas and importing the .csv file. The .csv file contains 5 timeseries of SSM for the locations Buzi, Mabalane, Muanza, Mabote, and ChokwÃ©. This filtered dataset shows the full temporal resolution of the product. To visualize this, we highlight the density of data points falling in a certain sector of the plot with blue shadingâ€”bluer values mark a higher density of data points.\n\nts = pd.read_csv(\n    make_url(\"ascat-6_25_ssm_timeseries.csv\"),\n    index_col=\"time\",\n    parse_dates=True,\n)\n\nts.hvplot.scatter(\n    x=\"time\",\n    y=\"surface_soil_moisture\",\n    groupby=\"name\",\n    rasterize=True,\n    dynspread=True,\n    threshold=1,\n    frame_width=800,\n    padding=(0.01, 0.1),\n    clabel=\"Density of data\",\n)\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/ascat-6_25_ssm_timeseries.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n  \n\n\n\n\nThe cyclical seasonal pattern from dry to wet can be easily discerned from the timeseries. Note, however, again that we do not track precipitation, but the change from wet to dry soils. Moreover, we can see that the cyclical pattern breaks down on occasion as can be seen in the years 2015 and 2016. Especially ChokwÃ© displays a complete lack of wet soils during the 2016 rainy season. We can remove some of the noise in the records by aggregating the values on a monthly basis, as can be seen in the following code chunk. Here, the pandas dataframe method groupby can group the timeseries for all successive months with the pandas function Grouper(freq=\"ME\") and the location name. We can then plot the data monthly and color code per location name as follows:\n\nts_monthly = (\n    ts.groupby([pd.Grouper(freq=\"ME\"), \"name\"])\n    .surface_soil_moisture.mean()\n    .reset_index(level=\"name\")\n)\n\nts_monthly.hvplot.line(\n    x=\"time\",\n    y=\"surface_soil_moisture\",\n    by=\"name\",\n    frame_width=800,\n    padding=(0.01, 0.1),\n)\n\n\n\n\n\n  \n\n\n\n\nIn these monthly aggregated timeseries we can more easily investigate temporal dynamics per location. Note that we are still looking at the degree of saturation, and that for each location it varies between 0 and 100%. So, these time series do not give us information on the absolute differences in SSM between locations. To do this we would need information on the soil porosity for each site. However, we can use the timeseries at each location to look at temporal dynamics such as changes in the the amplitude, or the magnitude of change in SSM. This is of greater importance for drought detection, as we can see if a change in SSM during a specific time is â€œnormalâ€, or more â€œunusualâ€ for this specific location, when compared to other years.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#normalization-and-anomaly-detection",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#normalization-and-anomaly-detection",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.5 Normalization and Anomaly Detection",
    "text": "10.5 Normalization and Anomaly Detection\nTo investigate how â€œunusualâ€ certain periods are, we can calculate Z-score statistics.\n\\[ z_{k,i} = \\frac{\\text{SM}_{k,i} - \\bar{\\text{SM}}_i}{s^{\\bar{\\text{SM}}_i}} \\]\nwhere:\n\\[\n\\begin{align}\n\\text{SM}_{k,i} &\\quad \\text{:soil moisture for specific period (e.g., month) (} \\; i \\; \\text{) and year (} \\; k \\; \\text{)}\\\\\n\\bar{\\text{SM}}_i &\\quad \\text{: long-term mean soil moisture for specific period (e.g., month) (} \\; i \\; \\text{)} \\\\\ns^{\\bar{\\text{SM}}_i} &\\quad \\text{: long-term standard deviation soil moisture for specific period (e.g., month) (} \\; i \\; \\text{)}\n\\end{align}\n\\]\nThe Z score statistic is an approach to detect anomalies in timeseries, where one measures how far a datapoint (\\(\\text{SM}_{k,i}\\)) is removed from the long-term mean (\\(\\bar{\\text{SM}}\\)). This distance from the mean by itself is not all that useful, as it depends on the locationâ€™s average SSM. To circumvent, and to more easily compare timeseries of different locations, we divide the distance of the mean with a measure of variation of the timeseries, such as the standard deviation (\\(s^{\\bar{\\text{SM}}_i}\\)).\n\ndef zscore(x: pd.Series) -&gt; pd.Series:\n    \"\"\"Z Score.\n\n    Parameters\n    ----------\n    x : pd.Series\n        Monthly aggregated surface soil moisture values\n\n\n    Returns\n    -------\n    Z scores : pd.Series\n\n    \"\"\"\n    return (x - x.mean()) / x.std()\n\nWe exemplify this normalization step below. Here we can see two histograms for a simulated SSM dataset. The histogram on the top is still in the original â€œdegree of saturationâ€ units, whereas the graph on the bottom is transformed to Z scores. The value of the x axis of the lower histogram can be translated as: â€œThis point is so many standard deviations removed from the mean.â€\n\nrng = np.random.default_rng()  # make reproducible\nmu, sigma = 50, 10  # mean and standard deviation\nrandom_ts = pd.Series(rng.normal(mu, sigma, 100))\n(\n    random_ts.hvplot.hist(xlabel=\"SSM (%)\")\n    + zscore(random_ts).hvplot.hist(xlabel=\"Z score\")\n).cols(1).opts(shared_axes=False)",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#drought-anomaly-detection",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#drought-anomaly-detection",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.6 Drought Anomaly Detection",
    "text": "10.6 Drought Anomaly Detection\nFor our time series, we will now calculate the Z-scores per month. First, we must calculate the average for all months of January and compare this to the monthly aggregated SSM value, then for February, and so on for every month. This operation is like the previous groupby operation, but now we use the datetime accessor month to accumulate monthly averages. Then we use the transform to calculate the Z score on the pandaâ€™s column with our previously defined function zscore.\n\nts_monthly[\"zscore\"] = ts_monthly.groupby(\n    [ts_monthly.index.month, \"name\"]\n).surface_soil_moisture.transform(zscore)\nts_monthly.hvplot.line(\n    x=\"time\",\n    y=\"zscore\",\n    by=\"name\",\n    frame_width=800,\n    padding=(0.01, 0.1),\n)\n\n\n\n\n\n  \n\n\n\n\nIn the last plot we can now clearly discern the drought of 2015/2016 but also other droughts, such as during the years 2019/2020. The Z score also appears to indicate drier than usual conditions in 2024/2025. The Z-score can be translated into drought severity levels where the following drought conditions can be classified: â€œmildâ€, â€œmoderateâ€, â€œsevereâ€, â€œextremeâ€. We will talk more about the drought severity levels in notebook 3.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#monitoring-drought-in-time-and-space",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#monitoring-drought-in-time-and-space",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.7 Monitoring Drought in Time and Space",
    "text": "10.7 Monitoring Drought in Time and Space\nAs a last step, we can now apply this approach to the whole of Mozambique. Here we have already calculated the Z scores and we just have to plot them.\n\ncolorbar_opts = {\n    \"major_label_overrides\": {\n        -2.5: \"Extreme\",\n        -2: \"Severe\",\n        -1.5: \"Moderate\",\n        -1: \"Mild\",\n        0: \"Normal\",\n    },\n    \"ticker\": FixedTicker(ticks=[-2.5, -2, -1.5, -1, 0]),\n}\n\ndf[df.zscore &lt;= 0].hvplot.points(\n    x=\"longitude\",\n    y=\"latitude\",\n    c=\"zscore\",\n    groupby=\"time\",\n    x_sampling=0.08,\n    y_sampling=0.08,\n    rasterize=True,\n    crs=ccrs.PlateCarree(),\n    tiles=True,\n    cmap=\"reds_r\",\n    clim=(-3, 0),\n    frame_width=500,\n    clabel=\"Drought anomaly\",\n).opts(hv.opts.Image(colorbar_opts={**colorbar_opts})) * points * labels\n\n\n\n\n\n  \n\n\n\n\nThis temporospatial analysis (in time and space) confirms that 2015/2016 was particularly pronounced in the south of the country surrounding the region of ChokwÃ©. But this intense drought was also prevalent in the northern districts neighbouring Malawi. This is something that would not be seen in a spot-wise analysis.\nIn the next notebooks, we will compare this microwave-based technique to other indicators of drought such as SPEI and vegetation-based indicators of drought (NDVI).",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#appendix-fibonacci-grid",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#appendix-fibonacci-grid",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "10.8 Appendix: Fibonacci Grid",
    "text": "10.8 Appendix: Fibonacci Grid\nThe H SAF ASCAT SSM data is presented on an irregular grid known as the Fibonacci grid (GonzÃ¡lez, 2010)3. This grid offers advantages for e.g., statistical calculations on the data by reducing errors caused by distortions and non-uniform weighting of point contributions. For instance, when comparing areas over a wide latitudinal range, a regular longitude-latitude grid can lead to unequal weighting, as data points become more densely packed farther from the equator (see table). However, working with irregular grids can be more challenging. We will provide you with some useful techniques to simplify your work.\n\n\n\n\n\n\n\n\nFeature\nRegular Grids\nIrregular Grids\n\n\n\n\nStructure\nUniform spacing and cell size\nVariable spacing and cell size\n\n\nData Distribution\nEvenly distributed data points\nDensely placed data points in areas of interest\n\n\nComputational Efficiency\nHighly efficient for processing and visualization\nMore complex and time-consuming computations\n\n\nBenefits\n- Simplicity- Computational efficiency- Ease of implementation\n- Detailed representation- Flexibility- Accurate spatial heterogeneity\n\n\nDownsides\n- May lack detail in complex areas- Uneven sampling weights in statistics\n- Increased computational complexity- More challenging to implement",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#footnotes",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/01_handout_drought.html#footnotes",
    "title": "10Â  Remotely Sensed Droughts in Mozambique",
    "section": "",
    "text": "European Organisation for the Exploitation of Meteorological Satellitesâ†©ï¸Ž\nThe Climate and Forecast (CF) Conventions are standards for NetCDF files that define metadata, including variable names, units, and other attributes, to ensure interoperability and consistency in climate and forecast data handling.â†©ï¸Ž\nÃ. GonzÃ¡lez, 2010, Measurement of Areas on a Sphere Using Fibonacci and Latitude-Longitude Lattices, Math Geosci, vol.Â 42, no. 1, pp.Â 49-64, doi: 10.1007/s11004-009-9257-x.â†©ï¸Ž",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Remotely Sensed Droughts in Mozambique</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "",
    "text": "11.1 Overview\nComparing H SAF ASCAT Surface Soil Moisture with In-Situ Sensors\nThe aim of this notebook is to demonstrate and teach a workflow for validating ASCAT H SAF surface soil moisture (SSM) data, sampled at 6.25\\(\\,\\)km distances, using in-situ sensors strategically placed in Mozambique. The evaluation in this context mainly assesses how well satellite-derived data aligns with the temporal patterns of in-situ soil water measurements. Remember, temporal dynamics are also crucial for anomaly detection in soil moisture records, which in turn affects our ability to monitor droughts (as discussed in the previous notebook). However, it is also a good practice to examine the absolute values of remotely sensed soil moisture. Such comprehensive validation processes are vital for forecasting, climate research, and decision-making, as they ensure the accuracy and reliability of weather data. By comparing different datasets, one can identify and address inconsistencies, thus enhancing the quality of meteorological records.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#imports",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#imports",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "11.2 Imports",
    "text": "11.2 Imports\n\nimport folium\nimport hvplot\nimport hvplot.pandas\nimport pandas as pd\n\nfrom envrs.download_path import make_url",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#in-situ-soil-moisture-sensors",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#in-situ-soil-moisture-sensors",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "11.3 In-situ Soil Moisture Sensors",
    "text": "11.3 In-situ Soil Moisture Sensors\nDuring the DrySat project we have placed 5 in-situ measuring stations (METERâ„¢, see image at the top) at strategic locations in Mozambique (Buzi, ChokwÃ©, Mabalane, Mabote and Muanza). The locations are plotted on the following folium map for reference.\n\nlocations = {\n    \"Muanza\": {\"latitude\": -18.9064758, \"longitude\": 34.7738921},\n    \"ChokwÃ©\": {\"latitude\": -24.5894393, \"longitude\": 33.0262595},\n    \"Mabote\": {\"latitude\": -22.0530427, \"longitude\": 34.1227842},\n    \"Mabalane\": {\"latitude\": -23.4258788, \"longitude\": 32.5448211},\n    \"Buzi\": {\"latitude\": -19.9747305, \"longitude\": 34.1391065},\n}\n\n\nmap = folium.Map(  # noqa: A001\n    max_bounds=True,\n    zoom_start=6,\n    location=[-20, 34],\n    scrollWheelZoom=False,\n)\n\nfor i, j in locations.items():\n    folium.Marker(\n        location=[j[\"latitude\"], j[\"longitude\"]],\n        popup=i,\n    ).add_to(map)\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nThese 5 stations each have 4 in-situ soil moisture sensors (Campbell Scientificâ„¢ HydroSense II with CS659) installed at depth intervals of 5, 10, 15, and 30\\(\\,\\)cm. The deeper layers may not be directly pertinent to H SAF ASCAT SSM values, but they are important for another product derived from ASCAT data: the Soil Water Index, which assesses the moisture content of deeper layers. We will explore this further in a later notebook. The soil moisture content is measured every 15 minutes and directly stored in the cloud. Since their installation at the end of September 2023, these stations have continually gathered data. For this exercise, we have already cleaned and reformatted a portion of this dataset, which now includes only the measurements from the 5\\(\\,\\)cm depth interval. Please consult us if you need access to the entire raw dataset.\nItâ€™s interesting to learn that the current in situ reference datasets are heavily focused on Europe and the USA (as seen on the ISMN MAP) due to data availability, which likely introduces bias into satellite products. Consequently, reference data from regions outside Europe and the USA are particularly valuable.\nWe load the data again as a pandas.DataFrame, like so:\n\nRANGE = (\"2023-09-30\", \"2025-05-06\")\ndf_insitu = pd.read_csv(\n    make_url(\"insitu_ssm_timeseries.csv\"),\n    index_col=\"time\",\n    parse_dates=True,\n)\nmask = (df_insitu.index &gt; RANGE[0]) & (df_insitu.index &lt;= RANGE[1])\ndf_insitu = df_insitu[mask]\ndf_insitu.head()\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/insitu_ssm_timeseries.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\nname\ntype\nsurface_soil_moisture\nunit\n\n\ntime\n\n\n\n\n\n\n\n\n2023-09-30 22:00:00\nBuzi\nin-situ\n0.106400\nmÂ³/mÂ³\n\n\n2023-09-30 22:15:00\nBuzi\nin-situ\n0.106434\nmÂ³/mÂ³\n\n\n2023-09-30 22:30:00\nBuzi\nin-situ\n0.106400\nmÂ³/mÂ³\n\n\n2023-09-30 22:45:00\nBuzi\nin-situ\n0.106434\nmÂ³/mÂ³\n\n\n2023-09-30 23:00:00\nBuzi\nin-situ\n0.106400\nmÂ³/mÂ³\n\n\n\n\n\n\n\nNext, we will load the H SAF SSM 6.25\\(\\,\\)km data as we did in the previous notebook. This time, however, we will filter the data to include only dates for which both ASCAT and in situ measurements are available.\n\ndf_ascat = pd.read_csv(\n    make_url(\"ascat-6_25_ssm_timeseries.csv\"),\n    index_col=\"time\",\n    parse_dates=True,\n)\nmask = (df_ascat.index &gt; RANGE[0]) & (df_ascat.index &lt;= RANGE[1])\ndf_ascat = df_ascat[mask]\ndf_ascat.head()\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/ascat-6_25_ssm_timeseries.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\nname\ntype\nsurface_soil_moisture\nunit\n\n\ntime\n\n\n\n\n\n\n\n\n2023-09-30 19:16:05.482000384\nChokwÃ©\nascat\n54.48\n%\n\n\n2023-09-30 20:08:26.582000128\nChokwÃ©\nascat\n49.17\n%\n\n\n2023-10-01 06:29:06.317000192\nChokwÃ©\nascat\n54.97\n%\n\n\n2023-10-01 07:21:28.896999936\nChokwÃ©\nascat\n46.66\n%\n\n\n2023-10-01 18:55:21.116000256\nChokwÃ©\nascat\n53.92\n%\n\n\n\n\n\n\n\nNote, that the units of the in situ measurements differ when compared to the H SAF ASCAT SSM data. The in-situ sensors record soil moisture in volumetric units as cubic meters of water per cubic meters of soil [m\\(^3\\) / m\\(^3\\)]. By contrast, the satellite derived estimates are presented as the degree of saturation in the pore spaces of the remotely sensed soil.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#degree-of-saturation-vs.-volumetric-soil-water-content",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#degree-of-saturation-vs.-volumetric-soil-water-content",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "11.4 Degree of Saturation vs.Â Volumetric Soil Water Content",
    "text": "11.4 Degree of Saturation vs.Â Volumetric Soil Water Content\nTo enable an absolute comparison of both data sources, we will first convert the degree of saturation used in the H SAF ASCAT dataset to volumetric units. This will allow us to compare the satellite-derived estimates with the measurements from the in-situ sensors. To achieve this, we need to know the porosity of the soil at the sensor locations. If the porosity is unknown, we can estimate it using a fixed particle density and the location-specific bulk density, as shown in the following expression.\n\\[\n\\text{Porosity} = 1 - \\frac{\\rho_{\\text{bulk}}}{\\rho_{\\text{particle}}}\n\\]\n\\[\n\\begin{aligned}\n\\text{Porosity} &\\quad \\text{: Total pore space in the soil (-)} \\\\\n\\rho_{\\text{bulk}} &\\quad \\text{: Bulk density (in g/cmÂ³)} \\\\\n\\rho_{\\text{particle}} &\\quad \\text{: Particle density (in g/cmÂ³)} \\\\\n\\end{aligned}\n\\]\nFor your convenience, we have obtain the location-specific bulk density for our targeted areas in Mozambique from SoilGrids. The particle density is typically averaged at about 2.65 g/cmÂ³1.\n\ndensity_df = pd.DataFrame(\n    {\n        \"name\": [\"Buzi\", \"ChokwÃ©\", \"Mabalane\", \"Mabote\", \"Muanza\"],\n        \"bulk_density\": [1.25, 1.4, 1.4, 1.35, 1.25],\n    }\n).set_index(\"name\")\ndensity_df\n\n\n\n\n\n\n\n\nbulk_density\n\n\nname\n\n\n\n\n\nBuzi\n1.25\n\n\nChokwÃ©\n1.40\n\n\nMabalane\n1.40\n\n\nMabote\n1.35\n\n\nMuanza\n1.25\n\n\n\n\n\n\n\nWe can now calculate the soil porosity from the bulk and particle density using the pandas transform method. After that, we will rename the column to â€œporosityâ€.\n\ndef calc_porosity(x: pd.Series) -&gt; pd.Series:\n    \"\"\"Calculate Porosity.\n\n    Parameters\n    ----------\n    x: Pandas.Series\n        Bulk Density\n\n    Returns\n    -------\n        Pandas.Series: Porosity\n\n    \"\"\"\n    return 1 - x / 2.65\n\n\nporosity_df = density_df.transform(calc_porosity).rename(\n    columns={\"bulk_density\": \"porosity\"}\n)\nporosity_df\n\n\n\n\n\n\n\n\nporosity\n\n\nname\n\n\n\n\n\nBuzi\n0.528302\n\n\nChokwÃ©\n0.471698\n\n\nMabalane\n0.471698\n\n\nMabote\n0.490566\n\n\nMuanza\n0.528302\n\n\n\n\n\n\n\nNow we have the necessary information to convert the H SAF ASCAT SSM to volumetric units by using the following equation.\n\\[\n\\text{SSM}_{\\text{abs}} = \\text{Porosity} \\cdot \\frac{\\text{SSM}_{\\text{rel}}}{100}\n\\]\n\\[\n\\begin{aligned}\n\\text{SSM}_{\\text{abs}} &\\quad \\text{: Absolute soil moisture, how much of the total soil volume is water (in mÂ³/mÂ³)} \\\\\n\\text{SSM}_{\\text{rel}} &\\quad \\text{: Relative soil moisture in the pore spaces (in \\%)}\n\\end{aligned}\n\\]\nTo apply this conversion to the HSAF dataset, we will first join the porosity values to the Soil Moisture (SSM) values based on the location names using a method called a â€œleft joinâ€. A left join in pandas merges two DataFrames while keeping all rows from the left DataFrame and adding matching rows from the right DataFrame. If thereâ€™s no match, it fills with NaN (see the figure for a schematic overview).\n\n\n\nSource: Pandas User Guide\n\n\nIn this case, weâ€™ll use the merge method, joining the left dataset on its â€˜nameâ€™ column with the right dataset using its index labeled â€˜nameâ€™.\n\ndf_ascat_porosity = df_ascat.merge(porosity_df, left_on=\"name\", right_index=True)\ndf_ascat_porosity.head()\n\n\n\n\n\n\n\n\nname\ntype\nsurface_soil_moisture\nunit\nporosity\n\n\ntime\n\n\n\n\n\n\n\n\n\n2023-09-30 19:16:05.482000384\nChokwÃ©\nascat\n54.48\n%\n0.471698\n\n\n2023-09-30 20:08:26.582000128\nChokwÃ©\nascat\n49.17\n%\n0.471698\n\n\n2023-10-01 06:29:06.317000192\nChokwÃ©\nascat\n54.97\n%\n0.471698\n\n\n2023-10-01 07:21:28.896999936\nChokwÃ©\nascat\n46.66\n%\n0.471698\n\n\n2023-10-01 18:55:21.116000256\nChokwÃ©\nascat\n53.92\n%\n0.471698\n\n\n\n\n\n\n\nWe can now use the pandas apply method to convert the units. This method takes the whole DataFrame as input allowing us to compute on two columns, while returning one column as output.\n\ndef deg2vol(df: pd.DataFrame) -&gt; pd.Series:\n    \"\"\"Degree of Saturation to Volumetric Units.\n\n    Parameters\n    ----------\n    df: Pandas.DataFrame\n        Degree of Saturation\n\n    Returns\n    -------\n        Pandas.Series: Volumetric Units\n\n    \"\"\"\n    return df[\"porosity\"] * df[\"surface_soil_moisture\"] / 100\n\n\ndf_ascat_vol = df_ascat.copy()\ndf_ascat_vol[\"unit\"] = \"mÂ³/mÂ³\"\ndf_ascat_vol[\"surface_soil_moisture\"] = df_ascat_porosity.apply(deg2vol, axis=1)\ndf_ascat_vol.head()\n\n\n\n\n\n\n\n\nname\ntype\nsurface_soil_moisture\nunit\n\n\ntime\n\n\n\n\n\n\n\n\n2023-09-30 19:16:05.482000384\nChokwÃ©\nascat\n0.256981\nmÂ³/mÂ³\n\n\n2023-09-30 20:08:26.582000128\nChokwÃ©\nascat\n0.231934\nmÂ³/mÂ³\n\n\n2023-10-01 06:29:06.317000192\nChokwÃ©\nascat\n0.259292\nmÂ³/mÂ³\n\n\n2023-10-01 07:21:28.896999936\nChokwÃ©\nascat\n0.220094\nmÂ³/mÂ³\n\n\n2023-10-01 18:55:21.116000256\nChokwÃ©\nascat\n0.254340\nmÂ³/mÂ³",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#validation-by-visual-inspection",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#validation-by-visual-inspection",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "11.5 Validation by Visual Inspection",
    "text": "11.5 Validation by Visual Inspection\nThe first step is to visually compare the time series. Visual inspection is essential for ensuring the validity and reliability of your results. It helps identify patterns and trends that might not be evident from data tables. Additionally, it is crucial for detecting outliers, which could indicate sensor malfunctions or data entry errors. In our case, we aim to see if both the in-situ and H SAF ASCAT SSM accurately reflect the characteristic seasonal rains of Mozambique.\nTo facilitate a clear overview, we will first concatenate the two datasets as follows:\n\ndf_combined = pd.concat([df_insitu, df_ascat_vol])\ndf_combined.head()\n\n\n\n\n\n\n\n\nname\ntype\nsurface_soil_moisture\nunit\n\n\ntime\n\n\n\n\n\n\n\n\n2023-09-30 22:00:00\nBuzi\nin-situ\n0.106400\nmÂ³/mÂ³\n\n\n2023-09-30 22:15:00\nBuzi\nin-situ\n0.106434\nmÂ³/mÂ³\n\n\n2023-09-30 22:30:00\nBuzi\nin-situ\n0.106400\nmÂ³/mÂ³\n\n\n2023-09-30 22:45:00\nBuzi\nin-situ\n0.106434\nmÂ³/mÂ³\n\n\n2023-09-30 23:00:00\nBuzi\nin-situ\n0.106400\nmÂ³/mÂ³\n\n\n\n\n\n\n\nNext, we will use the hvplot extension for pandas to create interactive scatter plots for the time series.\n\ndf_combined.hvplot.scatter(\n    x=\"time\",\n    y=\"surface_soil_moisture\",\n    by=\"type\",\n    groupby=\"name\",\n    frame_width=800,\n    padding=(0.01, 0.1),\n    alpha=0.5,\n)\n\n\n\n\n\n  \n\n\n\n\nThese plots already assure us that the trends in both data records align with the monotonic trends characteristic of soil wetting during Mozambiqueâ€™s rainy season.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#quantitative-validation-metrics",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#quantitative-validation-metrics",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "11.6 Quantitative Validation Metrics",
    "text": "11.6 Quantitative Validation Metrics\nWe can now move to a more quantitative estimate. Correlation analysis is a valuable tool for validating meteorological records by comparing different datasets to ensure consistency and accuracy. It measures the strength and direction of the relationship between two variables. In the context of meteorological records, it helps assess how well different datasets align with each other in terms of temporal dynamics, serving as a quality assurance measure.\nBefore applying correlation analysis, we need to reshape our DataFrame by pairing the data to the same timestamps for each of the five locations. For this, we will use the groupby method in combination with the resample method. The resample method will adjust the time index to a new frequency of 1 day, using the median value to down sample the frequencies from 15 minutes to daily for both ASCAT and in-situ sensor data.\n\ndf_insitu_daily = (\n    df_insitu.groupby(\"name\")[\"surface_soil_moisture\"]\n    .resample(\"D\")\n    .median()\n    .to_frame(\"in-situ\")\n)\n\ndf_ascat_vol_daily = (\n    df_ascat_vol.groupby(\"name\")[\"surface_soil_moisture\"]\n    .resample(\"D\")\n    .median()\n    .to_frame(\"ascat\")\n)\n\ndf_resampled = df_ascat_vol_daily.join(df_insitu_daily)\ndf_resampled = df_resampled.dropna()\ndf_resampled.head()\n\n\n\n\n\n\n\n\n\nascat\nin-situ\n\n\nname\ntime\n\n\n\n\n\n\nBuzi\n2023-10-01\n0.068072\n0.110634\n\n\n2023-10-03\n0.048498\n0.113430\n\n\n2023-10-05\n0.067623\n0.113479\n\n\n2023-10-06\n0.052117\n0.113479\n\n\n2023-10-08\n0.060834\n0.112111\n\n\n\n\n\n\n\nThe data is now ready for correlation analysis. For time series analysis, if youâ€™re looking at trends and expect a linear relationship, Pearson correlation is straightforward and precise method.\n\\[ r = \\frac{ \\sum_{i=1}^{n} (x_i - \\bar{x}) (y_i - \\bar{y}) }{ \\sqrt{ \\sum_{i=1}^{n} (x_i - \\bar{x})^2 } \\sqrt{ \\sum_{i=1}^{n} (y_i - \\bar{y})^2 } } \\]\nwhere:\n\\[\n\\begin{aligned}\nn &\\quad \\text{: number of data points} \\\\\nx_i  \\; \\text{and} \\; y_i &\\quad \\text{: individual sample points} \\\\\n\\bar{x} &\\quad \\text{: mean of the} \\; x \\; \\text{values} \\\\\n\\bar{y} &\\quad \\text{:  mean of the} \\; y \\;  \\text{values}\n\\end{aligned}\n\\]\nThe Pearson correlation coefficient ranges from -1 to 1:\n\n\\(r = 1\\) indicates a perfect positive linear relationship.\n\\(r = -1\\) indicates a perfect negative linear relationship.\n\\(r = 0\\) indicates no linear relationship.\n\nWe implement this with pandas, as follows:\n\ndf_resampled.groupby(\"name\").corr(method=\"pearson\")\n\n\n\n\n\n\n\n\n\nascat\nin-situ\n\n\nname\n\n\n\n\n\n\n\nBuzi\nascat\n1.000000\n0.663829\n\n\nin-situ\n0.663829\n1.000000\n\n\nChokwÃ©\nascat\n1.000000\n0.644887\n\n\nin-situ\n0.644887\n1.000000\n\n\nMabalane\nascat\n1.000000\n0.729945\n\n\nin-situ\n0.729945\n1.000000\n\n\nMabote\nascat\n1.000000\n0.584710\n\n\nin-situ\n0.584710\n1.000000\n\n\nMuanza\nascat\n1.000000\n0.669616\n\n\nin-situ\n0.669616\n1.000000\n\n\n\n\n\n\n\nUse Spearman correlation when the relationship between your time series is not necessarily linear but generally moves in the same direction (monotonic).\n\\[\\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)} \\]\nwhere:\n\\[\n\\begin{aligned}\nn &\\quad \\text{: number of observations} \\\\\nd_i &\\quad \\text{: difference between the ranks of corresponding values} \\; x_i \\; \\text{and} \\;  y_i\n\\end{aligned}\n\\]\nThe interpretation of \\(\\rho\\) is the same as for the Pearsonâ€™s correlation (\\(r\\)) coefficient. Spearman is great for data where the ranking of values is important and is less affected by outliers and non-normal distributions. This makes it a robust choice for various types of data. Itâ€™s also easy to interpret because it focuses on the overall trend.\n\ndf_resampled.groupby(\"name\").corr(method=\"spearman\")\n\n\n\n\n\n\n\n\n\nascat\nin-situ\n\n\nname\n\n\n\n\n\n\n\nBuzi\nascat\n1.000000\n0.652317\n\n\nin-situ\n0.652317\n1.000000\n\n\nChokwÃ©\nascat\n1.000000\n0.595828\n\n\nin-situ\n0.595828\n1.000000\n\n\nMabalane\nascat\n1.000000\n0.754692\n\n\nin-situ\n0.754692\n1.000000\n\n\nMabote\nascat\n1.000000\n0.720681\n\n\nin-situ\n0.720681\n1.000000\n\n\nMuanza\nascat\n1.000000\n0.593781\n\n\nin-situ\n0.593781\n1.000000\n\n\n\n\n\n\n\nThe correlation coefficients for both Pearson and Spearman methods range between 0.6 and 0.8 across different locations, indicating moderate to high positive correlations between the ASCAT HSAF 6.25\\(\\,\\)km data and the in-situ soil moisture estimates.\nSo far, we have only evaluated relative temporal trends in the two data sources. However, it is clear from the visual comparison of HSAF ASCAT SSM and in situ soil moisture that there are also absolute differences. To quantify these differences, we will first calculate the bias between in situ and remotely sensed soil moisture. Using Pandas, this involves comparing the mean of the target values (remotely sensed SSM) to the mean of the reference values (in situ SSM). Bias is determined by the difference between these means.\n\\[ \\text{Bias} = \\bar{x}_i - \\bar{y}_i \\]\nwhere:\n\\[\n\\begin{aligned}\n\\bar{y}_i &\\quad \\text{: mean target value (remotely sensed SSM)} \\\\\n\\bar{x}_i &\\quad \\text{: mean reference value (in situ SSM)}\n\\end{aligned}\n\\]\nWhich we can easily implement, like so:\n\n(\n    df_resampled.groupby(\"name\")[\"in-situ\"].mean()\n    - df_resampled.groupby(\"name\")[\"ascat\"].mean()\n)\n\nname\nBuzi        0.001074\nChokwÃ©      0.012045\nMabalane   -0.061894\nMabote     -0.071499\nMuanza     -0.040774\ndtype: float64\n\n\nAbove, we observe the systematic error (in m\\(^3\\)/m\\(^3\\)) for each location. The H SAF ASCAT values are generally lower than the paired in situ observations, with the exception of ChokwÃ© and Buzi. However, these differences are relatively small.\nAn interrelated yet distinct statistic is the Root Mean Square Error (RMSE).\n\\[ \\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - x_i)^2 } \\]\nwhere:\n\\[\n\\begin{aligned}\nn &\\quad \\text{: number of observations} \\\\\ny_i &\\quad \\text{: target value (remotely sensed SSM)} \\\\\nx_i &\\quad \\text{: reference value (in situ SSM)}\n\\end{aligned}\n\\]\nWhereas bias contributes to the overall error measured by RMSE, RMSE captures both the bias and the variance components of the error. The relationship can be expressed through the bias-variance tradeoff:\n\nBias: Reflects the absolute difference among in situ and remotely sensed soil moisture\nVariance: Reflects the relative differences among in situ and remotely sensed soil moisture\nIrreducible Error: The inherent noise or randomness in the data that cannot be explained\n\nThe total error, as captured by RMSE, can be broken down as:\n\\[ \\text{Total Error (RMSE)} = \\text{Bias}^2+\\text{Variance}+\\text{Irreducible Error} \\]\nThis can be implemented, as follows:\n\ndef rmse(df: pd.DataFrame) -&gt; pd.Series:\n    \"\"\"Root Mean Square Error.\n\n    Parameters\n    ----------\n    df: Pandas.DataFrame\n        Target \"ascat\" and reference \"in situ\" columns\n\n    Returns\n    -------\n        Pandas.Series: Root Mean Square Error\n\n    \"\"\"\n    return ((df[\"ascat\"] - df[\"in-situ\"]) ** 2).mean() ** 0.5\n\n\ndf_resampled.groupby(\"name\").apply(rmse)\n\nname\nBuzi        0.066416\nChokwÃ©      0.071972\nMabalane    0.074553\nMabote      0.082575\nMuanza      0.060688\ndtype: float64\n\n\nHere, we see that the RMSE ranges between 0.06 and 0.08 [m\\(^3\\) / m\\(^3\\)], which is small compared to the total range of H SAF ASCAT SSM. As a final step, we can visualize the relation of target (remotely sensed SSM) and reference values (in situ soil moisture) using hvplot.\n\nhvplot.scatter_matrix(df_resampled.reset_index(level=0), c=\"name\", alpha=0.3).opts(\n    plot_size=300\n)\n\n\n\n\n\n  \n\n\n\n\nHere, we observe that the relationship between in-situ and remotely sensed values is not entirely linear. Additionally, it indicates that soil moisture data is generally not normally distributed.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#scale-of-measurement",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#scale-of-measurement",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "11.7 Scale of Measurement",
    "text": "11.7 Scale of Measurement\nWe can only speculate about the reasons for the absolute and relative discrepancies, but it is important to note that the scale of in-situ measurements, which cover several centimeters around the device, compared to the averaged soil moisture value obtained by ASCAT, which encompasses about 50\\(\\,\\)km\\(^2\\), might be a significant factor in explaining these differences. One can wonder what an averaged signal over such a broad area encompasses, as it can include a range of geomorphological, hydrological, and geological settings. Additionally, weather patterns can be confined to scales smaller than this area.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#footnotes",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/02_handout_drought.html#footnotes",
    "title": "11Â  Evaluating the Reliability of Remotely Sensed Soil Moisture",
    "section": "",
    "text": "RÃ¼hlmann, M. KÃ¶rschens, and J. Graefe, A new approach to calculate the particle density of soils considering properties of the soil organic matter and the mineral matrix, Geoderma, vol.Â 130, no. 3, pp.Â 272-283, Feb.Â 2006, doi: 10.1016/j.geoderma.2005.01.024.â†©ï¸Ž",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>11</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Soil Moisture</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "",
    "text": "12.1 Overview\nComparing Various Drought Indicators\nThis notebook continues the evaluation of drought indicators introduced in notebook 1. The H SAF ASCAT sensors onboard the MetOp series of polar-orbiting satellites supply near real-time surface soil moisture (SSM) estimates, with data extending back to 2007. This extensive record allows us to compute temporal anomalies from the SSM data, using the long-term mean as a baseline. These anomalies are then standardized as deviations, or Z scores.\nAs noted in notebook 1, ASCAT SSM is measured in degrees of saturation, making spatial patterns reliant on soil characteristics such as porosity. However, the temporal changes used for drought anomaly detection with Z scores can provide insights into spatial patterns of drought conditions without requiring auxiliary soil data.\nWe will leverage this feature to compare the H SAF ASCAT SSM-based drought indicators with other drought indicators, notably the Standardized Precipitation-Evapotranspiration Index1.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#imports",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#imports",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.2 Imports",
    "text": "12.2 Imports\n\nimport cartopy.crs as ccrs\nimport datashader as ds\nimport holoviews as hv\nimport hvplot.pandas  # noqa\nimport numpy as np\nimport pandas as pd\n\nfrom envrs.download_path import make_url\n\nERROR 1: PROJ: proj_create_from_database: Open of /home/runner/work/eo-datascience/eo-datascience/.conda_envs/environmental-remote-sensing/share/proj failed",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#standardized-precipitation-evapotranspiration-index",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#standardized-precipitation-evapotranspiration-index",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.3 Standardized Precipitation-Evapotranspiration Index",
    "text": "12.3 Standardized Precipitation-Evapotranspiration Index\nHistorically, many studies on drought monitoring have used hydro-meteorological indicators such as the Standardized Precipitation Index (SPI) and the more comprehensive Standardized Precipitation-Evapotranspiration Index (SPEI). SPEI is seen as the more robust metric for drought monitoring as it uses the difference between precipitation and potential evapotranspiration (\\(P â€“ ETo\\)), rather than precipitation (\\(P\\)) as an input alone, and, where the potential evapotranspiration can be calculated from weather data. However, satellite-based soil moisture estimates, and linked drought anomaly indices (e.g., Z scores) might be more suitable for agricultural drought monitoring as they focus more directly on plant water requirements by directly measuring the soilâ€™s available water content.\nBoth SPEI and standardized soil moisture drought anomalies, such as Z scores, allow for direct comparisons across different regions and time scales.\nTo summarize:\n\nSPEI is a hydro-meteorological indicator for drought monitoring based on anomalies in precipitation and evapotranspiration\nZ scores are based on standardized anomalies derived from soil moisture; e.g., spaceborne microwave-retrieved surface soil moisture\n\nThe purpose of this notebook is to compare both drought indicators, particularly focusing on the spatial extent of drought-affected areas. We will relate these indicators to recorded drought events in Mozambique between 2007 and 2021 (The International Disaster Database).\n\n\n\n\n\n\n\n\nYear/Period\nAffected Provinces\nEstimated Affected People\n\n\n\n\n2008 (Early)\nMaputo, Gaza, Inhambane, Manica, Sofala, Tete\n~1.2 million\n\n\n2010\nMaputo, Gaza, Inhambane\n~460,000\n\n\n2015â€“2016 (El NiÃ±o)\nMaputo, Gaza, Inhambane, Sofala, Tete\n~2.3 million\n\n\n2021\nCabo Delgado, Tete (south), Manica (north)\n~1.56 million\n\n\n\nWe first load monthly aggregated SPEI data in the following code cell.\n\nurl = make_url(\"spei-6_25_monthly.csv\")\ndf_spei = pd.read_csv(\n    url,\n    index_col=[\"time\", \"location_id\"],\n    parse_dates=[\"time\"],\n)\ndf_spei\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/spei-6_25_monthly.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\n\nlatitude\nlongitude\nspei\n\n\ntime\nlocation_id\n\n\n\n\n\n\n\n2007-01-01\n10234428\n-26.855516\n32.357162\n-1.563430\n\n\n10235038\n-26.849566\n32.621094\n-1.418305\n\n\n10235648\n-26.843615\n32.885020\nNaN\n\n\n10236025\n-26.839937\n32.457973\n-1.502107\n\n\n10236635\n-26.833986\n32.721905\n-1.427557\n\n\n...\n...\n...\n...\n...\n\n\n2021-12-01\n11992443\n-10.611925\n40.540737\nNaN\n\n\n11993430\n-10.603155\n40.377617\n-1.170215\n\n\n11995027\n-10.588965\n40.478430\nNaN\n\n\n11997611\n-10.566007\n40.416126\n-1.141002\n\n\n12001792\n-10.528863\n40.454630\nNaN\n\n\n\n\n3548880 rows Ã— 3 columns\n\n\n\nNow letâ€™s also load monthly aggregated H SAF ASCAT SSM Z scores which we already prepared for notebook 1. For this exercise we will filter the data to have a comparable time range (up to the end of 2021) as we have for the SPEI data.\n\nurl = make_url(\"ascat-6_25_ssm_monthly.csv\")\ndf_ascat = pd.read_csv(\n    url,\n    index_col=[\"time\", \"location_id\"],\n    parse_dates=[\"time\"],\n)[[\"zscore\"]]\ndf_ascat = df_ascat[df_ascat.index &lt;= df_spei.index.max()]\ndf_ascat\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/ascat-6_25_ssm_monthly.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\n\nzscore\n\n\ntime\nlocation_id\n\n\n\n\n\n2007-01-01\n10250165\n-0.399316\n\n\n10243400\n-0.141156\n\n\n10246361\n0.151953\n\n\n10250542\n0.136301\n\n\n10278822\n-1.098983\n\n\n...\n...\n...\n\n\n2021-12-01\n11636071\n-1.405369\n\n\n11636825\n-2.288949\n\n\n11637613\n-1.492089\n\n\n11628230\n-2.038554\n\n\n11639731\n-2.264238\n\n\n\n\n3548880 rows Ã— 1 columns",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#merging-drought-indicator-data",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#merging-drought-indicator-data",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.4 Merging Drought Indicator Data",
    "text": "12.4 Merging Drought Indicator Data\nNow we will have to combine both datasets. Fortunately, both datasets are already projected on the same grid, so this task does not involve any re-projection and resampling of the data. The join operation is made easy here as we have already defined the same indexes in both datasets when loading the data. We can, in this case, use the join method, which joins the data based on the index values of the left and right datasets.\n\ndf_wide = df_spei.join(df_ascat)\ndf_wide\n\n\n\n\n\n\n\n\n\nlatitude\nlongitude\nspei\nzscore\n\n\ntime\nlocation_id\n\n\n\n\n\n\n\n\n2007-01-01\n10234428\n-26.855516\n32.357162\n-1.563430\n-0.371901\n\n\n10235038\n-26.849566\n32.621094\n-1.418305\n-0.687805\n\n\n10235648\n-26.843615\n32.885020\nNaN\n-0.721146\n\n\n10236025\n-26.839937\n32.457973\n-1.502107\n-0.183039\n\n\n10236635\n-26.833986\n32.721905\n-1.427557\n-0.285288\n\n\n...\n...\n...\n...\n...\n...\n\n\n2021-12-01\n11992443\n-10.611925\n40.540737\nNaN\n-1.488362\n\n\n11993430\n-10.603155\n40.377617\n-1.170215\n-1.797294\n\n\n11995027\n-10.588965\n40.478430\nNaN\n-1.587852\n\n\n11997611\n-10.566007\n40.416126\n-1.141002\n-1.628807\n\n\n12001792\n-10.528863\n40.454630\nNaN\n-1.572855\n\n\n\n\n3548880 rows Ã— 4 columns\n\n\n\nThis operation produced a â€œrecordâ€ or â€œwideâ€ format dataset, typically there is one row for each subject, in this case the indicators â€œspeiâ€ and â€œzscoresâ€ as well as the coordinates.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#simplifying-drought-severity-with-data-binning",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#simplifying-drought-severity-with-data-binning",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.5 Simplifying Drought Severity with Data Binning",
    "text": "12.5 Simplifying Drought Severity with Data Binning\nWe will convert the numeric data of the drought indicators \"spei\" and \"zscore\" into discrete categories using the pandas cut method. In pandas, binning dataâ€”also known as discretization or quantizationâ€”involves dividing continuous numerical data into discrete bins or intervals. This process is beneficial for sharing quantitative data with other users who can easily interpret it, but also it manages outliers, helps creating histograms, and prepares data for machine learning algorithms that require categorical input. Additionally, we will label the binned data, thereby transforming the columns into pandas categorical data types. Pandas categorical data types are used to represent data that takes on a limited and usually fixed number of possible values (categories or classes). This type is particularly useful for categorical variables such as gender, days of the week, or survey responses. It offers efficient storage and operations for categorical data, including handling category ordering and missing values.\nThe process of binning and labeling drought data based on intensity is somewhat subjective, as the bin thresholds are often arbitrarily assigned and subject to debate. Here, we adhere to the guidelines provided by the World Meteorological Organization and the definitions by McKee et al.Â (1993)2 for standardized soil moisture based drought indices, where a â€œmoderateâ€ drought is defined as starting at -1 unit of standard deviations.\n\ndrought_labels = np.array([\"extreme\", \"severe\", \"moderate\", \"mild\", \"normal\"])\nzscore_thresholds = [df_wide[\"zscore\"].min(), -2, -1.5, -1, 0, df_wide[\"zscore\"].max()]\nspei_thresholds = [df_wide[\"spei\"].min(), -2, -1.5, -1, 0, df_wide[\"spei\"].max()]\n\nNow we can use the labels and thresholds to bin the columns of the drought indicators. We make a copy of the original data so that we preserve the original dataset.\n\ndf_wide_cat = df_wide.copy()\ndf_wide_cat[\"zscore\"] = pd.cut(df_wide.zscore, zscore_thresholds, labels=drought_labels)\ndf_wide_cat[\"spei\"] = pd.cut(df_wide.spei, spei_thresholds, labels=drought_labels)\ndf_wide_cat\n\n\n\n\n\n\n\n\n\nlatitude\nlongitude\nspei\nzscore\n\n\ntime\nlocation_id\n\n\n\n\n\n\n\n\n2007-01-01\n10234428\n-26.855516\n32.357162\nsevere\nmild\n\n\n10235038\n-26.849566\n32.621094\nmoderate\nmild\n\n\n10235648\n-26.843615\n32.885020\nNaN\nmild\n\n\n10236025\n-26.839937\n32.457973\nsevere\nmild\n\n\n10236635\n-26.833986\n32.721905\nmoderate\nmild\n\n\n...\n...\n...\n...\n...\n...\n\n\n2021-12-01\n11992443\n-10.611925\n40.540737\nNaN\nmoderate\n\n\n11993430\n-10.603155\n40.377617\nmoderate\nsevere\n\n\n11995027\n-10.588965\n40.478430\nNaN\nsevere\n\n\n11997611\n-10.566007\n40.416126\nmoderate\nsevere\n\n\n12001792\n-10.528863\n40.454630\nNaN\nsevere\n\n\n\n\n3548880 rows Ã— 4 columns\n\n\n\nThe simplified labeled drought indicators now enable us to take the first step in assessing the spatial extent.\nTo perform a sanity check on our results, we will recreate the plot from notebook 1, but this time using categorical data types for the drought indicators. However, before we can plot this data, we need to reshape it into a â€œlongâ€ or â€œstackedâ€ format. This format will allow us to use the groupby parameter of the hvplot extension for pandas. We will reshape the data using the pandas melt method, keeping the indexes and coordinates unchanged while stacking the indicator values. The variable column will identify the drought indicator.\n\n\n\nSource: Pandas User Guide\n\n\n\ndf_long = df_wide_cat.melt(id_vars=[\"latitude\", \"longitude\"], ignore_index=False)\ndf_long\n\n\n\n\n\n\n\n\n\nlatitude\nlongitude\nvariable\nvalue\n\n\ntime\nlocation_id\n\n\n\n\n\n\n\n\n2007-01-01\n10234428\n-26.855516\n32.357162\nspei\nsevere\n\n\n10235038\n-26.849566\n32.621094\nspei\nmoderate\n\n\n10235648\n-26.843615\n32.885020\nspei\nNaN\n\n\n10236025\n-26.839937\n32.457973\nspei\nsevere\n\n\n10236635\n-26.833986\n32.721905\nspei\nmoderate\n\n\n...\n...\n...\n...\n...\n...\n\n\n2021-12-01\n11992443\n-10.611925\n40.540737\nzscore\nmoderate\n\n\n11993430\n-10.603155\n40.377617\nzscore\nsevere\n\n\n11995027\n-10.588965\n40.478430\nzscore\nsevere\n\n\n11997611\n-10.566007\n40.416126\nzscore\nsevere\n\n\n12001792\n-10.528863\n40.454630\nzscore\nsevere\n\n\n\n\n7097760 rows Ã— 4 columns\n\n\n\nNow we can plot the data, where we the datashader method by and any to deal with the new categorical data type when turning the data to a raster.\n\ncolor_key = {\n    \"extreme\": \"#bb0c0c\",\n    \"severe\": \"#c57b19\",\n    \"moderate\": \"#b1bb29\",\n    \"mild\": \"#1cd87a\",\n    \"normal\": \"#ffffff\",\n}\n\n\nlegend = (\n    df_long[~df_long.index.duplicated()]\n    .dropna()\n    .hvplot.points(\n        x=\"longitude\",\n        y=\"latitude\",\n        c=\"value\",\n        groupby=\"time\",\n        color_key=color_key,\n        crs=ccrs.PlateCarree(),\n    )\n)\n\n\nmap = df_long.hvplot.points(  # noqa: A001\n    x=\"longitude\",\n    y=\"latitude\",\n    c=\"value\",\n    groupby=[\"variable\", \"time\"],\n    x_sampling=0.1,\n    y_sampling=0.1,\n    aggregator=ds.by(\"value\", ds.any()),\n    rasterize=True,\n    crs=ccrs.PlateCarree(),\n    tiles=True,\n    frame_width=500,\n    clabel=\"Drought anomaly\",\n    color_key=color_key,\n    colorbar=False,\n)\nlegend * map",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#spatial-drought-extent-through-time",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#spatial-drought-extent-through-time",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.6 Spatial Drought Extent Through Time",
    "text": "12.6 Spatial Drought Extent Through Time\nNow that we have classified drought intensity into categories, letâ€™s calculate the spatial extent of droughts over time. This will enable us to compare how the two standardized drought indices relate to each other. Conveniently, we can use the pandas value_count method on the new categorical columns \"spei\" and \"zscore\", and also employ the normalize parameter to get relative frequencies. This provides an understanding of how many data points fall into each drought class relative to the total number of observations for a certain month.\n\ncol_spei = (\n    df_wide_cat.groupby(level=0)[\"spei\"].value_counts(normalize=True).unstack()  # noqa: PD010\n)\ncol_zscore = (\n    df_wide_cat.groupby(level=0)[\"zscore\"].value_counts(normalize=True).unstack()  # noqa: PD010\n)\n\nWe combine these relative frequencies results.\n\nnew_keys = pd.Index([\"spei\", \"zscore\"], name=\"indicator\")\ndf_drought_extend = pd.concat(\n    [col_spei, col_zscore],\n    keys=new_keys,\n)\ndf_drought_extend\n\n\n\n\n\n\n\n\n\nextreme\nsevere\nmoderate\nmild\nnormal\n\n\nindicator\ntime\n\n\n\n\n\n\n\n\n\nspei\n2007-01-01\n0.000000\n0.013475\n0.037324\n0.218705\n0.730496\n\n\n2007-02-01\n0.000000\n0.000000\n0.003304\n0.266390\n0.730305\n\n\n2007-03-01\n0.000428\n0.041281\n0.176408\n0.670018\n0.111866\n\n\n2007-04-01\n0.000000\n0.015988\n0.037592\n0.381423\n0.564997\n\n\n2007-05-01\n0.065519\n0.118397\n0.153631\n0.251963\n0.410490\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\nzscore\n2021-08-01\n0.001471\n0.016586\n0.054118\n0.283729\n0.644096\n\n\n2021-09-01\n0.004413\n0.024904\n0.058278\n0.319791\n0.592615\n\n\n2021-10-01\n0.006898\n0.028860\n0.096723\n0.421637\n0.445882\n\n\n2021-11-01\n0.003550\n0.066139\n0.251674\n0.439034\n0.239602\n\n\n2021-12-01\n0.303510\n0.207344\n0.172905\n0.143995\n0.172246\n\n\n\n\n360 rows Ã— 5 columns\n\n\n\nAs a final step we will plot the timeseries of the relative spatial extend of the upper three drought clases (â€œmoderateâ€, â€œsevereâ€, and â€œextremeâ€). We compare these results to recorded drought events that had a severe impact on food security and destabelized Mozambique.\n\nmozambique_droughts = [\n    {\"time\": \"2008-01-01\", \"people_affected\": 1.02},\n    {\"time\": \"2010-01-01\", \"people_affected\": 0.46},\n    {\"time\": \"2016-01-01\", \"people_affected\": 2.30},\n    {\"time\": \"2021-01-01\", \"people_affected\": 1.56},\n]\n\ndf_droughts = pd.DataFrame(mozambique_droughts).assign(y=1)\ndf_droughts[\"time\"] = pd.to_datetime(df_droughts[\"time\"], format=\"%Y-%M-%d\")\ndf_droughts = df_droughts.set_index(\"time\")\nlabels = df_droughts.hvplot.labels(\n    x=\"time\",\n    y=\"y\",\n    text=\"{people_affected} mill. people\",\n    text_baseline=\"bottom_left\",\n    hover=False,\n    angle=85,\n    text_font_size=\"14px\",\n)\noffset = hv.dim(\"y\") - 0.1\npoints = df_droughts.hvplot.points(\n    x=\"time\", y=\"y\", color=\"black\", hover=False, transforms={\"y\": offset}\n)\ndf_drought_extend.hvplot.area(\n    x=\"time\",\n    y=drought_labels[::-1][2:],\n    groupby=\"indicator\",\n    hover=False,\n    frame_width=800,\n    padding=((0.1, 0.1), (0, 0.9)),\n) * labels * points\n\n\n\n\n\n  \n\n\n\n\nWe observe significant differences between the two drought indicators. The SPEI drought information shows much higher variability compared to the Z-scores derived from H SAF ASCAT SSM data. We find that the spatial extent of the most severe drought classes, as indicated by the Z-scores, aligns well with recorded drought disasters.\nThe higher variability in SPEI might be due to the more variable precipitation input, while soil moisture has a â€œmemoryâ€, i.e.Â soil moisture represents water storage. Precipitation does not account for infiltration and overland flow. In SPEI the type of precipitation is not accounted for, and thus a very intense rainfall event, where a lot of rainfall falls in a short period, will not lead to a sustainable increase in soil water content, and plant available water, as most of the water will not infiltrate in the soil. Therefore, deviations from the norm are likely more subdued in soil moisture data than in SPEI but are more representative for plant available water and is intricately linked to agricultural practices that are crucial for food security in Mozambique.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#a-comprehensive-comparison-of-drought-indicators",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#a-comprehensive-comparison-of-drought-indicators",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.7 A Comprehensive Comparison of Drought Indicators",
    "text": "12.7 A Comprehensive Comparison of Drought Indicators\nTo obtain a more comprehensive and accurate overview of H SAF ASCAT SSM in detecting agriculturally relevant drought events, we will compare it with an additional set of drought indicators. These indicators are monthly Z-scores calculated from different soil moisture estimates. The estimates are derived from in-situ observations, remotely sensed retrievals, or hydro-meteorological models\n\n\n\n\n\n\n\n\n\nDataset\nDescription\nKey Features\nApplications\n\n\n\n\nERA5\nERA5 is a reanalysis dataset produced by ECMWF that provides comprehensive global climate and weather data, including soil moisture.\n- High spatial and temporal resolution- Derived from model simulations and observational inputs- Global coverage\n- Climate research- Hydrological modeling- Agricultural applications- Drought monitoring- Water resource management\n\n\nGLDAS\nThe Global Land Data Assimilation System (GLDAS) soil moisture dataset provides global estimates of soil moisture based on satellite observations, ground measurements, and model simulations.\n- High-resolution and temporally consistent- Integrates various data sources- Developed by NASA and NOAA\n- Hydrological modeling- Climate studies- Agricultural monitoring- Drought assessment- Water resource management- Environmental sustainability\n\n\nESA CCI\nThe ESA CCI (European Space Agency Climate Change Initiative) Soil Moisture project aims to provide long-term, consistent datasets of global soil moisture derived from satellite observations.\n- Long-term and consistent datasets- Derived from satellite observations- Supports scientific research and policy-making\n- Climate research- Hydrological modeling- Agricultural monitoring- Environmental sustainability- Food security studies\n\n\n\nWe have already prepared a dataset that includes all these drought indicators, along with the previously introduced SPEI and ASCAT data (previously labeled \"zscore\").\n\nurl = make_url(\"drought_indices-6_25_monthly.csv\")\ndf_drought_indices = pd.read_csv(\n    url,\n    index_col=[\"time\", \"location_id\"],\n    parse_dates=[\"time\"],\n)\ndf_drought_indices\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/drought_indices-6_25_monthly.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nascat\nera5\nspei\ngldas\ncci\n\n\ntime\nlocation_id\n\n\n\n\n\n\n\n\n\n\n\n2007-01-01\n10234428\n32.357162\n-26.855516\n-0.227513\n-1.177816\n-1.563430\n0.575884\nNaN\n\n\n10235038\n32.621094\n-26.849566\n-0.263700\n-1.105393\n-1.418305\n0.510610\n0.254604\n\n\n10235648\n32.885020\n-26.843615\n-0.524645\n-0.190537\nNaN\nNaN\nNaN\n\n\n10236025\n32.457973\n-26.839937\n0.048931\n-1.105393\n-1.502107\n0.575884\nNaN\n\n\n10236635\n32.721905\n-26.833986\n0.100799\n-1.025658\n-1.427557\n0.510610\n0.254604\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2021-12-01\n11992443\n40.540737\n-10.611925\n-1.532990\n-0.732172\nNaN\nNaN\nNaN\n\n\n11993430\n40.377617\n-10.603155\n-1.312185\n-0.732172\n-1.170215\n-0.656978\nNaN\n\n\n11995027\n40.478430\n-10.588965\n-1.512508\n-0.732172\nNaN\n-0.656978\nNaN\n\n\n11997611\n40.416126\n-10.566007\n-1.333472\n-0.732172\n-1.141002\n-0.656978\nNaN\n\n\n12001792\n40.454630\n-10.528863\n-1.303371\n-0.732172\nNaN\n-0.656978\nNaN\n\n\n\n\n7567809 rows Ã— 7 columns\n\n\n\nTo simplify the calculation of relative drought spatial extent, we will create two functions that loops over the different columns to perform the same analysis as before: 1) set the categorical drought type and 2) calculate relative drought extent.\n\ndef set_drought_cat_type(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Drought Severity Levels.\n\n    Parameters\n    ----------\n    df: Pandas.DataFrame\n        Data frame with continuos drought indicators.\n\n    Returns\n    -------\n        Pandas.DataFrame: Data frame with discrete drought indicators\n\n    \"\"\"\n    col_names = df.drop(columns=[\"longitude\", \"latitude\"]).columns\n    for name in col_names:\n        min_border = df[name].min()\n        max_border = df[name].max()\n        thresholds = np.array(\n            [\n                min_border if min_border &lt; -2 else -2.1,  # noqa: PLR2004\n                -2,\n                -1.5,\n                -1,\n                0,\n                max_border if max_border &gt; 0 else 0.1,\n            ]\n        )\n        df[name] = pd.cut(df[name], thresholds, labels=drought_labels)\n    return df\n\n\ndef calc_drought_areal_extend(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Areal Extent of Drought Severity Levels.\n\n    Parameters\n    ----------\n    df: Pandas.DataFrame\n        Data frame with discrete drought indicators.\n\n    Returns\n    -------\n        Pandas.DataFrame: Data frame with normalize counts of drought levels\n\n    \"\"\"\n    col_names = df.drop(columns=[\"longitude\", \"latitude\"]).columns\n    return pd.concat(\n        [\n            df.groupby(level=0)[col].value_counts(normalize=True).unstack()  # noqa: PD010\n            for col in col_names\n        ],\n        keys=pd.Index(col_names, name=\"indicator\"),\n    )\n\n\ndf_drought_indices_cat = set_drought_cat_type(df_drought_indices.copy())\ndf_drought_extend = calc_drought_areal_extend(df_drought_indices_cat)\ndf_drought_extend.hvplot.area(\n    x=\"time\",\n    y=drought_labels[::-1][2:],\n    groupby=\"indicator\",\n    hover=False,\n    frame_width=800,\n    padding=((0.1, 0.1), (0, 0.9)),\n) * labels * points\n\n\n\n\n\n  \n\n\n\n\nThe additional drought indicators share the characteristic of directly measuring or estimating the soilâ€™s water content by modeling soil geophysical conditions. This comparison validates the earlier observation that the SPEI-inferred drought extent exhibits greater variability compared to indicators based on soil moisture. However, with the exception of the H SAF ASCAT SSM-derived Z scores, all indicators show significant discrepancies in their estimates of drought extent for the five major drought events.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#close-up-of-the-20152016-el-niÃ±o-drought-event",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#close-up-of-the-20152016-el-niÃ±o-drought-event",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "12.8 Close-up of the 2015â€“2016 (El NiÃ±o) Drought Event",
    "text": "12.8 Close-up of the 2015â€“2016 (El NiÃ±o) Drought Event\nLetâ€™s now zoom in on one of the most significant drought disasters of recent history in Mozambique. The 2015-2016 drought event which has been related to El NiÃ±o significantly impacted agriculture, food security, and water resources. This drought was characterized by reduced rainfall and elevated temperatures, exacerbating conditions for farming and livestock. Estimated numbers for people affected by this events are ~2.3 million.\nWe filter this event from the loaded dataset and plot as before with hvplot.\n\ndf_long_2016 = df_drought_indices_cat.loc[\"2016-01-01\"].melt(\n    id_vars=[\"latitude\", \"longitude\"], ignore_index=False\n)\n\nlegend_2016 = (\n    df_long_2016[~df_long_2016.index.duplicated()]\n    .dropna()\n    .hvplot.points(\n        x=\"longitude\",\n        y=\"latitude\",\n        c=\"value\",\n        color_key=color_key,\n        crs=ccrs.PlateCarree(),\n    )\n)\n\nmap_2016 = df_long_2016.hvplot.points(\n    x=\"longitude\",\n    y=\"latitude\",\n    c=\"value\",\n    groupby=[\"variable\"],\n    x_sampling=0.1,\n    y_sampling=0.1,\n    aggregator=ds.by(\"value\", ds.any()),\n    rasterize=True,\n    crs=ccrs.PlateCarree(),\n    tiles=True,\n    frame_width=500,\n    clabel=\"Drought anomaly\",\n    color_key=color_key,\n    colorbar=False,\n)\nlegend_2016 * map_2016\n\n\n\n\n\n  \n\n\n\n\nA visual inspection of the map displaying various drought indicators reveals broad similarities, with most indicators highlighting drought conditions in the southern provinces of Maputo and Gaza, as well as in Sofala, Tete, and Zambezia. However, the spatial patterns also exhibit significant differences in their finer details. These discrepancies are likely influenced by the inherently coarser resolutions of ERA5 (9 km), ESA CCI, and GLDAS (~25 km).",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#footnotes",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/03_handout_drought.html#footnotes",
    "title": "12Â  Evaluating the Reliability of Remotely Sensed Droughts",
    "section": "",
    "text": "S. M. Vicente-Serrano, S. BegueriÂ­a, and J. I.LÃ³pez-Moreno,A Multiscalar Drought Index Sensitive to Global Warming: The Standardized Precipitation Evapotranspiration Index, Journal of Climate, vol.Â 23, no. 7, pp.Â 1696-1718, Apr.Â 2010, doi: 10.1175/2009JCLI2909.1.â†©ï¸Ž\nT. B. McKee, N. J. Doesken, and J. Kleist, The Relationship Of Drought Frequency and Duration to the Timescale. Eighth Conference on Applied Climatology, 17-22 January 1993, Anaheim, Californiaâ†©ï¸Ž",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>12</span>Â  <span class='chapter-title'>Evaluating the Reliability of Remotely Sensed Droughts</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "",
    "text": "13.1 Overview\nMeteorological, Agricultural, and Hydrological Droughts\nIn this notebook we will examine the propagation of precipitation deficits, soil water deficits, and finally their lagged effect on plants. This cascading effect of drought development, or so-called convergence of evidence, is important to study in areas where rain-fed agricultural practices are of importance, such as Mozambique.\nClassically drought have been categorized in four classes:\nThe first three phenomena often follow in a cascading sequence, whereas all of them can have a direct impact on society.\nimport hvplot.pandas  # noqa\nimport pandas as pd\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.stattools as smt\nfrom envrs.corr_plots import plot_step_corr, plot_predicted_values\nfrom envrs.download_path import make_url\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nResolve path ffmpeg: /home/runner/work/eo-datascience/eo-datascience/.conda_envs/environmental-remote-sensing/bin/ffmpeg",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#overview",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#overview",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "",
    "text": "Meteorological drought is described as the lack of precipitation and/or increased atmospheric demand (evapotranspiration)\nAgricultural drought is also a physical phenomenon where soils become replete of moisture\nHydrological drought follows when ongoing drought can then cause deficits in ground and surface reservoirs\nSocioeconomic drought impacts society through crop loss, food insecurity, shortages of fresh-water resources",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#monitoring-drought-dynamics",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#monitoring-drought-dynamics",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "13.2 Monitoring Drought Dynamics",
    "text": "13.2 Monitoring Drought Dynamics\nTo track drought development in this exercise we will work with precipitation, soil moisture and vegetation data. The following dataset combines the HSAF ASCAT 6.25 surface soil moisture with data for precipitation from CHIRPS, and data for vegetation, the NDVI (see table).\n\n\n\n\n\n\n\n\nFeature\nNDVI (Normalized Difference Vegetation Index)\nCHIRPS (Climate Hazards Group InfraRed Precipitation with Station data)\n\n\n\n\nDescription\nA widely used index to measure the health and vigor of vegetation (â€œgreennessâ€ of the biomes).\nA high-resolution precipitation dataset that combines satellite and station data.\n\n\nData Source\nRemote sensing, typically from satellite imagery.\nSatellite infrared data combined with rain gauge station data.\n\n\nCalculation\n(NIR - RED) / (NIR + RED), where NIR is Near-Infrared and RED is Red light reflectance.\nCombines data from multiple sources to provide daily precipitation estimates.\n\n\nApplications\n- Agriculture: Monitoring crop health and growth.- Ecology: Assessing vegetation cover and changes.- Climate: Studying vegetation response to climate change.\n- Drought monitoring and early warning.- Hydrological modeling.- Agricultural planning and risk management.\n\n\nAdvantages\n- Simple and quick to calculate.- Provides a standardized measure of vegetation health.- Useful for temporal and spatial comparisons.\n- High spatial and temporal resolution.- Integrates multiple data sources for better accuracy.- Useful for regions with sparse rain gauge networks.\n\n\nLimitations\n- Sensitive to atmospheric conditions and soil background.- May require calibration for different vegetation types.- Does not distinguish between different types of vegetation.\n- Dependent on the quality and availability of input data.- May have errors in areas with complex terrain or dense vegetation.- Requires validation with ground truth data.\n\n\nUse Cases\n- Detecting areas of stressed or unhealthy vegetation.- Monitoring deforestation and land use changes.- Assessing the impact of droughts and floods on vegetation.\n- Providing real-time precipitation data for disaster response.- Supporting water resource management and irrigation planning.- Enhancing climate models and weather forecasting.\n\n\n\nIn summary, NDVI indicates plant health based on the assumption that plants lose their greenness when they wilt due to water deprivation. However, this signal is highly dependent on vegetation types, soil background, and atmospheric conditions. CHIRPS measures precipitation and is affected by the quality of the input data, which can be problematic if there is a scarcity or poor quality of meteorological stations in a region.\nLetâ€™s load the data as prepared for the notebook.\n\nurl = make_url(\"drought_indices-6_25_dekadal.csv\")\ndf_dekadel = (\n    pd.read_csv(\n        url,\n        index_col=\"time\",\n        parse_dates=True,\n    )\n    .dropna()\n    .sort_index()\n)\n\ndf_dekadel.head()\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/drought_indices-6_25_dekadal.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nsurface_soil_moisture\nndvi\nprecip\nname\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n2012-01-01\n34.770840\n-18.889309\n0.30570\n0.564\n0.046854\nMuanza\n\n\n2012-01-01\n32.540100\n-23.426407\n0.29010\n0.432\n0.002876\nMabalane\n\n\n2012-01-01\n34.113262\n-22.077436\n0.31970\n0.576\n0.020926\nMabote\n\n\n2012-01-01\n34.119698\n-19.975350\n0.31385\n0.576\n0.024297\nBuzi\n\n\n2012-01-01\n33.030777\n-24.612324\n0.19315\n0.320\n0.000000\nChokwÃ©\n\n\n\n\n\n\n\nWe have five time series datasets spanning from 2011 to 2020 for the selected locations in the DrySat project, available for in-depth analysis (refer to notebooks 1 and 2). The NDVI data is sourced from the Copernicus Land Monitoring Service, and the CHIRPS data is obtained from ClimateSERV. NDVI values range from 0 to 1 and are often classified as follows:\n\n0 to 0.1: Bare soil, rock, or sand.\n0.1 to 0.2: Low vegetation or senescent (dying) vegetation.\n0.2 to 0.5: Sparse vegetation, such as shrubs and grasslands.\n0.5 to 0.7: Moderate to high vegetation, such as crops and forests.\n0.7 to 1: High density of green leaves, indicative of very healthy vegetation.\n\nFor this analysis, the ASCAT H SAF surface soil moisture (SSM) data, originally at a 6.25 km resolution and expressed as a percentage of saturation, is converted to a unit scale ranging from 0 to 1. Additionally, the CHIRPS precipitation data, measured in millimeters, is min-max scaled for each locationâ€™s time series individually to also range between 0 and 1.\nBoth NDVI and CHIRPS datasets are natively 10-daily products (or â€˜dekadalâ€™), while the SSM data is resampled to match this dekadal frequency.\nLetâ€™s have a look at the data for each site individually with hvplot use the dropdown menu â€œnameâ€ to select the preferred site.\n\ndf_dekadel.hvplot.line(\n    x=\"time\",\n    y=[\"precip\", \"surface_soil_moisture\", \"ndvi\"],\n    subcoordinate_y=True,\n    groupby=[\"name\"],\n    frame_width=800,\n)\n\n\n\n\n\n  \n\n\n\n\nBy examining the three variablesâ€”CHIRPS precipitation (precip), H SAF surface soil moisture (surface_soil_moisture), and NDVI (ndvi)â€”we observe a strong temporal correlation among them. This correlation is logical, as we expect rain to wet the soil, which in turn nourishes plant life, and vice versa. The most significant changes in these variables appear to be linked to transitions between dry and wet seasons.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#exploration-with-linear-regression",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#exploration-with-linear-regression",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "13.3 Exploration with Linear Regression",
    "text": "13.3 Exploration with Linear Regression\nLetâ€™s delve deeper into the relationships among these three variables. Linear regression, specifically Ordinary Least Squares (OLS) regression, is a powerful tool for explanatory data analysis. OLS is a good starting point for your analysis as it is easy to interpret; the coefficients directly relate changes in the response variable to one-unit changes in the predictor variables, with the sign and magnitude reflecting the modelâ€™s effects. In an OLS regression, these effects refer to the impact of the independent variables on the dependent variable.\nAlthough the assumptions underlying OLS regression (such as linearity, independence of observations, and normality of residuals) are likely to be violated, especially in time series analysis where observations closely spaced in time are likely to be dependent on each other (autocorrelation), we can still use OLS for an ad hoc analysis of the previously observed physical relationships. Specifically, we aim to test the following relationships:\n\nMore rain leads to healthier vegetation.\nWetter soils lead to healthier vegetation.\n\nThese relationships are intuitively important causal factors. To determine which best explains the dependent variable (NDVI), we will perform OLS regression using the statsmodels package. Note that other Python packages, like scipy.stats, are also available.\nWeâ€™ll utilize statsmodelsâ€™ formula interface, which allows specifying models with formula strings and directly using pandas.DataFrames. This interface employs a tilde (~) to separate the dependent variable from the independent variables. Interactions between variables can be specified using the * or : operators, enabling easy expansion to multiple regression. It also simplifies variable transformations and polynomial terms.\nTo translate the equation:\n\\[\\text{NDVI} = \\alpha + \\beta \\text{CHIRPS} + \\epsilon \\]\ninto an statsmodels formula, you use:\n\ndf_buzi = df_dekadel[df_dekadel.name == \"Buzi\"]\nmod_precip = smf.ols(formula=\"ndvi ~ precip\", data=df_buzi)\n\nIn this context, ndvi is the dependent variable, precip is the independent variable, and df_buzi is the data frame containing your data. We will focus on the Buzi region for the OLS regression and subsequent analysis.\nTo fit the model, simply call the fit method on the generated object. We will then print the parameters and their estimated coefficients as well as the variation in NDVI explained by the \\(R^2\\) value.\n\nres_precip = mod_precip.fit()\n\nprint(\"Parameters: \\n\", res_precip.params, sep=\"\")\nprint(\"R2: \", res_precip.rsquared)\n\nParameters: \nIntercept    0.531179\nprecip       0.249106\ndtype: float64\nR2:  0.08314849453004114\n\n\nWe can see that the model fit with CHIRPS precipitation as independent variable is limited. Now letâ€™s do the same for the second predefined relationship, where we translate (\\(\\text{NDVI} = \\alpha + \\beta \\text{SSM} + \\epsilon\\)) into an statsmodels formula and asses itâ€™s fit, like so:\n\nmod_ssm = smf.ols(formula=\"ndvi ~ surface_soil_moisture\", data=df_buzi)\nres_ssm = mod_ssm.fit()\n\nprint(\"Parameters: \\n\", res_ssm.params, sep=\"\")\nprint(\"R2: \", res_ssm.rsquared)\n\nParameters: \nIntercept                0.346452\nsurface_soil_moisture    0.740606\ndtype: float64\nR2:  0.5374351087887564\n\n\nThis approach provides better results, explaining nearly 50% of the variance in NDVI with H SAF ASCAT SSM. Additionally, we can visualize these results using an \\(R^2\\) plot to perform a more detailed diagnostic analysis of the modelâ€™s performance. We have predefined and loaded this function at the top of the notebook for clarity.\n\nresults = {\"precip\": res_precip, \"surface_soil_moisture\": res_ssm}\nplot_predicted_values(\n    df_buzi,\n    results,\n    figsize=(10, 5),\n)",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#leads-and-lags-of-water-availability-and-vegetation",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#leads-and-lags-of-water-availability-and-vegetation",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "13.4 Leads and Lags of Water Availability and Vegetation",
    "text": "13.4 Leads and Lags of Water Availability and Vegetation\nAt the beginning of the notebook, we highlighted that droughts are cascading events where a lack of rain leads to reduced soil moisture, which in turn affects plant health. To study the dynamics of these cascading droughts, we should first examine the effects of precipitation and soil moisture on vegetation under normal conditions. We need to consider both the lead and lag of the respective causes and effects in this system. Precipitation leads, soil moisture replenishment lags, and vegetation responds with a delay to rainfall events.\nThough the cyclical nature of NDVI, H SAF ASCAT SSM, and CHIRPS precipitation is evident, these cycles correspond to the dry and wet seasons experienced in Mozambique. To quantify the actual periodicity of these seasons, autocorrelation is a useful tool. Autocorrelation in time series refers to the correlation of a time series with a delayed copy of itself, measuring the extent to which a time series value is linearly related to its past and future values. The following animation visually demonstrates how a copy of the time series is shifted alongside itself, illustrating the corresponding correlation, known as autocorrelation. This can be expressed as:\n\\[r_k = \\frac{\\sum_{t=1}^{N-k}{(x_t-\\bar{x} )(x_{t+k} -\\bar{x})}}{\\sum_{t=1}^N{(x_t-\\bar{x}})}\\]\n\nplot_step_corr(df_buzi, \"ndvi\", length=72)\n\n\n  \n  Your browser does not support the video tag.\n\n\n\nAs expected, it takes 18 lags (or 18 dekads, equivalent to approximately half a year) for the signal to become almost entirely anti-correlated. It then takes 36 lags (or 36 dekads, equivalent to approximately 1 year) for the cycle to complete and the signal to become almost perfectly correlated again. You can perform you own autocorrelation test with statsmodels, like so:\n\nsmt.acf(df_buzi.ndvi, nlags=4)\n\narray([1.        , 0.94896775, 0.88434477, 0.79925742, 0.69430392])\n\n\nSimilarly, we can compare the lagged time series of CHIRPS precipitation with NDVI and the lagged time series of H SAF ASCAT SSM with NDVI. This type of analysis is known as lagged cross-correlation analysis. The following two animations illustrate the cross-correlations of H SAF ASCAT SSM with NDVI and CHIRPS precipitation with NDVI respectively.\n\nplot_step_corr(df_buzi, \"ndvi\", \"precip\", length=72)\n\n\n  \n  Your browser does not support the video tag.\n\n\n\n\nplot_step_corr(df_buzi, \"ndvi\", \"surface_soil_moisture\", length=72)\n\n\n  \n  Your browser does not support the video tag.\n\n\n\nWe observe that these wet-dry cycles do not perfectly align among the two variables in our analysis. In both cases, the correlation initially increases with 3 to 6 lags in the time series for CHIRPS precipitation and H SAF SSM, respectively.\n\nNDVI lags CHIRPS precipitation by 6 dekads (or approximately 2 months).\nNDVI lags H SAF SSM by 3 dekads (or approximately 1 month).\n\nYou can again perform you own lagged cross-correlation test with statsmodels, like so:\n\nsmt.ccf(df_buzi.ndvi, df_buzi.surface_soil_moisture, nlags=4)  # for example\n\narray([0.73309966, 0.82333965, 0.86011595, 0.87138539])",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#lagged-variable-regression",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#lagged-variable-regression",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "13.5 Lagged Variable Regression",
    "text": "13.5 Lagged Variable Regression\nNow that weâ€™ve determined the appropriate lag, we can revisit the OLS regression. By using pandasâ€™ shift function, we adjust precip and surface_soil_moisture accordingly and then apply the statsmodels OLS regression to the lagged dataset.\n\ndf_buzi_shift = df_buzi.assign(\n    surface_soil_moisture=df_buzi.loc[:, \"surface_soil_moisture\"].shift(3),\n    precip=df_buzi.loc[:, \"precip\"].shift(6),\n).dropna()\n\ndf_buzi_shift\n\n\n\n\n\n\n\n\nlongitude\nlatitude\nsurface_soil_moisture\nndvi\nprecip\nname\n\n\ntime\n\n\n\n\n\n\n\n\n\n\n2012-03-01\n34.119698\n-19.97535\n0.26675\n0.608\n0.024297\nBuzi\n\n\n2012-03-11\n34.119698\n-19.97535\n0.27485\n0.636\n0.375177\nBuzi\n\n\n2012-03-21\n34.119698\n-19.97535\n0.13000\n0.580\n0.154025\nBuzi\n\n\n2012-04-01\n34.119698\n-19.97535\n0.36055\n0.688\n0.053977\nBuzi\n\n\n2012-04-11\n34.119698\n-19.97535\n0.29830\n0.676\n0.244914\nBuzi\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2019-11-11\n34.119698\n-19.97535\n0.13205\n0.336\n0.022271\nBuzi\n\n\n2019-11-21\n34.119698\n-19.97535\n0.15360\n0.528\n0.020403\nBuzi\n\n\n2019-12-01\n34.119698\n-19.97535\n0.17110\n0.544\n0.074502\nBuzi\n\n\n2019-12-11\n34.119698\n-19.97535\n0.20390\n0.600\n0.009415\nBuzi\n\n\n2019-12-21\n34.119698\n-19.97535\n0.30400\n0.632\n0.035159\nBuzi\n\n\n\n\n282 rows Ã— 6 columns\n\n\n\nThee lagged values of precipitation to account for the delayed impact of rainfall on vegetation health would look something like this:\n\\[ \\text{NDVI}_t = \\alpha + \\beta \\text{CHIRPS}_{t-6} + \\epsilon_t \\]\nIn this equation, \\(\\text{NDVI}_t\\)â€‹ is the dependent variable at time \\(t\\) and \\(\\text{CHIRPS}_{t-6}\\) is the 6 dekadal lagged independent variables with \\(\\beta\\) as the coefficient. This approach can provide insights into how past events influence current outcomes, making it a valuable tool for time series analysis. We implement this as follows:\n\nmod_precip_shift = smf.ols(formula=\"ndvi ~ precip\", data=df_buzi_shift)\nres_precip_shift = mod_precip_shift.fit()\n\nprint(\"Parameters: \\n\", res_precip_shift.params, sep=\"\")\nprint(\"R2: \", res_precip_shift.rsquared)\n\nParameters: \nIntercept    0.503815\nprecip       0.479969\ndtype: float64\nR2:  0.3076670920100214\n\n\nWe observe that including lagged rainfall data improves the model fits compared to a model without this information. Next, we will apply the same approach to H SAF SSM, now using a time lag of 3 dekads:\n\nmod_ssm_shift = smf.ols(formula=\"ndvi ~ surface_soil_moisture\", data=df_buzi_shift)\nres_ssm_shift = mod_ssm_shift.fit()\n\nprint(\"Parameters: \\n\", res_ssm_shift.params, sep=\"\")\nprint(\"R2: \", res_ssm_shift.rsquared)\n\nParameters: \nIntercept                0.307934\nsurface_soil_moisture    0.874578\ndtype: float64\nR2:  0.74824179183522\n\n\nHere again the model fit improves over the model without lagged variables. We can perform a sanity check by plotting again the \\(R^2\\) plots.\n\nresults_shift = {\"precip\": res_precip_shift, \"surface_soil_moisture\": res_ssm_shift}\nplot_predicted_values(\n    df_buzi_shift,\n    results_shift,\n    figsize=(10, 5),\n    suffix=[\"(shifted 2 months)\", \"(shifted 1 month)\"],\n)\n\n\n\n\n\n\n\n\nThese \\(R^2\\) plots indicate that the relationships are better captured with lagged variables compared to unlagged ones. However, the precipitation data does not fully conform to the underlying principles of linear regression with OLS. It is quite obvious from this plot that rainfall data contains a lot of zeros. This should be addressed before one can make inferences from the model.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#enhancing-the-robustness-of-lagged-variable-ols-analysis",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#enhancing-the-robustness-of-lagged-variable-ols-analysis",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "13.6 Enhancing the Robustness of Lagged Variable OLS Analysis",
    "text": "13.6 Enhancing the Robustness of Lagged Variable OLS Analysis\nTo advance the lagged variable analysis with Ordinary Least Squares (OLS), we need to consider several methodological enhancements. Here are strategies to take this forward:\n\nBLUE Estimators: Ensure your models conform to the properties of BLUE estimators (Bias, Linearity, Uncorrelated errors, and Efficiency). This will provide the most reliable and unbiased estimates for your regression coefficients.\nAutocorrelation: Autocorrelation can significantly affect the reliability of your model. Weâ€™ve already identified strong autocorrelation in the temporal domain using autocorrelation tests. Consider looking into Generalized Least Squares models, which can account for dependency structures in their residuals.\nMultiple Independent Variables: Incorporate multiple independent variables, including both lagged and unlagged versions. For example, include precipitation, soil moisture, and other relevant factors with appropriate lag structures to capture their delayed effects.\nNon-normal Residuals: If your residuals are not normally distributed, it can impact the validity of your hypothesis tests. Techniques such as transforming the dependent variable (e.g., using log or Box-Cox transformations), or using robust regression methods can help address this.\nNon-linear Behavior: If you detect non-linear relationships, consider using polynomial regression or non-linear regression models. Interaction terms between your independent variables can also capture non-linear effects within an OLS framework.\nModel Diagnostics: Regularly perform diagnostic checks on your models. Examine plots of residuals versus fitted values, histograms of residuals, and autocorrelation plots to ensure model assumptions are met and identify areas for improvement.\n\nBy adopting these strategies, you will significantly enhance the robustness of your lagged variable OLS analysis, ensuring it is both methodologically sound and practically useful for understanding and predicting complex dynamic systems. Ultimately, this will help us better comprehend the normal wet/dry dynamics of the system, allowing us to predict the effects of current drought conditions on crops and subsequently help forecast yield.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#footnotes",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/04_handout_drought.html#footnotes",
    "title": "13Â  Leads and lags in Drought Dynamics",
    "section": "",
    "text": "L. Crocetti et al., Earth Observation for agricultural drought monitoring in the Pannonian Basin (southeastern Europe): current state and future directions, Reg Environ Change, vol.Â 20, no. 4, p.Â 123, Dec.Â 2020, doi: 10.1007/s10113-020-01710-w.â†©ï¸Ž",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>13</span>Â  <span class='chapter-title'>Leads and lags in Drought Dynamics</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "",
    "text": "14.1 Overview\nDownloading, Reading and Working with H SAF Surface Soil Moisture 6.25 km\nThis notebook demonstrates how to access the H SAF soil moisture products in near real-time, as utilized in previous notebooks.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#imports",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#imports",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.2 Imports",
    "text": "14.2 Imports\n\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\n\nimport cartopy.crs as ccrs\nimport hvplot.pandas  # noqa\nfrom ascat.download.interface import hsaf_download\nfrom ascat.swath import SwathGridFiles\nfrom dotenv import dotenv_values\n\nfrom envrs.ssm_cmap import SSM_CMAP\n\nERROR 1: PROJ: proj_create_from_database: Open of /home/runner/work/eo-datascience/eo-datascience/.conda_envs/environmental-remote-sensing/share/proj failed",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#h-saf",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#h-saf",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.3 H SAF",
    "text": "14.3 H SAF\nH SAF, the Satellite Application Facility on Support to Operational Hydrology and Water Management, is part of EUMETSAT, the â€˜European Organisation for the Exploitation of Meteorological Satellitesâ€™ headquartered in Darmstadt, Germany. EUMETSAT consists of 30 European Member states and operates both geostationary satellites (Meteosat) and polar-orbiting satellites (Metop), the latter of which carry the ASCAT sensors used for soil moisture retrieval. These missions are crucial for weather forecasting and significantly contribute to environmental and climate change monitoring. H SAF aims to disseminate satellite-derived products useful for operational hydrology, including precipitation, snow cover, and soil moisture. They ensure that these products are accurate through rigorous validation and are delivered to users in a timely manner. All these products are freely available.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#registration",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#registration",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.4 Registration",
    "text": "14.4 Registration\nH SAF has an FTP server for users to download near real time data products. Before you can start downloading data products, one need to register to become an H SAF user. This is relatively easy when following these steps:\n\nGo to H SAF homepage.\n\n\n\n\n\nClick on the lock icon at the top right of the screen and select â€œRegisterâ€.\n\n\n\n\n\nAfter completing the registration you can login on the webpage.\n\n\n\n\n\nNow you browse the data products; for example, ASCAT SSM NRT 6.25 km (H122)\n\n\n\n\n\nYou can then click on â€œDownloadâ€. This will provide you with the URL of the FTP server for downloading.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#downloading",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#downloading",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.5 Downloading",
    "text": "14.5 Downloading\nNow that we have the address for finding the soil moisture data products in the form of an URL, we need to think about a method to download the data. In other words we need a client, which requests the resources from the H SAF FTP servers. One way to download the data would be to use a client with a graphical user interface, like FileZilla.\nOf course, we will look into a â€œPythonicâ€ way to download the data. For this we use the ascat package developed by the TU Wien. You can pip install this package from the Python Package Index (PyPi), like so:\npip install ascat\nThe ascat package has a download interface hsaf_download. The interface needs the following information; a local path for saving the downloaded data, a remote path to locate the H SAF data products on the FTP server, and a start and end datetime for the query. Here we show how to download the H SAF SSM 6.25 km product for the last 30 days from the time of running this notebook.\n\nlocal_path = \"h130\"\nremote_path = \"h130/h130_cur_mon_data\"\nstart_date = datetime.now() - timedelta(days=30)  # noqa: DTZ005\nend_date = datetime.now()  # noqa: DTZ005\n\nYou also need to provide your credentials to authenticate with the FTP server, which you obtained when registering as an user (see above). It is always a good practice to â€œnotâ€ store your credentials, tokens, and other secrets in scripts or notebooks. Hence, we will use a dotenv (.env). Dotenv is a tool that helps load environment variables from an .env-file into your applicationâ€™s environment, allowing you to manage configuration settings separately from your code.\nBefore you can use dotenv, you will have to create the .env-file manually or with the command line, like so\ntouch .env\nOpen the file and write your email at the location indicated with &lt;your_email_here&gt; and your password here: &lt;your_password_here&gt;.\nUSER_HSAF=&lt;your_email_here&gt;\nPASS_HSAF=&lt;your_password_here&gt;\nNow we can load the credentials from the dotenv and pass this information to the H SAF FTP server with hsaf_download.\n\ncredentials = {\n    \"user\": dotenv_values(\".env\")[\"USER_HSAF\"],\n    \"password\": dotenv_values(\".env\")[\"PASS_HSAF\"],\n}\n\nIn the following code cell, we create the location to store the downloaded data and start the download.\n\n%%time\n\nif not Path(local_path).is_dir():\n    Path(local_path).mkdir()\n\nhsaf_download(credentials, remote_path, local_path, start_date, end_date, limit=5)\n\n2025-10-05 15:31:57,644 INFO: FTP connection successfully established\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2025-10-05 15:32:40,671 INFO: FTP disconnected\n\n\nCPU times: user 354 ms, sys: 185 ms, total: 539 ms\nWall time: 44.2 s",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#swath-vs.-cell-format-soil-moisture-data",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#swath-vs.-cell-format-soil-moisture-data",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.6 Swath vs.Â Cell Format Soil Moisture Data",
    "text": "14.6 Swath vs.Â Cell Format Soil Moisture Data\nThe data provided by the near real time service is provided in â€œswathâ€ format as opposed to the â€œcellâ€ format with which we worked before. A swath is the area on the Earthâ€™s surface that is observed or imaged by a satellite or an airborne sensor during a single pass. This is often visualized as a strip or a corridor of data collected as the satellite or aircraft moves along its path (see figure below).\n\n\n\nDistinctive double strips when ASCAT scans the Earthâ€™s surface (Source: ESA)\n\n\nEach format has its unique characteristics and implications for Earth observation research:\n\n\n\n\n\n\n\n\nAspect\nSwath Format\nCell Format\n\n\n\n\nDefinition\nData collected in continuous strips\nData collected and presented in gridded format\n\n\nCoverage\nBroad spatial coverage in a single pass\nLocalized and detailed view\n\n\nTemporal Resolution\nHigh, frequent updates over large areas\nLower, depends on satellite revisit time\n\n\nData Processing\nComplex, handles continuous data\nStraightforward, each cell is independent\n\n\nApplications\nLarge-scale hydrological studies, weather forecasting, climate monitoring\nPrecision agriculture, local hydrological studies, detailed environmental monitoring\n\n\n\nIn summary, the choice between swath and cell formats depends on the specific requirements of the Earth observation research. Swath data is advantageous for broad, frequent coverage, while cell data offers detailed, localized information.\nLetâ€™s have a look at the downloaded swath data. For this we can use again the ascat package and the SwathGridFiles class where point to the downloaded data and provide the product id \"H130\". We can then read the data, which return the ASCAT 6.25 km data in swath format as a Pandas.DataFrame.\n\nh130_nrt = SwathGridFiles.from_product_id(local_path, product_id=\"H130\")\ndf_h130 = h130_nrt.read(date_range=(start_date, end_date)).to_dataframe()\ndf_h130.head()\n\nsh: 1: getfattr: not found\n\n\n\n\n\n\n\n\n\nlocation_id\nas_des_pass\nswath_indicator\nsurface_flag\nsurface_flag_source\nsurface_soil_moisture\nsurface_soil_moisture_noise\nbackscatter40\nslope40\ncurvature40\n...\nprocessing_flag\nsnow_cover_probability\nfrozen_soil_probability\nwetland_fraction\ntopographic_complexity\nsubsurface_scattering_probability\nsat_id\nlatitude\nlongitude\ntime\n\n\nobs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n6032472\n1.0\n0.0\n0.0\n9.0\nNaN\nNaN\nNaN\n-0.169247\n-0.000711\n...\n2.0\n41.0\n2.0\n0.0\n2.0\n0.0\n5\n66.207786\n-96.414459\n2025-09-05 19:00:00.556999936\n\n\n1\n6035056\n1.0\n0.0\n0.0\n9.0\nNaN\nNaN\n-11.103960\n-0.169160\n-0.000686\n...\n2.0\n41.0\n2.0\n11.0\n2.0\n0.0\n5\n66.262886\n-96.476768\n2025-09-05 19:00:00.556999936\n\n\n2\n6037640\n1.0\n0.0\n0.0\n9.0\nNaN\nNaN\n-11.354557\n-0.176604\n-0.000189\n...\n2.0\n41.0\n2.0\n3.0\n2.0\n0.0\n5\n66.318115\n-96.539070\n2025-09-05 19:00:00.556999936\n\n\n3\n6038627\n1.0\n0.0\n0.0\n9.0\nNaN\nNaN\n-11.778568\n-0.185619\n0.000419\n...\n2.0\n39.0\n2.0\n44.0\n1.0\n0.0\n5\n66.339241\n-96.702186\n2025-09-05 19:00:00.556999936\n\n\n4\n6041211\n1.0\n0.0\n0.0\n9.0\nNaN\nNaN\n-12.553858\n-0.190845\n0.000924\n...\n2.0\n36.0\n2.0\n11.0\n1.0\n0.0\n5\n66.394630\n-96.764495\n2025-09-05 19:00:00.556999936\n\n\n\n\n5 rows Ã— 23 columns",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#data-quality-flags",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#data-quality-flags",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.7 Data Quality Flags",
    "text": "14.7 Data Quality Flags\nThe DataFrame now includes additional columns when compared with earlier notebooks. These columns indicate that the data is accompanied by quality flags to ensure the reliability and accuracy of soil moisture estimates for specific studies and areas of interest. Users have to use these flags to filter out unreliable data to maintain an accurate overview of the conditions.\nFor the data used in these notebooks, specific flags and threshold values were applied: â€œtopographic_complexityâ€ and â€œwetland_fractionâ€ were set below 20%. This is because the backscattering of microwaves from topographically varied terrain, such as hills, valleys, and slopes, creates surface roughness that can scatter the microwave signal in multiple directions. This scattering leads to a more complex and less predictable backscatter signal. Additionally, wetland backscattering signals can be dominated by water, resulting in biased soil moisture retrievals. This bias can be further compounded by microwaves bouncing off water surfaces into reed belts and other vegetation along the shores of water bodies. To ensure sufficient variation in the backscatter signal, the sensitivity flag is set to more than 1 dB (decibel), allowing the retrieval algorithms to separate soil moisture contributions from noise. It is expected that in Mozambique, vegetation attenuation of microwaves can create unfavorable conditions for soil moisture retrievals due to this mechanism.\nThere are many more processing and quality flags. Check the ASCAT Soil Moisture User Manual for the other flags and determine if they are important for your requirements.\nBy applying these quality flags and understanding their implications, users can better interpret the soil moisture data and ensure that their analyses are based on reliable and accurate information. This approach helps mitigate the potential biases introduced by topographic complexity and wetland influences, ultimately leading to more robust and informative soil moisture retrievals.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#selecting-a-region-of-interest",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/05_supplement_drought.html#selecting-a-region-of-interest",
    "title": "14Â  Access to Near Real Time Soil Moisture Data",
    "section": "14.8 Selecting a Region of Interest",
    "text": "14.8 Selecting a Region of Interest\nWe will plot the obtained soil moisture data without applying any filters. We use hvplot, as we typically do. It is evident that the â€œswathâ€ format data provides global coverage. However, this format makes it more challenging to directly download data specific to your area of interest, such as Mozambique. To target a specific region before downloading the data, one needs to understand the intersection of the swath geometry with the area of interest at any given time. This is beyond the scope of this course. At present you can download the whole swaths and then extract the region of interest.\nNote, that one can stack swath format data to obtain cell format data. This functionality is available in the ascat package, but this is beyond the scope of this notebook.\n\ndf_h130.hvplot.points(\n    x=\"longitude\",\n    y=\"latitude\",\n    c=\"surface_soil_moisture\",\n    x_sampling=0.16,\n    y_sampling=0.16,\n    rasterize=True,\n    crs=ccrs.PlateCarree(),\n    tiles=True,\n    cmap=SSM_CMAP,\n    clim=(0, 100),\n    frame_width=500,\n    clabel=\"Surface soil moisture (%)\",\n)",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>14</span>Â  <span class='chapter-title'>Access to Near Real Time Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "",
    "text": "15.1 Overview\nDownloading, Reading, and Working with Copernicus WEkEO Soil Water Index 12.5 km\nIn this notebook we will examine how one can obtain historic soil moisture data. We will do this by looking into the Copernicus WEkEO portal.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#imports",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#imports",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "15.2 Imports",
    "text": "15.2 Imports\n\nfrom pathlib import Path\n\nimport cartopy.crs as ccrs\nimport hvplot.pandas  # noqa\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nfrom dotenv import dotenv_values\nfrom hda import Client, Configuration\nfrom numpy.lib.recfunctions import unstructured_to_structured\nfrom pyswi.swi_ts import calc_swi_ts\n\nfrom envrs.download_path import make_url\nfrom envrs.ssm_cmap import SSM_CMAP\n\nERROR 1: PROJ: proj_create_from_database: Open of /home/runner/work/eo-datascience/eo-datascience/.conda_envs/environmental-remote-sensing/share/proj failed",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#copernicus-wekeo",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#copernicus-wekeo",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "15.3 Copernicus WEkEO",
    "text": "15.3 Copernicus WEkEO\nThe name WEkEO (pronounced [wikio]) refer to the four key organisations â€“ EUMETSAT, ECMWF, Copernicus Programme, and Mercator Ocean International, which link to the broader user community (â€œWEâ€), with the purpose of knowledge advancement and sharing (â€œkâ€), focussing Earth and Environmental Observation (â€œEOâ€).\nThe platform is a web-based service that helps people easily access and use Earth observation data. Its main goal is to make it simple for researchers, companies, and decision-makers to get the data they need and analyze it without needing advanced tools or a lot of technical knowledge.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#registration",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#registration",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "15.4 Registration",
    "text": "15.4 Registration\nSimilarly to H SAF FTP server, we need to register as an user to make full use of WEkEO, although some features are available without an account. We can follow these steps:\n\nGo to the homepage of WEkEO.\n\n\n\n\n\nClick on top right â€œLoginâ€ button, whereafter we select â€œCreate an accountâ€ and fill out the form.\n\n\n\n\n\nNow we can login and, for example, look at the available data by clicking on â€œGoâ€ in the â€œData Catalogueâ€ field in the middle of the screen.\n\n\n\n\n\nThis shows us a data viewer where we can select from many different data products.\n\n\n\n\nWe will use the latter step to find the datasets we need and create query strings that we will use in a Python environment.",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#harmonized-data-access",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#harmonized-data-access",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "15.5 Harmonized Data Access",
    "text": "15.5 Harmonized Data Access\nThe Copernicus WEkEO platform offers a straightforward way to access data through its Application Programming Interface (API). APIs enable different programming languages to communicate and exchange information, effectively serving as a bridge for programs to utilize and extend each otherâ€™s functionalities. In the case of WEkEO, the API is called the Harmonized Data Access (HDA) API, which provides uniform access to the entire WEkEO catalogue, including subsetting and downloading capabilities. We will use the Python HDA client to interact with this API.\nInstall with either pip:\npip install hda\nor conda:\nconda install -c conda-forge hda\nNow, we need to authenticate using the Configuration object and provide your accountâ€™s username and password. As in the previous notebook, we will use a dotenv environment for this purpose. To utilize dotenv, you need to add your username to the USER_WEKEO variable and your password to the PASS_WEKEO variable in the .env file.\n\nconf = Configuration(\n    user=dotenv_values(\".env\")[\"USER_WEKEO\"],\n    password=dotenv_values(\".env\")[\"PASS_WEKEO\"],\n)\nhda_client = Client(config=conf)",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#finding-soil-moisture-data",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#finding-soil-moisture-data",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "15.6 Finding Soil Moisture Data",
    "text": "15.6 Finding Soil Moisture Data\nTo find the SWI 12.5 km dataset in time series format, we have to return to the data viewer in the browser. Click in the â€œLayersâ€ field on the + sign, and search for â€œSoil Water Indexâ€ in the â€œFree Text Searchâ€.\n\n\n\nThen select the fourth dataset from the top; â€œSoil Water Index Time Series 2007-present (discrete global grid), global, daily - version 3â€. Click on the download button in the layers field, which unfolds a form which allows subsetting of the data. We can enter here a bounding box (bbox) for Mozambique. Scroll further down and click on â€œShow API request(s)â€.\n\n\n\nWe will copy this query to our Python environment and use the hda_client to search for the files.\n\nquery = {\n    \"dataset_id\": \"EO:CLMS:DAT:CLMS_GLOBAL_SWI_12.5KM_V3_TIME-SERIES_NETCDF\",\n    \"bbox\": [\n        30.315,\n        -27.49,\n        41.07,\n        -10.20,\n    ],\n    \"itemsPerPage\": 200,\n    \"startIndex\": 0,\n}\n\nmatches = hda_client.search(query)\n\nprint(matches)\n\nSearchResults[items=3,volume=312MB]\n\n\nIf you are content with the results then you can start the downloading process. Here we again create a directory to contain the downloaded files. The downloaded file with be in NetCDF format. NetCDF is a data formats that is tailored to multi-dimensional array-oriented scientific data with many options to label the data.\n\n%%capture\n\nlocal_path = \"cgls_swi_12_5\"\n\nif not Path(local_path).is_dir():\n    Path(local_path).mkdir()\n\nmatches.download(download_dir=local_path)\n\nThe downloaded data is projected on the same Fibonacci grid as the H SAF ASCAT 6.25 km surface soil moisture (see notebook 1). But the NetCDF data format requires another solution to read the data. Hence we will use another package to read the data. We use xarray, which is optimised to work with multi-dimensional arrays. We will introduce this package into more detail later on. We will call the method to_dataframe() to turn the xarray.Dataset into a pandas.DataFrame.\n\ndef _preprocess(ds: xr.Dataset) -&gt; xr.DataArray:\n    \"\"\"Preprocess Dataset.\n\n    Parameters\n    ----------\n    ds: Xarray.Dataset\n        Individually loaded NetCDF\n\n    Returns\n    -------\n    Xarray.DataArray: _Data array containing only SWI from depth 10 cm\n\n    \"\"\"\n    return ds.SWI_010\n\n\ndf_wekeo = xr.open_mfdataset(\n    \"cgls_swi_12_5/*.nc\",\n    engine=\"h5netcdf\",\n    combine=\"nested\",\n    parallel=True,\n    chunks=-1,\n    preprocess=_preprocess,\n    join=\"outer\",\n    compat=\"no_conflicts\",\n).to_dataframe()\n\ndf_wekeo.head()\n\n\n\n\n\n\n\n\n\nlon\nlat\nSWI_010\n\n\nlocations\ntime\n\n\n\n\n\n\n\n565647\n2007-01-01 12:00:00\n30.104193\n-10.060086\nNaN\n\n\n2007-01-02 12:00:00\n30.104193\n-10.060086\n80.5\n\n\n2007-01-03 12:00:00\n30.104193\n-10.060086\n80.5\n\n\n2007-01-04 12:00:00\n30.104193\n-10.060086\n80.5\n\n\n2007-01-05 12:00:00\n30.104193\n-10.060086\n79.0\n\n\n\n\n\n\n\nWe use again hvplot to validate our search results.\n\ndf_wekeo.hvplot.points(\n    x=\"lon\",\n    y=\"lat\",\n    c=\"SWI_010\",\n    groupby=\"time\",\n    x_sampling=0.16,\n    y_sampling=0.16,\n    rasterize=True,\n    crs=ccrs.PlateCarree(),\n    tiles=True,\n    cmap=SSM_CMAP,\n    clim=(0, 100),\n    frame_width=500,\n    clabel=\"Soil Water Index\",\n)",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#what-is-the-soil-water-index",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#what-is-the-soil-water-index",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "15.7 What is the Soil Water Index?",
    "text": "15.7 What is the Soil Water Index?\nWe have not yet talked about what the data exactly represents. The Soil Water Index is derived from surface soil moisture. The current dataset is derived from H SAF ASCAT 12.5 km and represents modelled approximation of soil water content at deeper layers of the soil. In the above plot we selected moisture content at a 10 cm depth interval. Remember that ASCAT can only probe the surface of soils.\nThe Soil Water Index provides a measure of how wet or dry the soil is over a specific area, ranging between 0 and 1. It is often derived using a combination of satellite data and modeling techniques. One commonly used approach to derive the SWI is through the TU Wien model1\nThe equation to derive the SWI typically involves a convolution of surface soil moisture observations with an exponential filter. This process helps in estimating the root-zone soil moisture, which is more relevant for agricultural and hydrological applications. The general form of the equation can be described as follows:\n\\[ \\text{SWI} = \\frac{\\sum_{i=0}^{n} w_i \\cdot SSM_i}{\\sum_{i=0}^{n} w_i} \\]\nWhere:\n\\[\n\\begin{aligned}\n\\text{SWI} &\\quad \\text{: Soil Water Index} \\\\\n\\text{SSM}_i &\\quad \\text{: surface soil moisture at time step} i \\\\\nw_i &\\quad \\text{: the weight assigned to the surface soil moisture at time step} i \\\\\nn &\\quad \\text{: number of time steps considered in the convolution}\n\\end{aligned}\n\\]\nThe weights \\(w_i\\) are often determined using an exponential decay function, which gives more importance to recent observations. The exponential decay function can be expressed as:\n\\[ w_i = e^{-\\frac{t_i}{T}} \\]\nWhere: \\[\n\\begin{aligned}\nt_i &\\quad \\text{: the time difference between the current time step and the time step} i \\\\\nT  &\\quad \\text{: a characteristic time scale that determines the rate of decay of the weights}\n\\end{aligned}\n\\]\nThis approach allows the SWI to reflect the cumulative effect of surface soil moisture over a period, providing a more stable and representative measure of the soil moisture conditions in the root zone.\nOne will observe that the SWI at depth is often less variable (more stable) than contemporaneous surface soil moisture with only delayed and dampened responses to external forcing (e.g.Â precipitation). We can visualize this by applying the SWI algorithm to one of the five timeseries introduced in notebook 1.\nLetâ€™s select only the year 2024 from the H SAF ASCAT 6.25 km surface soil moisture for Buzi:\n\nsm_ts = (\n    pd.read_csv(\n        make_url(\"ascat-6_25_ssm_timeseries.csv\"),\n        index_col=\"time\",\n        parse_dates=True,\n    )\n    .loc[\"2024\"]\n    .dropna()\n)\n\nsm_ts = sm_ts[sm_ts.name == \"Buzi\"].sort_index()\nsm_ts.head()\n\nhttps://git.geo.tuwien.ac.at/api/v4/projects/1266/repository/files/ascat-6_25_ssm_timeseries.csv/raw?ref=main&lfs=true\n\n\n\n\n\n\n\n\n\nname\ntype\nsurface_soil_moisture\nunit\n\n\ntime\n\n\n\n\n\n\n\n\n2024-01-01 06:23:23.932999680\nBuzi\nascat\n48.61\n%\n\n\n2024-01-01 07:17:21.082001408\nBuzi\nascat\n51.29\n%\n\n\n2024-01-01 18:52:13.149000192\nBuzi\nascat\n43.34\n%\n\n\n2024-01-01 19:46:11.505000448\nBuzi\nascat\n41.71\n%\n\n\n2024-01-03 06:36:02.624999936\nBuzi\nascat\n53.57\n%\n\n\n\n\n\n\n\nNow we can use the TU Wien developed package pyswi to calculate time series SWI. First we have to prepare the numpy arrays for the SSM and Julian time stamps2, like so:\n\nswi_jd = sm_ts.index.to_julian_date().to_numpy().astype(np.float64)\nsm = sm_ts[\"surface_soil_moisture\"].to_numpy()\n\ndtype = np.dtype([(\"sm_jd\", np.float64), (\"sm\", np.float32)])\nssm_ts = unstructured_to_structured(\n    np.hstack((swi_jd[:, np.newaxis], sm[:, np.newaxis])), dtype=dtype\n)\n\nNow we can calculate the SWI. Here we calculate it for depth intervals of 5, 50, and 100 cm.\n\nt_value = np.array([5, 50, 100], dtype=np.int32)\nswi_ts, gain_out = calc_swi_ts(ssm_ts, swi_jd, t_value=t_value)\n\nAfter which, we convert the numpy arrays back to a pandas DataFrame and merge it with the original SSM data. This requires the Julian time steps to be converted back to a normal pandas datetime type.\n\nswi_ts = pd.DataFrame(swi_ts)\nswi_ts[\"time\"] = pd.to_datetime(swi_ts[\"swi_jd\"] - 2440587.5, unit=\"D\")\nts = pd.merge_asof(sm_ts, swi_ts.set_index(\"time\"), left_index=True, right_index=True)\n\nFinally, we plot the results where see the lagged and dampened response of soil moisture content with increasing depth.\n\nts.hvplot.line(\n    y=[\"surface_soil_moisture\", \"swi_5\", \"swi_50\", \"swi_100\"], frame_width=800\n)",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#footnotes",
    "href": "chapters/courses/environmental-remote-sensing/unit_01/06_supplement_drought.html#footnotes",
    "title": "15Â  Access to Historic Soil Moisture Data",
    "section": "",
    "text": "W. Wagner, Lemoine, G., Rott, H., 1999, A Method for Estimating Soil Moisture from ERS Scatterometer and Soil Data, Remote Sensing of Environment, Volume 70-2, pp.Â 191-207, doi: S0034-4257(99)00036-Xâ†©ï¸Ž\nJulian time stamps, also known as Julian dates, are continuous counts of days and fractions of days since a specific starting point, commonly used in astronomy and scientific applications to measure time intervals precisely.â†©ï¸Ž",
    "crumbs": [
      "Environmental Remote Sensing",
      "<span class='chapter-number'>15</span>Â  <span class='chapter-title'>Access to Historic Soil Moisture Data</span>"
    ]
  },
  {
    "objectID": "chapters/templates/prereqs-templates.html",
    "href": "chapters/templates/prereqs-templates.html",
    "title": "Templates",
    "section": "",
    "text": "This section of the Cookbook covers a wide range of topics. The intent is to create templates to showcase workflows that can be used by students as a primer for independent research projects.\n\n\n\nConcepts\nImportance\nNotes\n\n\n\n\nIntro to xarray\nNecessary\n\n\n\nDask Arrays\nNecessary\n\n\n\nDocumentation scikit-learn\nNeccesary\nMachine Learning in Python\n\n\nDocumentation Matplotlib\nHelpful\nPloting in Python\n\n\nDocumentation odc-stac\nHelpful\nData access\n\n\n\n\nTime to learn: 10 min",
    "crumbs": [
      "Appendices",
      "Templates"
    ]
  },
  {
    "objectID": "chapters/templates/classification.html",
    "href": "chapters/templates/classification.html",
    "title": "Appendix A â€” Classification of Sentinel-2 imagery",
    "section": "",
    "text": "A.1 Data Acquisition\nIn this chapter, we will employ machine learning techniques to classify a scene using satellite imagery. Specifically, we will utilize scikit-learn to implement two distinct classifiers and subsequently compare their results. To begin, we need to import the following modules.\nfrom datetime import datetime, timedelta\n\nimport cmcrameri as cmc  # noqa: F401\nimport geopandas as gpd\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport odc.stac\nimport pandas as pd\nimport pystac_client\nimport rioxarray  # noqa: F401\nimport xarray as xr\nfrom odc.geo.geobox import GeoBox\nfrom shapely.geometry import Polygon\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nBefore we start, we need to load the data. We will use odc-stac to obtain data from Earth Search by Element 84. Here we define the area of interest and the time frame, aswell as the EPSG code and the resolution.",
    "crumbs": [
      "Appendices",
      "Templates",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/templates/classification.html#data-acquisition",
    "href": "chapters/templates/classification.html#data-acquisition",
    "title": "Appendix A â€” Classification of Sentinel-2 imagery",
    "section": "",
    "text": "A.1.1 Searching in the Catalog\nThe module odc-stac provides access to free, open source satelite data. To retrieve the data, we must define several parameters that specify the location and time period for the satellite data. Additionally, we must specify the data collection we wish to access, as multiple collections are available. In this example, we will use multispectral imagery from the Sentinel-2 satellite.\n\ndx = 0.0006  # 60m resolution\nepsg = 4326\n\n# Set Spatial extent\nlatmin, latmax = 47.86, 48.407\nlonmin, lonmax = 16.32, 16.9\nbounds = (lonmin, latmin, lonmax, latmax)\n\n\n# Set Temporal extent\nstart_date = datetime(year=2024, month=5, day=1)\nend_date = start_date + timedelta(days=10)\n\ntime_format = \"%Y-%m-%d\"\ndate_query = start_date.strftime(time_format) + \"/\" + end_date.strftime(time_format)\n\n# Search for Sentinel-2 data\nitems = (\n    pystac_client.Client.open(\"https://earth-search.aws.element84.com/v1\")\n    .search(\n        bbox=bounds,\n        collections=[\"sentinel-2-l2a\"],\n        datetime=date_query,\n        limit=100,\n    )\n    .item_collection()\n)\nprint(len(items), \"scenes found\")\n\n10 scenes found\n\n\nWe will now focus on the area south-east of Vienna, where the Nationalpark Donauauen is situated. The time frame we are interested in is the beginning of May 2024. After passing these parameters to the stac-catalog we have found 10 scenes that we can use for our analysis.\n\n\nA.1.2 Loading the Data\nNow we will load the data directly into an xarray dataset, which we can use to perform computations on the data. xarray is a powerful library for working with multi-dimensional arrays, making it well-suited for handling satellite data.\nHereâ€™s how we can load the data using odc-stac and xarray:\n\n# define a geobox for my region\ngeobox = GeoBox.from_bbox(bounds, crs=f\"epsg:{epsg}\", resolution=dx)\n\n# lazily combine items into a datacube\ndc = odc.stac.load(\n    items,\n    bands=[\"scl\", \"red\", \"green\", \"blue\", \"nir\"],\n    chunks={\"time\": 5, \"x\": 600, \"y\": 600},\n    geobox=geobox,\n    resampling=\"bilinear\",\n)\ndc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 79MB\nDimensions:      (latitude: 913, longitude: 967, time: 10)\nCoordinates:\n  * latitude     (latitude) float64 7kB 48.41 48.41 48.41 ... 47.86 47.86 47.86\n  * longitude    (longitude) float64 8kB 16.32 16.32 16.32 ... 16.9 16.9 16.9\n    spatial_ref  int32 4B 4326\n  * time         (time) datetime64[ns] 80B 2024-05-01T09:57:21.858000 ... 202...\nData variables:\n    scl          (time, latitude, longitude) uint8 9MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    red          (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    green        (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    blue         (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;\n    nir          (time, latitude, longitude) uint16 18MB dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;xarray.DatasetDimensions:latitude: 913longitude: 967time: 10Coordinates: (4)latitude(latitude)float6448.41 48.41 48.41 ... 47.86 47.86units :degrees_northresolution :-0.0006crs :EPSG:4326array([48.4071, 48.4065, 48.4059, ..., 47.8611, 47.8605, 47.8599], shape=(913,))longitude(longitude)float6416.32 16.32 16.32 ... 16.9 16.9units :degrees_eastresolution :0.0006crs :EPSG:4326array([16.3203, 16.3209, 16.3215, ..., 16.8987, 16.8993, 16.8999], shape=(967,))spatial_ref()int324326spatial_ref :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]crs_wkt :GEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],CS[ellipsoidal,2],AXIS[\"geodetic latitude (Lat)\",north,ORDER[1],ANGLEUNIT[\"degree\",0.0174532925199433]],AXIS[\"geodetic longitude (Lon)\",east,ORDER[2],ANGLEUNIT[\"degree\",0.0174532925199433]],USAGE[SCOPE[\"Horizontal component of 3D system.\"],AREA[\"World.\"],BBOX[-90,-180,90,180]],ID[\"EPSG\",4326]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984 ensemblegrid_mapping_name :latitude_longitudeGeoTransform :16.320000000000000284217094 0.000599999999999999947438 0 48.407399999999995543475961 0 -0.000599999999999999947438array(4326, dtype=int32)time(time)datetime64[ns]2024-05-01T09:57:21.858000 ... 2...array(['2024-05-01T09:57:21.858000000', '2024-05-01T09:57:24.892000000',\n       '2024-05-04T10:07:18.103000000', '2024-05-04T10:07:22.389000000',\n       '2024-05-06T09:57:19.789000000', '2024-05-06T09:57:22.823000000',\n       '2024-05-09T10:07:16.090000000', '2024-05-09T10:07:20.373000000',\n       '2024-05-11T09:57:22.239000000', '2024-05-11T09:57:25.274000000'],\n      dtype='datetime64[ns]')Data variables: (5)scl(time, latitude, longitude)uint8dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n8.42 MiB\n1.72 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint8 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nred(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\ngreen(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nblue(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10\n\n\n\n\nnir(time, latitude, longitude)uint16dask.array&lt;chunksize=(5, 600, 600), meta=np.ndarray&gt;nodata :0\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16.84 MiB\n3.43 MiB\n\n\nShape\n(10, 913, 967)\n(5, 600, 600)\n\n\nDask graph\n8 chunks in 3 graph layers\n\n\nData type\nuint16 numpy.ndarray\n\n\n\n\n                               967 913 10",
    "crumbs": [
      "Appendices",
      "Templates",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/templates/classification.html#data-visualization",
    "href": "chapters/templates/classification.html#data-visualization",
    "title": "Appendix A â€” Classification of Sentinel-2 imagery",
    "section": "A.2 Data Visualization",
    "text": "A.2 Data Visualization\n\nA.2.1 RGB Image\nWith the image data now in our possession, we can proceed with computations and visualizations.\nFirst, we define a mask to exclude cloud cover and areas with missing data. Subsequently, we create a composite median image, where each pixel value represents the median value across all the scenes we have identified. This approach helps to eliminate clouds and outliers present in some of the images, thereby providing a clearer and more representative visualization of the scene.\n\n# define a mask for valid pixels (non-cloud)\n\n\ndef is_valid_pixel(data):\n    # include only vegetated, not_vegitated, water, and snow\n    return ((data &gt; 3) & (data &lt; 7)) | (data == 11)\n\n\ndc[\"valid\"] = is_valid_pixel(dc.scl)\n\n# compute the masked median\nrgb_median = (\n    dc[[\"red\", \"green\", \"blue\"]]\n    .where(dc.valid)\n    .to_dataarray(dim=\"band\")\n    .median(dim=\"time\")\n    .astype(int)\n)\n\n# plot the median composite\ntitle_rgb = (\n    \"RGB - Median Composite\"\n    + f\"\\n{start_date.strftime('%d.%m.%Y')} - {end_date.strftime('%d.%m.%Y')}\"\n)\nrgb_median.plot.imshow(robust=True).axes.set_title(title_rgb)\nplt.show()\n\n/home/runner/work/eo-datascience/eo-datascience/.conda_envs/classification/lib/python3.12/site-packages/rasterio/warp.py:387: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n  dest = _reproject(\n\n\n\n\n\n\n\n\n\n\n\nA.2.2 False Color Image\nIn addition to the regular RGB Image, we can swap any of the bands from the visible spectrum with any other bands. In this specific case the red band has been changed to the near infrared band. This allows us to see vegetated areas more clearly, since they now appear in a bright red color. This is due to the fact that plants absorb regular red light while reflecting near infrared light (NASA 2020).\n\n# compute a false color image\n# near infrared instead of red\nfc_median = (\n    dc[[\"nir\", \"green\", \"blue\"]]\n    .where(dc.valid)\n    .to_dataarray(dim=\"band\")\n    .transpose(..., \"band\")\n    .median(dim=\"time\")\n    .astype(int)\n)\n\ntitle_fc = (\n    \"False color - Median Composite\"\n    + f\"\\n{start_date.strftime('%d.%m.%Y')} - {end_date.strftime('%d.%m.%Y')}\"\n)\nfc_median.plot.imshow(robust=True).axes.set_title(title_fc)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nA.2.3 NDVI Image\nTo get an first impression of the data, we can calculate the NDVI (Normalized Difference Vegetation Index) and plot it. The NDVI is calculated by useing the following formula. (Rouse et al. 1974)\n\\[\nNDVI = \\frac{NIR - Red}{NIR + Red}\n\\]\nThis gives us a good overview of the vegetation in the area. The values can range from -1 to 1 where the following meanings are associated with these values:\n\n-1 to 0 indicate dead plants or inanimate objects\n0 to 0.33 are unhealthy plants\n0.33 to 0.66 are moderatly healthy plants\n0.66 to 1 are very healthy plants\n\n\n# Normalized Difference Vegetation Index (NDVI)\n\n\ndef normalized_difference(a, b):\n    return (a - b * 1.0) / (a + b)\n\n\nndvi = normalized_difference(dc.nir, dc.red)\nndvi.median(dim=\"time\").plot.imshow(cmap=\"cmc.cork\", vmin=-1, vmax=1).axes.set_title(\n    \"NDVI\"\n)\nplt.show()",
    "crumbs": [
      "Appendices",
      "Templates",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/templates/classification.html#classification",
    "href": "chapters/templates/classification.html#classification",
    "title": "Appendix A â€” Classification of Sentinel-2 imagery",
    "section": "A.3 Classification",
    "text": "A.3 Classification\nIn this chapter, we will classify the satellite data to identify forested areas within the scene. By using supervised machine learning techniques, we can train classifiers to distinguish between forested and non-forested regions based on the training data we provide. We will explore two different classifiers and compare their performance in accurately identifying forest areas.\n\nA.3.1 Regions of Interest\nSince this is a supervised classification, we need to have some training data. Therefore we need to define areas or regions, which we are certain represent the feature which we are classifiying. In this case we are interested in forested areas and regions that are definitly not forested. These regions will be used to train our classifiers.\n\n# Define Polygons\nforest_areas = {\n    0: [\n        Polygon(\n            [\n                (16.482772, 47.901753),\n                (16.465133, 47.870124),\n                (16.510142, 47.874382),\n                (16.482772, 47.901753),\n            ]\n        )\n    ],\n    1: [\n        Polygon(\n            [\n                (16.594079, 47.938855),\n                (16.581914, 47.894454),\n                (16.620233, 47.910268),\n                (16.594079, 47.938855),\n            ]\n        )\n    ],\n    2: [\n        Polygon(\n            [\n                (16.67984, 47.978998),\n                (16.637263, 47.971091),\n                (16.660376, 47.929123),\n                (16.67984, 47.978998),\n            ]\n        )\n    ],\n    3: [\n        Polygon(\n            [\n                (16.756477, 48.000286),\n                (16.723024, 47.983256),\n                (16.739446, 47.972916),\n                (16.756477, 48.000286),\n            ]\n        )\n    ],\n    4: [\n        Polygon(\n            [\n                (16.80696, 48.135923),\n                (16.780806, 48.125583),\n                (16.798445, 48.115243),\n                (16.80696, 48.135923),\n            ]\n        )\n    ],\n    5: [\n        Polygon(\n            [\n                (16.684097, 48.144438),\n                (16.664634, 48.124366),\n                (16.690788, 48.118892),\n                (16.684097, 48.144438),\n            ]\n        )\n    ],\n    6: [\n        Polygon(\n            [\n                (16.550894, 48.169984),\n                (16.530822, 48.165118),\n                (16.558801, 48.137139),\n                (16.550894, 48.169984),\n            ]\n        )\n    ],\n    7: [\n        Polygon(\n            [\n                (16.588604, 48.402329),\n                (16.556976, 48.401112),\n                (16.580697, 48.382865),\n                (16.588604, 48.402329),\n            ]\n        )\n    ],\n}\n\nnonforest_areas = {\n    0: [\n        Polygon(\n            [\n                (16.674974, 48.269126),\n                (16.623882, 48.236281),\n                (16.682272, 48.213168),\n                (16.674974, 48.269126),\n            ]\n        )\n    ],\n    1: [\n        Polygon(\n            [\n                (16.375723, 48.228374),\n                (16.357476, 48.188839),\n                (16.399444, 48.185798),\n                (16.375723, 48.228374),\n            ]\n        )\n    ],\n    2: [\n        Polygon(\n            [\n                (16.457834, 48.26426),\n                (16.418907, 48.267301),\n                (16.440804, 48.23324),\n                (16.457834, 48.26426),\n            ]\n        )\n    ],\n    3: [\n        Polygon(\n            [\n                (16.519266, 48.101861),\n                (16.470607, 48.100645),\n                (16.500411, 48.07145),\n                (16.519266, 48.101861),\n            ]\n        )\n    ],\n    4: [\n        Polygon(\n            [\n                (16.453577, 48.051986),\n                (16.412217, 48.067192),\n                (16.425598, 48.012451),\n                (16.453577, 48.051986),\n            ]\n        )\n    ],\n}\n\n\n# Geoppandas Dataframe from Polygons\nforest_df = gpd.GeoDataFrame(\n    {\"geometry\": [poly[0] for poly in forest_areas.values()]}, crs=\"EPSG:4326\"\n)\nnonforest_df = gpd.GeoDataFrame(\n    {\"geometry\": [poly[0] for poly in nonforest_areas.values()]},\n    crs=\"EPSG:4326\",\n)\n\n\n# Plotting Regions of Interest\nfig, ax = plt.subplots()\nrgb_median.plot.imshow(ax=ax, robust=True)\nforest_df.plot(ax=ax, ec=\"C0\", fc=\"none\")\nnonforest_df.plot(ax=ax, ec=\"C1\", fc=\"none\")\nax.set_title(\"Regions of Interest\")\nax.set_aspect(\"equal\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nA.3.2 Data Preparation\nIn addition to the Regions of Interest we will extract the specific bands from the loaded dataset that we intend to use for the classification, which are the red, green, blue and near-infrared bands, although other bands can also be utilized. Using these bands, we will create both a training and a testing dataset. The training dataset will be used to train the classifier, while the testing dataset will be employed to evaluate its performance.\n\n# Classifiying dataset (only necessary bands)\nbands = [\"red\", \"green\", \"blue\", \"nir\"]\nds_class = dc[bands].where(dc.valid).median(dim=\"time\")\nds_class = ds_class.fillna(0)\n\n\ndef clip_array(ds: xr.Dataset, polygons):\n    clipped = ds.rio.clip(polygons, invert=False, all_touched=False, drop=True)\n    clipped_nan = clipped.where(clipped == ds)\n    return clipped_nan\n\n\n# Dictionaries with Dataarrays, each clipped by a Polygon\ndata_dict_feat = {\n    idx: clip_array(ds_class, polygon) for idx, polygon in forest_areas.items()\n}\ndata_dict_nonfeat = {\n    idx: clip_array(ds_class, polygon) for idx, polygon in nonforest_areas.items()\n}\n\n\n# Reshape the polygon dataarrays to get a tuple (one value per band) of pixel values\nfeat_data = [\n    xarray.to_array().values.reshape(len(bands), -1).T\n    for xarray in data_dict_feat.values()\n]  # replaced median_data_dict_feat with data_dict_feat\nnonfeat_data = [\n    xarray.to_array().values.reshape(len(bands), -1).T\n    for xarray in data_dict_nonfeat.values()\n]  # replaced median_data_dict_feat with data_dict_feat\n\n# The rows of the different polygons are concatenated to a single array for further processing\nfeat_values = np.concatenate(feat_data)\nnonfeat_values = np.concatenate(nonfeat_data)\n\n# Drop Nan Values\nX_feat_data = feat_values[~np.isnan(feat_values).any(axis=1)]\nX_nonfeat_data = nonfeat_values[~np.isnan(nonfeat_values).any(axis=1)]\n\n\n# Creating Output Vector (1 for pixel is features; 0 for pixel is not feature)\ny_feat_data = np.ones(X_feat_data.shape[0])\ny_nonfeat_data = np.zeros(X_nonfeat_data.shape[0])\n\n# Concatenate all Classes for training\nX = np.concatenate([X_feat_data, X_nonfeat_data])\ny = np.concatenate([y_feat_data, y_nonfeat_data])\n\n# Split into Training and Testing Data.\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.5, random_state=42\n)\n\nNow that we have prepared the training and testing data, we will create an image array of the actual scene that we intend to classify. This array will serve as the input for our classification algorithms, allowing us to apply the trained classifiers to the entire scene and identify the forested and non-forested areas accurately.\n\nimage_data = (\n    ds_class[bands].to_array(dim=\"band\").transpose(\"latitude\", \"longitude\", \"band\")\n)\n\n# Reshape the image data\nnum_of_pixels = ds_class.sizes[\"longitude\"] * ds_class.sizes[\"latitude\"]\nnum_of_bands = len(bands)\nX_image_data = image_data.values.reshape(num_of_pixels, num_of_bands)\n\n\n\nA.3.3 Classifiying with Naive Bayes\nNow that we have prepared all the needed data, we can begin the actual classification process.\nWe will start with a Naive Bayes classifier. First, we will train the classifier using our training dataset. Once trained, we will apply the classifier to the actual image to identify the forested and non-forested areas.\n\n# Naive Bayes initialization and training\nnb = GaussianNB()\nnb_test = nb.fit(X_train, y_train)\nnb_predict = nb.predict(X_test)\n\n# Prediction on image\nnb_predict_img = nb.predict(X_image_data)\nnb_predict_img = nb_predict_img.reshape(\n    ds_class.sizes[\"latitude\"], ds_class.sizes[\"longitude\"]\n)\n\n# Adding the Naive Bayes Prediction to the dataset\nds_class[\"NB-forest\"] = xr.DataArray(\n    nb_predict_img,\n    dims=[\"latitude\", \"longitude\"],\n    coords={\n        \"longitude\": ds_class[\"longitude\"],\n        \"latitude\": ds_class[\"latitude\"],\n    },\n)\n\nTo evaluate the effectiveness of the classification, we will plot the image predicted by the classifier. Additionally, we will examine the Classification Report and the Confusion Matrix to gain further insights into the classifierâ€™s performance.\n\n# Plot Naive Bayes\nalpha = 1\ncmap_green = colors.ListedColormap([(1, 1, 1, alpha), \"green\"])\n\nplot = ds_class[\"NB-forest\"].plot.imshow(\n    cmap=cmap_green, cbar_kwargs={\"ticks\": [0.25, 0.75]}\n)\ncbar = plot.colorbar\ncbar.set_ticklabels([\"non-forest\", \"forest\"])\nplot.axes.set_title(\"Naive Bayes Classification\")\nplt.show()\n\n# Print the Classification report\nprint(\"NAIVE BAYES: \\n \" + classification_report(y_test, nb_predict))\n\n# Print the confusion matrix\ncon_mat_nb = pd.DataFrame(\n    confusion_matrix(y_test, nb_predict),\n    index=[\"Actual Negative\", \"Actual Positive\"],\n    columns=[\"Predicted Negative\", \"Predicted Positive\"],\n)\ndisplay(con_mat_nb)\n\n\n\n\n\n\n\n\nNAIVE BAYES: \n               precision    recall  f1-score   support\n\n         0.0       0.95      0.82      0.88      6618\n         1.0       0.81      0.95      0.88      5487\n\n    accuracy                           0.88     12105\n   macro avg       0.88      0.88      0.88     12105\nweighted avg       0.89      0.88      0.88     12105\n\n\n\n\n\n\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\n5406\n1212\n\n\nActual Positive\n276\n5211\n\n\n\n\n\n\n\n\n\nA.3.4 Classifiying with Random Forest\nTo ensure our results are robust, we will explore an additional classifier. In this section, we will use the Random Forest classifier. The procedure for using this classifier is the same as before: we will train the classifier using our training dataset and then apply it to the actual image to classify the scene.\n\n# Random Forest initialization and training\nrf = RandomForestClassifier(n_estimators=100)\nrf_test = rf.fit(X_train, y_train)\nrf_predict = rf.predict(X_test)\n\n# Prediction on image\nrf_predict_img = rf.predict(X_image_data)\nrf_predict_img = rf_predict_img.reshape(\n    ds_class.sizes[\"latitude\"], ds_class.sizes[\"longitude\"]\n)\n\n# Adding the Random Forest Prediction to the dataset\nds_class[\"RF-forest\"] = xr.DataArray(\n    rf_predict_img,\n    dims=[\"latitude\", \"longitude\"],\n    coords={\n        \"longitude\": ds_class[\"longitude\"],\n        \"latitude\": ds_class[\"latitude\"],\n    },\n)\n\nplot = ds_class[\"RF-forest\"].plot.imshow(\n    cmap=cmap_green, cbar_kwargs={\"ticks\": [0.25, 0.75]}\n)\ncbar = plot.colorbar\ncbar.set_ticklabels([\"non-forest\", \"forest\"])\nplot.axes.set_title(\"Random Forest Classification\")\nplt.show()\n\n# Print the Classification report\nprint(\"RANDOM FOREST: \\n \" + classification_report(y_test, rf_predict))\n\n# Print the confusion matrix\ncon_mat_rf = pd.DataFrame(\n    confusion_matrix(y_test, rf_predict),\n    index=[\"Actual Negative\", \"Actual Positive\"],\n    columns=[\"Predicted Negative\", \"Predicted Positive\"],\n)\ndisplay(con_mat_rf)\n\n\n\n\n\n\n\n\nRANDOM FOREST: \n               precision    recall  f1-score   support\n\n         0.0       0.96      0.95      0.95      6618\n         1.0       0.94      0.95      0.94      5487\n\n    accuracy                           0.95     12105\n   macro avg       0.95      0.95      0.95     12105\nweighted avg       0.95      0.95      0.95     12105\n\n\n\n\n\n\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\n6297\n321\n\n\nActual Positive\n289\n5198\n\n\n\n\n\n\n\nWe can already see from the classification reports and the confusion matrices that the Random Forest classifier has outperformed the Naive Bayes classifier. This is particularly evident from the lower values in the secondary diagonal, indicating minimal False Positives and False Negatives. It appears that the Naive Bayes classifier is more sensitive to False Positives, resulting in a higher rate of incorrect classifications.\n\n\nA.3.5 Comparison of the Classificators\nTo gain a more in-depth understanding of the classifiersâ€™ performance, we will compare their results. Specifically, we will identify the areas where both classifiers agree and the areas where they disagree. This comparison will provide valuable insights into the strengths and weaknesses of each classifier, allowing us to better assess their effectiveness in identifying forested and non-forested regions.\n\n\nCode\ncmap_trio = colors.ListedColormap([\"whitesmoke\", \"indianred\", \"goldenrod\", \"darkgreen\"])\n\n\ndouble_clf = ds_class[\"NB-forest\"] + 2 * ds_class[\"RF-forest\"]\n\nfig, ax = plt.subplots()\ncax = ax.imshow(double_clf, cmap=cmap_trio, interpolation=\"none\")\n\n# Add a colorbar with custom tick labels\ncbar = fig.colorbar(cax, ticks=[1 * 0.375, 3 * 0.375, 5 * 0.375, 7 * 0.375])\ncbar.ax.set_yticklabels([\"None\", \"Naive Bayes\", \"Random Forest\", \"Both\"])\nax.set_title(\"Classification Comparisson\")\nax.set_axis_off()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe areas where both classifiers agree include the larger forested regions, such as the Nationalpark Donau-Auen and the Leithagebirge. Additionally, both classifiers accurately identified the urban areas of Vienna and correctly excluded them from being classified as forested.\n\n\nCode\n# Plot only one class, either None (0), Naive Bayes (1), Random Forest (2), or Both (3)\nfig, axs = plt.subplots(2, 2, figsize=(8, 8))\nax = axs.ravel()\n\nfor i in range(4):\n    ax[i].imshow(double_clf == i, cmap=\"cmc.oleron_r\", interpolation=\"none\")\n    category = [\n        \"by None\",\n        \"only by Naive Bayes\",\n        \"only by Random Forest\",\n        \"by Both\",\n    ][i]\n    title = \"Areas classified \" + category\n    ax[i].set_title(title)\n    ax[i].set_axis_off()\n\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nWhen plotting the classified areas individually, we observe that the Random Forest classifier mistakenly identified the Danube River as a forested area. Conversely, the Naive Bayes classifier erroneously classified a significant amount of cropland as forest.\nFinally, by analyzing the proportion of forested areas within the scene, we find that approximately 18% of the area is classified as forest, while around 66% is classified as non-forest. The remaining areas, which include water bodies and cropland, fall into less clearly defined categories.\nThe accompanying bar chart illustrates the distribution of these classifications, highlighting the percentage of forested areas, non-forested areas, and regions classified by only one of the two classifiers. This visual representation helps to quantify the areas of agreement and disagreement between the classifiers, providing a clearer picture of their performance.\n\n\nCode\ncounts = {}\nfor num in range(0, 4):\n    num_2_class = {0: \"None\", 1: \"Naive Bayes\", 2: \"Random Forest\", 3: \"Both\"}\n    counts[num_2_class[num]] = int((double_clf == num).sum().values)\n\nclass_counts_df = pd.DataFrame(list(counts.items()), columns=[\"Class\", \"Count\"])\nclass_counts_df[\"Percentage\"] = (\n    class_counts_df[\"Count\"] / class_counts_df[\"Count\"].sum()\n) * 100\nax = class_counts_df.plot.bar(\n    x=\"Class\",\n    y=\"Percentage\",\n    rot=0,\n    color=\"darkgreen\",\n    ylim=(0, 100),\n    title=\"Classified Areas per Classificator (%)\",\n)\n\n# Annotate the bars with the percentage values\nfor p in ax.patches:\n    ax.annotate(\n        f\"{p.get_height():.1f}%\",\n        (p.get_x() + p.get_width() / 2.0, p.get_height()),\n        ha=\"center\",\n        va=\"center\",\n        xytext=(0, 9),\n        textcoords=\"offset points\",\n    )",
    "crumbs": [
      "Appendices",
      "Templates",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/templates/classification.html#conclusion",
    "href": "chapters/templates/classification.html#conclusion",
    "title": "Appendix A â€” Classification of Sentinel-2 imagery",
    "section": "A.4 Conclusion",
    "text": "A.4 Conclusion\nIn this chapter, we utilized machine learning to classify satellite imagery into forested and non-forested areas, comparing Naive Bayes and Random Forest classifiers. The Random Forest classifier generally outperformed Naive Bayes, with fewer errors in classification, although it misclassified the Danube River as forested, while Naive Bayes incorrectly identified cropland as forest. The analysis, supported by the bar chart, revealed that about 18% of the scene was classified as forest, 66% as non-forest, and the remainder included ambiguous categories. This comparison highlights the strengths and limitations of each classifier, underscoring the need for careful selection and evaluation of classification methods.\n\n\n\n\nNASA. 2020. â€œEarth Observatory.â€ 2020. https://earthobservatory.nasa.gov/features/MeasuringVegetation/measuring_vegetation_2.php.\n\n\nRouse, John Wilson, RÃ¼diger H Haas, John A Schell, Donald W Deering, et al. 1974. â€œMonitoring Vegetation Systems in the Great Plains with ERTS.â€ NASA Spec. Publ 351 (1): 309.",
    "crumbs": [
      "Appendices",
      "Templates",
      "<span class='chapter-number'>A</span>Â  <span class='chapter-title'>Classification of Sentinel-2 imagery</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/prereqs-tutorials.html",
    "href": "chapters/tutorials/prereqs-tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "This section of the Cookbook covers a wide range of topics. They showcase the creation and usage of data products developed by TU Wien and EODC.",
    "crumbs": [
      "Appendices",
      "Tutorials"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html",
    "href": "chapters/tutorials/floodmapping.html",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "",
    "text": "B.1 Overview\nThis notebook explains how microwave (\\(\\sigma^0\\)) backscattering can be used to map the extent of a flood. We replicate in this exercise the work of (Bauer-Marschallinger et al. 2022) on the TU Wien Bayesian-based flood mapping algorithm.",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#prerequisites",
    "href": "chapters/tutorials/floodmapping.html#prerequisites",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.2 Prerequisites",
    "text": "B.2 Prerequisites\n\n\n\nConcepts\nImportance\nNotes\n\n\n\n\nIntro to xarray\nNecessary\n\n\n\nIntro to Harmonic parameters\nNecessary\n\n\n\nDocumentation hvPlot\nHelpful\nInteractive plotting\n\n\nDocumentation odc-stac\nHelpful\nData access\n\n\n\n\nTime to learn: 10 min",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#imports",
    "href": "chapters/tutorials/floodmapping.html#imports",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.3 Imports",
    "text": "B.3 Imports\n\nimport datetime\n\nimport holoviews as hv\nimport hvplot.pandas\nimport hvplot.xarray\nimport numpy as np\nimport pandas as pd\nimport panel as pn\nimport pystac_client\nimport rioxarray  # noqa: F401\nimport xarray as xr\nfrom bokeh.models import FixedTicker\nfrom odc import stac as odc_stac\nfrom scipy.stats import norm\n\npn.extension()\nhv.extension(\"bokeh\")",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#greece-flooding-2018",
    "href": "chapters/tutorials/floodmapping.html#greece-flooding-2018",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.4 Greece Flooding 2018",
    "text": "B.4 Greece Flooding 2018\nIn this exercise we will replicate the case study of the above mentioned paper, the February 2018 flooding of the Greek region of Thessaly.\n\ntime_range = \"2018-02-28T04:00:00Z/2018-02-28T05:00:00Z\"\nminlon, maxlon = 21.93, 22.23\nminlat, maxlat = 39.47, 39.64\nbounding_box = [minlon, minlat, maxlon, maxlat]",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#eodc-stac-catalog",
    "href": "chapters/tutorials/floodmapping.html#eodc-stac-catalog",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.5 EODC STAC Catalog",
    "text": "B.5 EODC STAC Catalog\nThe data required for TU Wien flood mapping algorithm consists of terrain corrected sigma naught backscatter data \\(\\sigma^{0}\\), the projected local incidence angle (PLIA) values of those measurements, and the harmonic parameters (HPAR) of a model fit on the pixelâ€™s backscatter time series. The latter two datasets will needed to calculate the probability density functions over land and water for. We will be getting the required data from the EODC STAC Catalog. Specifically the collections: SENTINEL_SIG0_20M, SENTINEL1_MPLIA and SENTINEL1_HPAR. We use the pystac-client and odc_stac packages to, respectively, discover and fetch the data.\nDue to the way the data is acquired and stored, some items include â€œno dataâ€ areas. In our case, no data has the value -9999, but this can vary from data provider to data provider. This information can usually be found in the metadata. Furthermore, to save memory, data is often stored as integer (e.g.Â 25) and not in float (e.g.Â 2.5) format. For this reason, the backscatter values are often multiplied by a scale factor. Hence we define the function post_process_eodc_cube to correct for these factors as obtained from the STAC metadata.\n\nB.5.1 Sigma naught\n\neodc_catalog = pystac_client.Client.open(\"https://stac.eodc.eu/api/v1\")\nsearch = eodc_catalog.search(\n    collections=\"SENTINEL1_SIG0_20M\",\n    bbox=bounding_box,\n    datetime=time_range,\n)\nitems_sig0 = search.item_collection()\n\n\ndef post_process_eodc_cube(dc, items, bands):\n    \"\"\"\n    Postprocessing of EODC data cubes.\n\n    Parameters\n    ----------\n    x : xarray.Dataset\n    items: pystac.item_collection.ItemCollection\n        STAC items that concern the Xarray Dataset\n    bands: array\n        Selected bands\n\n    Returns\n    -------\n    xarray.Dataset\n    \"\"\"\n    if not isinstance(bands, tuple):\n        bands = tuple([bands])\n    for i in bands:\n        dc[i] = post_process_eodc_cube_(dc[i], items, i)\n    return dc\n\n\ndef post_process_eodc_cube_(dc, items, band):\n    fields = items[0].assets[band].extra_fields\n    scale = fields.get(\"raster:bands\")[0][\"scale\"]\n    nodata = fields.get(\"raster:bands\")[0][\"nodata\"]\n    return dc.where(dc != nodata) / scale\n\n\nbands = \"VV\"\nsig0_dc = odc_stac.load(items_sig0, bands=bands, bbox=bounding_box)\nsig0_dc = (\n    post_process_eodc_cube(sig0_dc, items_sig0, bands)\n    .rename_vars({\"VV\": \"sig0\"})\n    .dropna(dim=\"time\", how=\"all\")\n    .median(\"time\")\n)\n\nsig0_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:      (y: 977, x: 1324)\nCoordinates:\n  * y            (y) float64 8kB 6.388e+05 6.388e+05 ... 6.193e+05 6.193e+05\n  * x            (x) float64 11kB 5.658e+06 5.658e+06 ... 5.684e+06 5.684e+06\n    spatial_ref  int32 4B 27704\nData variables:\n    sig0         (y, x) float32 5MB -9.6 -9.2 -8.3 -8.7 ... -12.3 -11.6 -9.7xarray.DatasetDimensions:y: 977x: 1324Coordinates: (3)y(y)float646.388e+05 6.388e+05 ... 6.193e+05units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([638790., 638770., 638750., ..., 619310., 619290., 619270.], shape=(977,))x(x)float645.658e+06 5.658e+06 ... 5.684e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5657530., 5657550., 5657570., ..., 5683950., 5683970., 5683990.],\n      shape=(1324,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5657520 20 0 638800 0 -20array(27704, dtype=int32)Data variables: (1)sig0(y, x)float32-9.6 -9.2 -8.3 ... -12.3 -11.6 -9.7array([[ -9.6,  -9.2,  -8.3, ...,  -9.6, -10. ,  -9.9],\n       [ -9. ,  -8.2,  -7.9, ...,  -9.6,  -9.4,  -9.3],\n       [ -7.6,  -6.9,  -6.9, ..., -11.3, -10.3, -10.1],\n       ...,\n       [ -7.6,  -9.2, -10.3, ..., -11.8, -10.5,  -8.7],\n       [ -8.6,  -7.5,  -7.9, ..., -13.3, -11.5,  -9. ],\n       [ -9.3,  -7.4,  -6.2, ..., -12.3, -11.6,  -9.7]],\n      shape=(977, 1324), dtype=float32)\n\n\n\n\nB.5.2 Harmonic Parameters\n\nsearch = eodc_catalog.search(\n    collections=\"SENTINEL1_HPAR\",\n    bbox=bounding_box,\n    query=[\"sat:relative_orbit=80\"],\n)\n\nitems_hpar = search.item_collection()\nbands = (\"C1\", \"C2\", \"C3\", \"M0\", \"S1\", \"S2\", \"S3\", \"STD\")\nhpar_dc = odc_stac.load(\n    items_hpar,\n    bands=bands,\n    bbox=bounding_box,\n    groupby=None,\n)\nhpar_dc = post_process_eodc_cube(hpar_dc, items_hpar, bands).median(\"time\")\nhpar_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 41MB\nDimensions:      (y: 977, x: 1324)\nCoordinates:\n  * y            (y) float64 8kB 6.388e+05 6.388e+05 ... 6.193e+05 6.193e+05\n  * x            (x) float64 11kB 5.658e+06 5.658e+06 ... 5.684e+06 5.684e+06\n    spatial_ref  int32 4B 27704\nData variables:\n    C1           (y, x) float32 5MB -0.1 -0.1 0.0 0.1 0.3 ... 1.2 1.6 1.8 1.4\n    C2           (y, x) float32 5MB -0.1 -0.2 -0.2 0.0 -0.1 ... 0.2 0.2 0.6 0.6\n    C3           (y, x) float32 5MB 0.2 0.1 0.0 0.0 0.1 ... -0.4 -0.6 -0.5 -0.6\n    M0           (y, x) float32 5MB -9.0 -9.7 -10.0 -9.7 ... -11.8 -11.3 -11.5\n    S1           (y, x) float32 5MB -0.3 -0.2 -0.2 -0.1 ... -0.3 -0.2 -0.7 -1.1\n    S2           (y, x) float32 5MB -0.2 0.0 0.0 -0.2 ... -0.2 -0.3 -0.4 -0.2\n    S3           (y, x) float32 5MB -0.1 0.0 0.0 -0.1 -0.1 ... 0.0 0.1 0.1 0.4\n    STD          (y, x) float32 5MB 1.3 1.2 1.1 1.0 1.2 ... 1.9 1.9 1.8 1.8 1.9xarray.DatasetDimensions:y: 977x: 1324Coordinates: (3)y(y)float646.388e+05 6.388e+05 ... 6.193e+05units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([638790., 638770., 638750., ..., 619310., 619290., 619270.], shape=(977,))x(x)float645.658e+06 5.658e+06 ... 5.684e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5657530., 5657550., 5657570., ..., 5683950., 5683970., 5683990.],\n      shape=(1324,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5657520 20 0 638800 0 -20array(27704, dtype=int32)Data variables: (8)C1(y, x)float32-0.1 -0.1 0.0 0.1 ... 1.6 1.8 1.4array([[-0.1, -0.1,  0. , ..., -0.4, -0.2, -0.5],\n       [ 0.1,  0.2,  0.3, ..., -0.5, -0.2, -0.5],\n       [ 0.6,  0.7,  0.7, ..., -0.6, -0.5, -0.5],\n       ...,\n       [ 0.6,  1.1,  1.2, ...,  1.2,  1.3,  1.3],\n       [ 1. ,  1.2,  1.4, ...,  1.1,  1.4,  1.4],\n       [ 1.4,  1.6,  1.8, ...,  1.6,  1.8,  1.4]],\n      shape=(977, 1324), dtype=float32)C2(y, x)float32-0.1 -0.2 -0.2 0.0 ... 0.2 0.6 0.6array([[-0.1, -0.2, -0.2, ..., -0.1, -0.2, -0.2],\n       [ 0. , -0.1,  0. , ..., -0.1, -0.2, -0.2],\n       [ 0.3,  0.3,  0.2, ...,  0. ,  0. , -0.1],\n       ...,\n       [ 0.4,  0.5,  0.5, ...,  0.6,  0.6,  0.6],\n       [ 0.5,  0.5,  0.6, ...,  0.3,  0.5,  0.6],\n       [ 0.5,  0.3,  0.4, ...,  0.2,  0.6,  0.6]],\n      shape=(977, 1324), dtype=float32)C3(y, x)float320.2 0.1 0.0 0.0 ... -0.6 -0.5 -0.6array([[ 0.2,  0.1,  0. , ...,  0.2,  0.3,  0.3],\n       [ 0. ,  0. ,  0. , ...,  0.1,  0.2,  0.2],\n       [-0.2,  0. ,  0.1, ...,  0.1,  0. ,  0. ],\n       ...,\n       [-0.2, -0.3, -0.2, ..., -0.4, -0.3, -0.1],\n       [-0.3, -0.4, -0.3, ..., -0.3, -0.3, -0.2],\n       [-0.4, -0.5, -0.4, ..., -0.6, -0.5, -0.6]],\n      shape=(977, 1324), dtype=float32)M0(y, x)float32-9.0 -9.7 -10.0 ... -11.3 -11.5array([[ -9. ,  -9.7, -10. , ...,  -8.9,  -9. ,  -8.9],\n       [ -8.6,  -9.4,  -9.9, ...,  -9. ,  -9.2,  -9.6],\n       [ -7.8,  -7.7,  -8.4, ..., -10.7, -10.1, -10.6],\n       ...,\n       [ -9. ,  -9.5,  -9.7, ..., -12.5, -12.4, -12.1],\n       [ -9.6,  -9.7,  -9.6, ..., -12.2, -11.9, -11.9],\n       [ -9.5,  -9.5,  -9.5, ..., -11.8, -11.3, -11.5]],\n      shape=(977, 1324), dtype=float32)S1(y, x)float32-0.3 -0.2 -0.2 ... -0.2 -0.7 -1.1array([[-0.3, -0.2, -0.2, ...,  0. ,  0. , -0.4],\n       [-0.2, -0.3, -0.4, ...,  0. ,  0. , -0.3],\n       [ 0.1, -0.2, -0.3, ...,  0. , -0.1, -0.1],\n       ...,\n       [-1.4, -1.5, -1.1, ..., -0.6, -0.4, -0.6],\n       [-1.7, -1.9, -1.7, ..., -0.1, -0.4, -0.8],\n       [-1.6, -1.7, -1.7, ..., -0.2, -0.7, -1.1]],\n      shape=(977, 1324), dtype=float32)S2(y, x)float32-0.2 0.0 0.0 ... -0.3 -0.4 -0.2array([[-0.2,  0. ,  0. , ...,  0.4,  0.3,  0.1],\n       [-0.1,  0. ,  0. , ...,  0.5,  0.3,  0.1],\n       [-0.1,  0. ,  0. , ...,  0.5,  0.6,  0.2],\n       ...,\n       [ 0.7,  0.5,  0.3, ..., -0.6, -0.5, -0.3],\n       [ 0.2,  0.4,  0.3, ..., -0.2, -0.5, -0.4],\n       [ 0. ,  0.2,  0.4, ..., -0.3, -0.4, -0.2]],\n      shape=(977, 1324), dtype=float32)S3(y, x)float32-0.1 0.0 0.0 -0.1 ... 0.1 0.1 0.4array([[-0.1,  0. ,  0. , ..., -0.1, -0.1,  0. ],\n       [-0.2, -0.1,  0. , ..., -0.1,  0. ,  0. ],\n       [ 0. ,  0. ,  0. , ...,  0.1,  0. ,  0. ],\n       ...,\n       [-0.8, -0.7, -0.5, ...,  0. ,  0. ,  0. ],\n       [-0.4, -0.4, -0.4, ...,  0.2,  0.1,  0.3],\n       [-0.3, -0.4, -0.3, ...,  0.1,  0.1,  0.4]],\n      shape=(977, 1324), dtype=float32)STD(y, x)float321.3 1.2 1.1 1.0 ... 1.9 1.8 1.8 1.9array([[1.3, 1.2, 1.1, ..., 1.2, 1. , 1.1],\n       [1.3, 1.2, 1.2, ..., 0.9, 0.9, 1. ],\n       [1.3, 1.3, 1.2, ..., 0.9, 0.9, 1. ],\n       ...,\n       [2.2, 2.2, 1.7, ..., 1.9, 1.8, 1.8],\n       [2.5, 2.4, 2.1, ..., 1.8, 1.8, 1.9],\n       [2.5, 2.5, 2.3, ..., 1.8, 1.8, 1.9]],\n      shape=(977, 1324), dtype=float32)\n\n\n\n\nB.5.3 Projected Local Incidence Angles\n\nsearch = eodc_catalog.search(\n    collections=\"SENTINEL1_MPLIA\",\n    bbox=bounding_box,\n    query=[\"sat:relative_orbit=80\"],\n)\n\nitems_plia = search.item_collection()\n\nbands = \"MPLIA\"\nplia_dc = odc_stac.load(\n    items_plia,\n    bands=bands,\n    bbox=bounding_box,\n)\n\nplia_dc = post_process_eodc_cube(plia_dc, items_plia, bands).median(\"time\")\nplia_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 5MB\nDimensions:      (y: 977, x: 1324)\nCoordinates:\n  * y            (y) float64 8kB 6.388e+05 6.388e+05 ... 6.193e+05 6.193e+05\n  * x            (x) float64 11kB 5.658e+06 5.658e+06 ... 5.684e+06 5.684e+06\n    spatial_ref  int32 4B 27704\nData variables:\n    MPLIA        (y, x) float32 5MB 27.32 29.22 32.16 ... 33.79 34.02 34.27xarray.DatasetDimensions:y: 977x: 1324Coordinates: (3)y(y)float646.388e+05 6.388e+05 ... 6.193e+05units :metreresolution :-20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([638790., 638770., 638750., ..., 619310., 619290., 619270.], shape=(977,))x(x)float645.658e+06 5.658e+06 ... 5.684e+06units :metreresolution :20.0crs :PROJCS[\"Azimuthal_Equidistant\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Azimuthal_Equidistant\"],PARAMETER[\"latitude_of_center\",53],PARAMETER[\"longitude_of_center\",24],PARAMETER[\"false_easting\",5837287.81977],PARAMETER[\"false_northing\",2121415.69617],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]]]array([5657530., 5657550., 5657570., ..., 5683950., 5683970., 5683990.],\n      shape=(1324,))spatial_ref()int3227704spatial_ref :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]crs_wkt :PROJCRS[\"Azimuthal_Equidistant\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"unnamed\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.81977,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.69617,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :Azimuthal_Equidistantgrid_mapping_name :azimuthal_equidistantlatitude_of_projection_origin :53.0longitude_of_projection_origin :24.0false_easting :5837287.81977false_northing :2121415.69617GeoTransform :5657520 20 0 638800 0 -20array(27704, dtype=int32)Data variables: (1)MPLIA(y, x)float3227.32 29.22 32.16 ... 34.02 34.27array([[27.32, 29.22, 32.16, ..., 38.68, 37.31, 36.56],\n       [21.78, 24.62, 29.13, ..., 39.57, 38.85, 38.75],\n       [17.  , 20.55, 26.17, ..., 40.32, 40.23, 40.57],\n       ...,\n       [35.4 , 35.38, 35.39, ..., 33.86, 34.16, 34.63],\n       [35.41, 35.41, 35.41, ..., 33.77, 34.17, 34.65],\n       [35.41, 35.41, 35.41, ..., 33.79, 34.02, 34.27]],\n      shape=(977, 1324), dtype=float32)\n\n\nFinally, we merged the datasets as one big dataset and reproject the data in EPSG 4326 for easier visualizing of the data.\n\nflood_dc = xr.merge([sig0_dc, plia_dc, hpar_dc])\nflood_dc = flood_dc.rio.reproject(\"EPSG:4326\").rio.write_crs(\"EPSG:4326\")\nflood_dc\n\n/tmp/ipykernel_4466/355527453.py:1: FutureWarning: In a future version of xarray the default value for compat will change from compat='no_conflicts' to compat='override'. This is likely to lead to different results when combining overlapping variables with the same name. To opt in to new defaults and get rid of these warnings now use `set_options(use_new_combine_kwarg_defaults=True) or set compat explicitly.\n  flood_dc = xr.merge([sig0_dc, plia_dc, hpar_dc])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 49MB\nDimensions:      (x: 1443, y: 846)\nCoordinates:\n  * x            (x) float64 12kB 21.92 21.92 21.92 21.93 ... 22.23 22.23 22.23\n  * y            (y) float64 7kB 39.65 39.65 39.65 39.65 ... 39.46 39.46 39.46\n    spatial_ref  int64 8B 0\nData variables:\n    sig0         (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    MPLIA        (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    C1           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    C2           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    C3           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    M0           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    S1           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    S2           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    S3           (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nan\n    STD          (y, x) float32 5MB nan nan nan nan nan ... nan nan nan nan nanxarray.DatasetDimensions:x: 1443y: 846Coordinates: (3)x(x)float6421.92 21.92 21.92 ... 22.23 22.23axis :Xlong_name :longitudestandard_name :longitudeunits :degrees_eastarray([21.924527, 21.924742, 21.924957, ..., 22.234298, 22.234513, 22.234728],\n      shape=(1443,))y(y)float6439.65 39.65 39.65 ... 39.46 39.46axis :Ylong_name :latitudestandard_name :latitudeunits :degrees_northarray([39.645899, 39.645684, 39.645469, ..., 39.464554, 39.464339, 39.464124],\n      shape=(846,))spatial_ref()int640crs_wkt :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984grid_mapping_name :latitude_longitudespatial_ref :GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AXIS[\"Latitude\",NORTH],AXIS[\"Longitude\",EAST],AUTHORITY[\"EPSG\",\"4326\"]]GeoTransform :21.92441968968017 0.0002151185728747185 0.0 39.64600661223929 0.0 -0.0002151185728747185array(0)Data variables: (10)sig0(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)MPLIA(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)C1(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)C2(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)C3(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)M0(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)S1(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)S2(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)S3(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)STD(y, x)float32nan nan nan nan ... nan nan nan nan_FillValue :nanarray([[nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       ...,\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan],\n       [nan, nan, nan, ..., nan, nan, nan]],\n      shape=(846, 1443), dtype=float32)",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#from-backscattering-to-flood-mapping",
    "href": "chapters/tutorials/floodmapping.html#from-backscattering-to-flood-mapping",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.6 From Backscattering to Flood Mapping",
    "text": "B.6 From Backscattering to Flood Mapping\nIn the following lines we create a map with microwave backscattering values.\n\nmrs_view = flood_dc.sig0.hvplot.image(\n    x=\"x\", y=\"y\", cmap=\"viridis\", geo=True, tiles=True\n).opts(frame_height=400)\nmrs_view\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Area targeted for \\(\\sigma^0\\) backscattering is the Greek region of Thessaly, which experienced a major flood in February of 2018.\n\n\n\n\n\nFigureÂ B.1",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#microwave-backscattering-over-land-and-water",
    "href": "chapters/tutorials/floodmapping.html#microwave-backscattering-over-land-and-water",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.7 Microwave Backscattering over Land and Water",
    "text": "B.7 Microwave Backscattering over Land and Water\nReverend Bayes was concerned with two events, one (the hypothesis) occurring before the other (the evidence). If we know its cause, it is easy to logically deduce the probability of an effect. However, in this case we want to deduce the probability of a cause from an observed effect, also known as â€œreversed probabilityâ€. In the case of flood mapping, we have \\(\\sigma^0\\) backscatter observations over land (the effect) and we want to deduce the probability of flooding (\\(F\\)) and non-flooding (\\(NF\\)).\nIn other words, we want to know the probability of flooding \\(P(F)\\) given a pixelâ€™s \\(\\sigma^0\\):\n\\[P(F|\\sigma^0)\\]\nand the probability of a pixel being not flooded \\(P(NF)\\) given a certain \\(\\sigma^0\\):\n\\[P(NF|\\sigma^0).\\]\nBayes showed that these can be deduced from the observation that forward and reversed probability are equal, so that:\n\\[P(F|\\sigma^0)P(\\sigma^0) = P(\\sigma^0|F)P(F)\\]\nand\n\\[P(NF|\\sigma^0)P(\\sigma^0) = P(\\sigma^0|NF)P(NF).\\]\nThe forward probability of \\(\\sigma^0\\) given the occurrence of flooding (\\(P(\\sigma^0|F)\\)) and \\(\\sigma^0\\) given no flooding (\\(P(\\sigma^0|NF)\\)) can be extracted from past information on backscattering over land and water surfaces. As seen in the sketch below (FigureÂ B.2), the characteristics of backscattering over land and water differ considerably.\n\n\n\n\n\n\nFigureÂ B.2: Schematic backscattering over land and water. Image from Geological Survey Ireland",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#likelihoods",
    "href": "chapters/tutorials/floodmapping.html#likelihoods",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.8 Likelihoods",
    "text": "B.8 Likelihoods\nThe so-called likelihoods of \\(P(\\sigma^0|F)\\) and \\(P(\\sigma^0|NF)\\) can thus be calculated from past backscattering information. In the following code chunk we define the functions calc_water_likelihood and calc_land_likelihood to calculate the water and land likelihoodâ€™s of a pixel, based on the Xarray datasets for the PLIA and HPAR, respectively.\n\ndef calc_water_likelihood(sigma, x=None, y=None):\n    \"\"\"\n    Calculate water likelihoods.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    numpy array\n    \"\"\"\n    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n    wbsc_mean = point.MPLIA * -0.394181 + -4.142015\n    wbsc_std = 2.754041\n    return norm.pdf(sigma, wbsc_mean.to_numpy(), wbsc_std)\n\n\ndef expected_land_backscatter(data, dtime_str):\n    w = np.pi * 2 / 365\n    dt = datetime.datetime.strptime(dtime_str, \"%Y-%m-%d\")\n    t = dt.timetuple().tm_yday\n    wt = w * t\n\n    M0 = data.M0\n    S1 = data.S1\n    S2 = data.S2\n    S3 = data.S3\n    C1 = data.C1\n    C2 = data.C2\n    C3 = data.C3\n    hm_c1 = (M0 + S1 * np.sin(wt)) + (C1 * np.cos(wt))\n    hm_c2 = (hm_c1 + S2 * np.sin(2 * wt)) + C2 * np.cos(2 * wt)\n    hm_c3 = (hm_c2 + S3 * np.sin(3 * wt)) + C3 * np.cos(3 * wt)\n    return hm_c3\n\n\ndef calc_land_likelihood(sigma, x=None, y=None):\n    \"\"\"\n    Calculate land likelihoods.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    numpy array\n    \"\"\"\n    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n    lbsc_mean = expected_land_backscatter(point, \"2018-02-01\")\n    lbsc_std = point.STD\n    return norm.pdf(sigma, lbsc_mean.to_numpy(), lbsc_std.to_numpy())\n\nWithout going into the details of how these likelihoods are calculated, you can hover over a pixel of the map to plot the likelihoods of \\(\\sigma^0\\) being governed by land or water. For reference we model the water and land likelihoods (model_likelihoods) over a range of \\(\\sigma^0\\) values.\n\ndef model_likelihoods(sigma=(-30, 0), x=None, y=None):\n    \"\"\"\n    Model likelihoods over a range of sigma naught.\n\n    Parameters\n    ----------\n    sigma: tuple\n        Minimum and maximum for range of sigma naught values\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Pandas Datafrane\n    \"\"\"\n    sigma = np.arange(sigma[0], sigma[1], 0.1)\n    land_likelihood = calc_land_likelihood(sigma=sigma, x=x, y=y)\n    water_likelihood = calc_water_likelihood(sigma=sigma, x=x, y=y)\n    point = flood_dc.sel(x=x, y=y, method=\"nearest\")\n    return pd.DataFrame(\n        {\n            \"sigma\": sigma,\n            \"water_likelihood\": water_likelihood,\n            \"land_likelihood\": land_likelihood,\n            \"observed\": np.repeat(point.sig0.values, len(land_likelihood)),\n        }\n    )\n\n\npointer = hv.streams.PointerXY(source=mrs_view.get(1), x=22.1, y=39.5)\n\nlikelihood_pdi = hvplot.bind(\n    model_likelihoods, x=pointer.param.x, y=pointer.param.y\n).interactive()\n\nview_likelihoods = (\n    likelihood_pdi.hvplot(\"sigma\", \"water_likelihood\", ylabel=\"likelihoods\").dmap()\n    * likelihood_pdi.hvplot(\"sigma\", \"land_likelihood\").dmap()\n    * likelihood_pdi.hvplot(\"observed\", \"land_likelihood\").dmap()\n).opts(frame_height=200, frame_width=300)\n\nview_likelihoods + mrs_view.get(1)\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Likelihoods for \\(\\sigma^0\\) being associated with land or water for 1 pixel in the Greek area of Thessaly. Likelihoods are calculated over a range of \\(\\sigma^0\\). The pixelâ€™s observed \\(\\sigma^0\\) is given with a vertical line. Hover on the map to re-calculate and update this figure for another pixel in the study area.\n\n\n\n\n\nFigureÂ B.3",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#posteriors",
    "href": "chapters/tutorials/floodmapping.html#posteriors",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.9 Posteriors",
    "text": "B.9 Posteriors\nHaving calculated the likelihoods, we can now move on to calculate the probability of (non-)flooding given a pixelâ€™s \\(\\sigma^0\\). These so-called posteriors need one more piece of information, as can be seen in the equation above. We need the probability that a pixel is flooded \\(P(F)\\) or not flooded \\(P(NF)\\). Of course, these are the figures weâ€™ve been trying to find this whole time. We donâ€™t actually have them yet, so what can we do? In Bayesian statistics, we can just start with our best guess. These guesses are called our â€œpriorsâ€, because they are the beliefs we hold prior to looking at the data. This subjective prior belief is the foundation Bayesian statistics, and we use the likelihoods we just calculated to update our belief in this particular hypothesis. This updated belief is called the â€œposteriorâ€.\nLetâ€™s say that our best estimate for the chance of flooding versus non-flooding of a pixel is 50-50: a coin flip. We now can also calculate the probability of backscattering \\(P(\\sigma^0)\\), as the weighted average of the water and land likelihoods, ensuring that our posteriors range between 0 to 1.\nThe following code block shows how we calculate the priors.\n\ndef calc_posteriors(sigma, x=None, y=None):\n    \"\"\"\n    Calculate posterior probability.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Tuple of two Numpy arrays\n    \"\"\"\n    land_likelihood = calc_land_likelihood(sigma=sigma, x=x, y=y)\n    water_likelihood = calc_water_likelihood(sigma=sigma, x=x, y=y)\n    evidence = (water_likelihood * 0.5) + (land_likelihood * 0.5)\n    water_posterior = (water_likelihood * 0.5) / evidence\n    land_posterior = (land_likelihood * 0.5) / evidence\n    return water_posterior, land_posterior\n\nWe can plot the posterior probabilities of flooding and non-flooding again and compare these to pixelâ€™s measured \\(\\sigma^0\\). For reference we model the flood and non-flood posteriors (model_posteriors) over a range of \\(\\sigma^0\\) values. Hover on a pixel to calculate the posterior probability.\n\ndef model_posteriors(sigma=(-30, 0), x=None, y=None):\n    \"\"\"\n    Model posterior probabilities over a range of sigma naught.\n\n    Parameters\n    ----------\n    sigma: tuple\n        Minimum and maximum for range of sigma naught values\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Pandas Datafrane\n    \"\"\"\n    bays_pd = model_likelihoods(sigma=sigma, x=x, y=y)\n    sigma = np.arange(sigma[0], sigma[1], 0.1)\n    bays_pd[\"f_post_prob\"], bays_pd[\"nf_post_prob\"] = calc_posteriors(\n        sigma=sigma, x=x, y=y\n    )\n    return bays_pd\n\n\nposterior_pdi = hvplot.bind(\n    model_posteriors, x=pointer.param.x, y=pointer.param.y\n).interactive()\n\nview_posteriors = (\n    posterior_pdi.hvplot(\"sigma\", \"f_post_prob\", ylabel=\"posteriors\").dmap()\n    * posterior_pdi.hvplot(\"sigma\", \"nf_post_prob\").dmap()\n    * posterior_pdi.hvplot(\"observed\", \"nf_post_prob\").dmap()\n).opts(frame_height=200, frame_width=300)\n\n(view_likelihoods + view_posteriors).cols(1) + mrs_view.get(1)\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Posterior probabilities for \\(\\sigma^0\\) of 1 pixel being associated with land for water in the Greek area of Thessaly. Hover on the map to re-calculate and update this figure for another pixel in the study area.\n\n\n\n\n\nFigureÂ B.4",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/floodmapping.html#flood-classification",
    "href": "chapters/tutorials/floodmapping.html#flood-classification",
    "title": "Appendix B â€” Reverend Bayes updates our Belief in Flood Detection",
    "section": "B.10 Flood Classification",
    "text": "B.10 Flood Classification\nWe are now ready to combine all this information and classify the pixels according to the probability of flooding given the backscatter value of each pixel. Here we just look whether the probability of flooding is higher than non-flooding:\n\ndef bayesian_flood_decision(sigma, x=None, y=None):\n    \"\"\"\n    Bayesian decision.\n\n    Parameters\n    ----------\n    sigma: float|array\n        Sigma naught value(s)\n    x: float|array\n        Longitude\n    y: float|array\n        Latitude\n\n    Returns\n    -------\n    Xarray DataArray\n    \"\"\"\n    f_post_prob, nf_post_prob = calc_posteriors(sigma=sigma, x=x, y=y)\n    return xr.where(\n        np.isnan(f_post_prob) | np.isnan(nf_post_prob),\n        np.nan,\n        np.greater(f_post_prob, nf_post_prob),\n    )\n\nHover on a point in the below map to see the likelihoods and posterior distributions (in the left-hand subplots).\n\nflood_dc[\"decision\"] = (\n    (\"y\", \"x\"),\n    bayesian_flood_decision(flood_dc.sig0, flood_dc.x, flood_dc.y),\n)\n\ncolorbar_opts = {\n    \"major_label_overrides\": {\n        0: \"non-flood\",\n        1: \"flood\",\n    },\n    \"ticker\": FixedTicker(ticks=[0, 1]),\n}\nflood_view = flood_dc.decision.hvplot.image(\n    x=\"x\", y=\"y\", rasterize=True, geo=True, cmap=[\"rgba(0, 0, 1, 0.1)\", \"darkred\"]\n).opts(frame_height=400, colorbar_opts={**colorbar_opts})\nmrs_view.get(0) * flood_view\n\n\n\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n  \n\n\n\n\n(b) Flood extent of the Greek region of Thessaly based on Bayesian probabilities are shown on the map superimposed on an open street map. Hover over a pixel to generate the pointâ€™s water and land likelihoods as well as the posterior probabilities.\n\n\n\n\n\nFigureÂ B.5\n\n\n\n\n\n\n\n\nBauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian Roth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang Wagner. 2022. â€œSatellite-Based Flood Mapping Through Bayesian Inference from a Sentinel-1 SAR Datacube.â€ Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>B</span>Â  <span class='chapter-title'>Reverend Bayes updates our Belief in Flood Detection</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/harmonic-parameters.html",
    "href": "chapters/tutorials/harmonic-parameters.html",
    "title": "Appendix C â€” Harmonic Parameters of Sentinel 1 Backscatter Time Series",
    "section": "",
    "text": "C.1 Prerequisites\nIn this notebook, we will show the concept of extracting coefficients that describe seasonal patterns in Sentinel 1 radar backscatter variability. Namely, sine and cosine functions as harmonic oscillators are used to describe periodicities in the time series of, either VV or VH polarisations, backscatter. Those can then be removed from time series and what is left would generally be the noise or transient events, for example floods, volcano erruptions, and whatever is possible to detect with radar Earth Observation data.",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>C</span>Â  <span class='chapter-title'>Harmonic Parameters of Sentinel 1 Backscatter Time Series</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/harmonic-parameters.html#prerequisites",
    "href": "chapters/tutorials/harmonic-parameters.html#prerequisites",
    "title": "Appendix C â€” Harmonic Parameters of Sentinel 1 Backscatter Time Series",
    "section": "",
    "text": "Concepts\nImportance\nNotes\n\n\n\n\nIntro to xarray\nNecessary\n\n\n\nIntro to Flood mapping\nNecessary\n\n\n\nDocumentation hvPlot\nHelpful\nInteractive plotting\n\n\n\n\nTime to learn: 10 min",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>C</span>Â  <span class='chapter-title'>Harmonic Parameters of Sentinel 1 Backscatter Time Series</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/harmonic-parameters.html#imports",
    "href": "chapters/tutorials/harmonic-parameters.html#imports",
    "title": "Appendix C â€” Harmonic Parameters of Sentinel 1 Backscatter Time Series",
    "section": "C.2 Imports",
    "text": "C.2 Imports\n\nimport folium\nimport holoviews as hv\nimport hvplot.xarray  # noqa\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\n\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nLoading sigma nought time series.\n\ntimeseries_dc = xr.open_dataset(\n    \"simplecache::zip:///::https://huggingface.co/datasets/martinschobben/tutorials/resolve/main/harmonic-parameters.zarr.zip\",  # noqa\n    engine=\"zarr\",\n    storage_options={\n        \"simplecache\": {\"cache_storage\": \"/tmp/fsspec_cache/harmonic-parameters\"}\n    },\n)\ntimeseries_dc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 29kB\nDimensions:      (point: 2, time: 1214)\nCoordinates:\n  * point        (point) &lt;U4 32B 'land' 'lake'\n    spatial_ref  int32 4B ...\n  * time         (time) datetime64[ns] 10kB 2015-01-05T17:03:45 ... 2022-12-3...\n    x            (point) float64 16B ...\n    y            (point) float64 16B ...\nData variables:\n    VH           (point, time) float32 10kB ...\n    VV           (point, time) float32 10kB ...xarray.DatasetDimensions:point: 2time: 1214Coordinates: (5)point(point)&lt;U4'land' 'lake'array(['land', 'lake'], dtype='&lt;U4')spatial_ref()int32...GeoTransform :5015300 20 0 437360 0 -20crs_wkt :PROJCRS[\"WGS 84 / Equi7 Europe\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Equi7 projection - Europe\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.82,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.696,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Continental mapping of raster data.\"],AREA[\"Europe including Russia west of the Ural Mountains.\"],BBOX[29.24,-42.52,83.67,51.73]],ID[\"EPSG\",27704]]false_easting :5837287.82false_northing :2121415.696geographic_crs_name :WGS 84grid_mapping_name :azimuthal_equidistanthorizontal_datum_name :World Geodetic System 1984 ensembleinverse_flattening :298.257223563latitude_of_projection_origin :53.0longitude_of_prime_meridian :0.0longitude_of_projection_origin :24.0prime_meridian_name :Greenwichprojected_crs_name :WGS 84 / Equi7 Europereference_ellipsoid_name :WGS 84semi_major_axis :6378137.0semi_minor_axis :6356752.314245179spatial_ref :PROJCRS[\"WGS 84 / Equi7 Europe\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Equi7 projection - Europe\",METHOD[\"Azimuthal Equidistant\",ID[\"EPSG\",1125]],PARAMETER[\"Latitude of natural origin\",53,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",24,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",5837287.82,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",2121415.696,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"(E)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"(N)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Continental mapping of raster data.\"],AREA[\"Europe including Russia west of the Ural Mountains.\"],BBOX[29.24,-42.52,83.67,51.73]],ID[\"EPSG\",27704]][1 values with dtype=int32]time(time)datetime64[ns]2015-01-05T17:03:45 ... 2022-12-...array(['2015-01-05T17:03:45.000000000', '2015-01-12T16:55:44.000000000',\n       '2015-01-17T17:03:45.000000000', ..., '2022-12-25T16:56:31.000000000',\n       '2022-12-30T17:04:49.000000000', '2022-12-31T05:05:06.000000000'],\n      shape=(1214,), dtype='datetime64[ns]')x(point)float64...[2 values with dtype=float64]y(point)float64...[2 values with dtype=float64]Data variables: (2)VH(point, time)float32...[2428 values with dtype=float32]VV(point, time)float32...[2428 values with dtype=float32]\n\n\nThe data that is loaded represents VV and VH backsatter polarisations, as detected by Sentinel-1 radar instrument. The two points of interest are on Sicily, nearby Lentini and Catania.\n\nlatmin, latmax = 37.283606, 37.40621527385254\nlonmin, lonmax = 14.826223, 15.109736519516783\n\nbounding_box = [\n    [latmin, lonmin],\n    [latmax, lonmax],\n]\n\nmap = folium.Map(\n    location=[\n        (latmin + latmax) / 2,\n        (lonmin + lonmax) / 2,\n    ],\n    zoom_start=9,\n    zoom_control=True,\n    scrollWheelZoom=False,\n    dragging=True,\n)\n\n\nfolium.Rectangle(\n    bounds=bounding_box,\n    color=\"red\",\n).add_to(map)\n\nfolium.Marker(\n    location=[37.37489461337563, 14.884886613876311],\n    popup=\"Selected Pixel in the flooded land in 2018\",\n    icon=folium.Icon(color=\"red\"),\n).add_to(map)\n\nfolium.Marker(\n    location=[37.32275297904196, 14.947068995810364],\n    popup=\"Selected Pixel in lake Lentini\",\n    icon=folium.Icon(color=\"red\"),\n).add_to(map)\n\nmap\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nLetâ€™s plot time series of those two points.\n\nevent_date = pd.to_datetime(\"2018-05-17\")\n\nlake_curve = timeseries_dc.sel(point=\"lake\").VV.hvplot(\n    label=\"Lake Lentini VV\",\n    width=800,\n    height=300,\n    color=\"navy\",\n    ylabel=\"Sigma0 VV (dB)\",\n    xlabel=\"Time\",\n    title=\"Lake Lentini Pixel\",\n)\n\nland_curve = timeseries_dc.sel(point=\"land\").VV.hvplot(\n    label=\"Land Pixel VV\",\n    width=800,\n    height=300,\n    color=\"olive\",\n    ylabel=\"Sigma0 VV (dB)\",\n    xlabel=\"Time\",\n    title=\"Flooded Land Pixel\",\n)\n\nevent_line = hv.VLine(event_date).opts(color=\"red\", line_dash=\"dashed\", line_width=2)\n\nlake_plot = lake_curve * event_line\nland_plot = land_curve * event_line\n\n(lake_plot + land_plot).cols(1)",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>C</span>Â  <span class='chapter-title'>Harmonic Parameters of Sentinel 1 Backscatter Time Series</span>"
    ]
  },
  {
    "objectID": "chapters/tutorials/harmonic-parameters.html#the-concept-of-harmonic-parameters",
    "href": "chapters/tutorials/harmonic-parameters.html#the-concept-of-harmonic-parameters",
    "title": "Appendix C â€” Harmonic Parameters of Sentinel 1 Backscatter Time Series",
    "section": "C.3 The Concept of Harmonic Parameters",
    "text": "C.3 The Concept of Harmonic Parameters\n\nC.3.1 One Harmonic in Traditional Form\nA single harmonic is an oscillatory function, which can be expressed as:\n\\[ f(t) = A \\cos \\left( \\frac{2\\pi}{n} t + \\phi \\right) \\]\nwhere: - $ A $ is the amplitude of the harmonic, - $ $ is the phase shift in radians, - $ n $ is the period in units of time, - $ 2/n $ angular frequency.\nThe amplitude here can represent a physical quantitiy of interest, for instance temperature, radar backscatter, soil moisture, etc. In a way, anything can be represented as signal and signal processing can be therefore applied to many different scientific fields.\n\n# A simple harmonic oscillator\n\ntime = np.linspace(0, 300, 2000)\namplitude = 1.0\nperiod = 20.0\nphi = 0.0\ny = amplitude * np.cos((2 * np.pi / period) * time + phi)\n\nhv.Curve((time, y), \"Time\", \"Amplitude\").opts(\n    title=\"Simple Cosine Plot\", width=1000, height=600, line_width=2\n)\n\n\n\n\n\n  \n\n\n\n\nNow, if we have measure a physical quantity over a long time period, for example temperature of some region, we have a time series. A harmonic regression is a least-square-fit of a harmonic function to the complex signal - or time series. In regard to microwave backscattering time series this property can be utilized to represent seasonal patterns caused by vegetation. This way we can filter out the vegetation signal from our microwave backscattering time series - to either better understand the physics behind this harmonic or to better detect events that donâ€™t seasonally repeat, like flood events.\nHarmonic parameters would be input parameters that define such fitted harmonic components, in this case: amplitude, shifting phase and period of an oscillating function. However, the period and starting phase are inside the non-linear (sinusoidal) function, so a linearisation has to be done, as those parameters are going to be estimated with a least-square regression algorithm. In our case we will only estimate phase shift and amplitude, not the period of the harmonics.\nUsing the angle sum identity:\n\\[ \\cos(x + y) = \\cos x \\cos y - \\sin x \\sin y \\]\nwe expand:\n\\[ A \\cos \\left( \\frac{2\\pi t}{n} + \\phi \\right) = A \\left[ \\cos \\phi \\cos \\left( \\frac{2\\pi t}{n} \\right) - \\sin \\phi \\sin \\left( \\frac{2\\pi t}{n} \\right) \\right] \\]\n\nC.3.1.1 Defining Coefficients $ c_i $ and $ s_i $\nNow, we can define the coefficients, that have units of a physical quantity (amplitude, such as radar backscatter cross sections):\n\\[ c = A \\cos \\phi, \\quad s = - A \\sin \\phi \\]\nso that the equation becomes:\n\\[ A \\cos \\left( \\frac{2\\pi t}{n} + \\phi \\right) = c \\cdot \\cos \\left( \\frac{2\\pi t}{n} \\right) + s \\cdot \\sin \\left( \\frac{2\\pi t}{n} \\right) \\]\nWe can then extract the starting phase information outside of the sinusoidal function. The period information is still there, but only because in this case it is not estimated in least-square process, but predetermined.\n\n\nC.3.1.2 Generalizing to $ k $ Harmonics\nA complex signal is generally summation of many basic harmonic terms. Summing over all harmonics, we obtain:\n\\[ f(t) = f^0 + \\sum_{i=1}^{k} \\left[ c_i \\cos \\left( \\frac{2\\pi i t}{n} \\right) + s_i \\sin \\left( \\frac{2\\pi i t}{n} \\right) \\right] \\]\nwhere:\n\n$ f^0 $ is the mean function value,\n$ c_i = A_i _i $ and $ s_i = - A_i _i $ are the harmonic coefficients.\n\nIn this form different periodicities are covered, for example with $ i = 1, 2, â€¦ k $, we can have periods of $ , $, and so on.\n\n# Simulation of complex signal with many harmonics\n\nt = np.linspace(0, 15, 1000)\nk = 3\n\ncoefficients = [\n    {\"A\": 3, \"B\": 2, \"n\": 2, \"phi\": 0},\n    {\"A\": 1.5, \"B\": 0.5, \"n\": 5, \"phi\": np.pi / 4},\n    {\"A\": 0.8, \"B\": 1.2, \"n\": 8, \"phi\": np.pi / 2},\n]\n\ncolors = [\"firebrick\", \"navy\", \"seagreen\"]\n\nharmonics = []\nsignal_sum = np.zeros_like(t)\n\nfor coeff in coefficients:\n    harmonic = coeff[\"A\"] * np.cos(\n        (2 * np.pi * coeff[\"n\"] * t) / 10 + coeff[\"phi\"]\n    ) + coeff[\"B\"] * np.sin((2 * np.pi * coeff[\"n\"] * t) / 10 + coeff[\"phi\"])\n    harmonics.append(harmonic)\n    signal_sum += harmonic\n\nmax_amp = max(np.max(np.abs(h)) for h in harmonics + [signal_sum])\n\nfig, axes = plt.subplots(k + 1, 1, figsize=(6, 8), sharex=True)\n\nfor i in range(k):\n    axes[i].plot(t, harmonics[i], label=f\"Harmonic {i + 1}\", color=colors[i])\n    axes[i].legend()\n    axes[i].grid()\n    axes[i].set_ylim(-max_amp, max_amp)\n\naxes[k].plot(\n    t,\n    signal_sum,\n    label=\"Summed Signal = Harmonic 1 + Harmonic 2 + Harmonic 3\",\n    color=\"black\",\n)\naxes[k].legend()\naxes[k].grid()\naxes[k].set_xlabel(\"Time\")\naxes[k].set_ylim(-max_amp, max_amp)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nC.3.2 Recovering Amplitude and Phase\nNow that we have estimated the harmonic coefficients $ c_i \\(** and **\\) s_i $ wit the harmonic regression, we can recover the original amplitude and phase for a physical interpretation, as:\n\\[ A_i = \\sqrt{c_i^2 + s_i^2} \\]\n\\[ \\phi_i = \\tan^{-1} \\left( -\\frac{s_i}{c_i} \\right) \\]\n\n\nC.3.3 Harmonic Model Equation for Radar Backscatter in Flood Detection Algorithm\nThe harmonic model function is given by:\n\\[\n\\widehat{\\sigma}^0 (t_{doy}) = \\sigma^0 + \\sum_{i=1}^{k} \\left\\{ c_i \\cos \\left( \\frac{2\\pi i }{n} t_{doy} \\right) + s_i \\sin \\left( \\frac{2\\pi i}{n} t_{doy} \\right) \\right\\}\n\\]\nwhere:\n\\[\n\\sigma^0 &\\quad \\text{is the effective mean radar backscatter,} \\\\\n\\widehat{\\sigma}^0 (t_{doy}) &\\quad \\text{is the estimated radar backscatter at time } t, \\\\\nt_{doy} &\\quad \\text{is the time instance (as a day of a year),} \\\\\nn &= 365 \\text{ days} \\\\\nc_i, s_i &\\quad \\text{are harmonic coefficients for } i = 1, 2, ..., k, \\\\\nk &\\quad \\text{is the number of harmonic iterations}.\n\\]\nLetâ€™s define a function that will fit a model like this with a least squares method, on a xarray array. Of course, the initial harmonic parameters first need to be estimated or known and their number depends on \\(k\\).\n\ndef build_initial_parameters(array, k):\n    \"\"\"\n    Constructs initial parameters and their names for harmonic curve fitting\n    with option to choose number of k harmonics. Needed for\n    xarray.DataArray.curvefit\n\n    Parameters\n    ----------\n    array : xarray.DataArray\n        The input 1D time series data for which the harmonic model is being\n        fitted.\n\n    k : int\n        Number of harmonics to include in the model. For each harmonic, two\n        parameters\n        (cosine and sine coefficients) will be added: 'c1', 's1', ..., 'ck',\n        'sk'.\n\n    Returns\n    -------\n    param_names : list of str\n        A list of parameter names in the order expected by the harmonic model\n        function.\n        Format: ['mean', 'c1', 's1', ..., 'ck', 'sk'].\n\n    p0 : dict\n        A dictionary containing initial guesses for each parameter.\n        The mean is initialized from the data, and all harmonic coefficients are\n        set to 1.0.\n    \"\"\"\n    mean_val = float(array.mean().values)\n\n    param_names = [\"mean\"]\n    for i in range(1, k + 1):\n        param_names += [f\"c{i}\", f\"s{i}\"]\n\n    p0 = {\"mean\": mean_val}\n    for name in param_names[1:]:\n        p0[name] = 1.0\n\n    return param_names, p0\n\n\ndef harmonic_model(t, mean, *coef):\n    \"\"\"\n    Harmonic model function for fitting periodic components in time series data.\n    To be passed in xarray.DataArray.curvefit as func argument\n\n    This function computes a sum of sine and cosine terms up to a specified\n    number of harmonics. The number of harmonics k is inferred from the length\n    of the coef argument (must be 2 * k). The time variable t is expected to\n    be in nanoseconds, e.g., from datetime64[ns] converted to int.\n\n    Parameters\n    ----------\n    t : array-like or float\n        Time values (in nanoseconds) over which to evaluate the harmonic model.\n        This should match the time coordinate used in the original dataset,\n        converted to integers via .astype('int64').\n\n    mean : float\n        The mean (baseline) value of the signal to which the harmonic components\n        are added.\n\n    *coef : float\n        Variable-length list of harmonic coefficients, ordered as:\n        [c1, s1, c2, s2, ..., ck, sk], where k = len(coef) // 2.\n        Each `ci` and `si` corresponds to the cosine and sine coefficients for\n        the i-th harmonic.\n\n    Returns\n    -------\n    result : array-like or float\n        The computed harmonic model values corresponding to the input t.\n\n    Notes\n    -----\n    The fundamental frequency is assumed to be one cycle per year. The time\n    normalization is based on the number of nanoseconds in a year (365 * 24 * 60\n    * 60 * 1e9).\n    \"\"\"\n    n = 365\n    result = mean\n\n    k = len(coef) // 2  # Number of harmonics\n\n    for i in range(1, k + 1):\n        c_i = coef[2 * (i - 1)]\n        s_i = coef[2 * (i - 1) + 1]\n        result += c_i * np.cos(2 * np.pi * i * t / n) + s_i * np.sin(\n            2 * np.pi * i * t / n\n        )\n\n    return result\n\n\n\nC.3.4 Harmonic Function Fitting\nNow, the two time series can be selected and the coefficients can be estimated. We pick the VV polarisation for a land pixel and 3 harmonics (7 parameters).\n\nland_VV_series = timeseries_dc.sel(point=\"land\").VH\nparam_names, p0 = build_initial_parameters(land_VV_series, k=3)\n\nfit_result = land_VV_series.curvefit(\n    coords=\"time.dayofyear\",\n    func=harmonic_model,\n    param_names=param_names,\n    reduce_dims=\"time\",\n)\n\nfit_result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 820B\nDimensions:                (param: 7, cov_i: 7, cov_j: 7)\nCoordinates:\n    point                  &lt;U4 16B 'land'\n    spatial_ref            int32 4B 27704\n    x                      float64 8B 5.022e+06\n    y                      float64 8B 4.333e+05\n  * param                  (param) &lt;U4 112B 'mean' 'c1' 's1' 'c2' 's2' 'c3' 's3'\n  * cov_i                  (cov_i) &lt;U4 112B 'mean' 'c1' 's1' 'c2' 's2' 'c3' 's3'\n  * cov_j                  (cov_j) &lt;U4 112B 'mean' 'c1' 's1' 'c2' 's2' 'c3' 's3'\nData variables:\n    curvefit_coefficients  (param) float64 56B -21.87 0.9572 ... 0.2654 0.1653\n    curvefit_covariance    (cov_i, cov_j) float64 392B 0.005444 ... 0.0108xarray.DatasetDimensions:param: 7cov_i: 7cov_j: 7Coordinates: (7)point()&lt;U4'land'array('land', dtype='&lt;U4')spatial_ref()int3227704array(27704, dtype=int32)x()float645.022e+06array(5021648.65)y()float644.333e+05array(433262.91)param(param)&lt;U4'mean' 'c1' 's1' ... 's2' 'c3' 's3'array(['mean', 'c1', 's1', 'c2', 's2', 'c3', 's3'], dtype='&lt;U4')cov_i(cov_i)&lt;U4'mean' 'c1' 's1' ... 's2' 'c3' 's3'array(['mean', 'c1', 's1', 'c2', 's2', 'c3', 's3'], dtype='&lt;U4')cov_j(cov_j)&lt;U4'mean' 'c1' 's1' ... 's2' 'c3' 's3'array(['mean', 'c1', 's1', 'c2', 's2', 'c3', 's3'], dtype='&lt;U4')Data variables: (2)curvefit_coefficients(param)float64-21.87 0.9572 ... 0.2654 0.1653array([-21.86538445,   0.95718435,   1.22863733,  -0.66058152,\n        -1.43516171,   0.26540114,   0.165339  ])curvefit_covariance(cov_i, cov_j)float640.005444 -0.0001707 ... 0.0108array([[ 5.44448956e-03, -1.70694361e-04,  1.20456538e-04,\n         9.41079798e-05,  1.68670551e-04, -1.73089038e-05,\n         4.27136268e-05],\n       [-1.70694361e-04,  1.09827868e-02,  1.68924548e-04,\n        -1.87992361e-04,  1.62689437e-04,  8.79983499e-05,\n         1.80398004e-04],\n       [ 1.20456538e-04,  1.68924548e-04,  1.07948096e-02,\n        -7.69060587e-05, -1.54293580e-04, -1.57745977e-04,\n         9.85632262e-05],\n       [ 9.41079798e-05, -1.87992361e-04, -7.69060587e-05,\n         1.08809134e-02,  1.20137030e-05, -1.77589946e-04,\n         1.84420305e-04],\n       [ 1.68670551e-04,  1.62689437e-04, -1.54293580e-04,\n         1.20137030e-05,  1.08905288e-02, -6.16704118e-05,\n        -1.65982088e-04],\n       [-1.73089038e-05,  8.79983499e-05, -1.57745977e-04,\n        -1.77589946e-04, -6.16704118e-05,  1.09693630e-02,\n        -2.79394710e-05],\n       [ 4.27136268e-05,  1.80398004e-04,  9.85632262e-05,\n         1.84420305e-04, -1.65982088e-04, -2.79394710e-05,\n         1.07954085e-02]])\n\n\nLetâ€™s extract and print estimated harmonic parameters for this pixel\n\nestimated_params = fit_result.curvefit_coefficients.values\n\nfor name, val in zip(fit_result.param.values, estimated_params):\n    print(f\"{name: &gt;6}: {val: .4f}\")\n\n  mean: -21.8654\n    c1:  0.9572\n    s1:  1.2286\n    c2: -0.6606\n    s2: -1.4352\n    c3:  0.2654\n    s3:  0.1653\n\n\nNow, these coefficient can be used to construct a total harmonic signal.\n\n# Extract estimated harmonic parameters and reconstruct a signal as xarray dataaray\n\nmean = estimated_params[0]\ncoeffs = estimated_params[1:]\n\nfitted_vals = harmonic_model(timeseries_dc[\"time.dayofyear\"], mean, *coeffs)\n\nfitted_da = xr.DataArray(\n    fitted_vals, coords={\"time\": land_VV_series.time}, dims=\"time\", name=\"Harmonic Fit\"\n)\n\n# Plot the data\n\nplot = land_VV_series.hvplot(\n    label=\"Original\", color=\"forestgreen\", alpha=1\n) * fitted_da.hvplot(label=\"Harmonic Fit\", color=\"darkorange\", line_width=2.5)\n\nplot.opts(\n    title=\"Harmonic Model Fit to VV Timeseries over Land\",\n    xlabel=\"Time\",\n    ylabel=\"VV backscatter\",\n    width=900,\n    height=400,\n)\n\n\n\n\n\n  \n\n\n\n\nWe can see cycles that happen once a year, twice a year and three times a year, so it makes sense to work with time series over several years. Important parameter is a number of observations (NOBS) - the more observations the better. It directly relates to the uncertainty of our estimate. In this respect, the standard deviation is an important parameter, as it tells us how well our harmonic function fits the observations. It does not, however, tell us the uncertainty of the observations, just how well they align with seasonal patterns defined by the model.\n\nresiduals_land = land_VV_series - fitted_da\nsse = np.sum(residuals_land.dropna(dim=\"time\").values ** 2)\n\nnobs = residuals_land.size\ndof = nobs - (2 * k + 1)\n\nstdev = np.sqrt(sse / dof)\n\nprint(f\"Number of observations (NOBS): {nobs}\")\nprint(f\"Estimated standard deviation of the fit: {stdev: .4f}\")\n\nNumber of observations (NOBS): 1214\nEstimated standard deviation of the fit:  2.4799\n\n\nLets plot residuals that were used to calculate standard deviation and see the possible outliers that do not fit those seasonal patterns.\n\nland_residuals_ts = residuals_land.dropna(dim=\"time\")\nland_residuals_ts.name = \"Residual\"\n\nland_residuals_ts.hvplot(\n    label=\"Residuals\",\n    color=\"firebrick\",\n    line_width=2,\n    title=\"Residuals of Harmonic Fit (Land Pixel)\",\n    xlabel=\"Time\",\n    ylabel=\"Residual (VV)\",\n    width=900,\n    height=300,\n) * event_line\n\n\n\n\n\n  \n\n\n\n\n\nC.3.4.1 Lake Lentini Example\nLets see how time summed harmonic signal looks like for a lake pixel, where backscatter is more stable. Therefore, vegetation periodicities should be less pronounced over water.\n\nlake_VV_series = timeseries_dc.sel(point=\"lake\").VV\nparam_names_lake, p0_lake = build_initial_parameters(lake_VV_series, k=3)\n\nfit_result = lake_VV_series.curvefit(\n    coords=\"time\", func=harmonic_model, p0=p0_lake, param_names=param_names_lake\n)\n\nestimated_params_lake = fit_result.curvefit_coefficients.values\n\nfor name, val in zip(fit_result.param.values, estimated_params_lake):\n    print(f\"{name: &gt;6}: {val: .4f}\")\n\n  mean: -20.4635\n    c1: -0.1479\n    s1:  0.1429\n    c2:  0.0382\n    s2: -0.2207\n    c3: -0.2902\n    s3:  0.0870\n\n\n\nmean = estimated_params_lake[0]\ncoeffs = estimated_params_lake[1:]\n\nfitted_vals = harmonic_model(timeseries_dc[\"time.dayofyear\"], mean, *coeffs)\n\nfitted_da = xr.DataArray(\n    fitted_vals, coords={\"time\": lake_VV_series.time}, dims=\"time\", name=\"Harmonic Fit\"\n)\n\nplot = lake_VV_series.hvplot(\n    label=\"Original\", color=\"navy\", alpha=0.75\n) * fitted_da.hvplot(label=\"Harmonic Fit\", color=\"darkorange\", line_width=2.5)\n\nplot.opts(\n    title=\"Harmonic Model Fit to VV Timeseries of a pixel inside lake Lentini\",\n    xlabel=\"Time\",\n    ylabel=\"VV backscatter\",\n    width=900,\n    height=400,\n)\n\n\n\n\n\n  \n\n\n\n\n\nresiduals_lake = lake_VV_series - fitted_da\nsse = np.sum(residuals_lake.dropna(dim=\"time\").values ** 2)\n\nnobs = residuals_lake.size\ndof = nobs - (2 * k + 1)\n\nstdev = np.sqrt(sse / dof)\n\nprint(f\"Number of observations (NOBS): {nobs}\")\nprint(f\"Estimated standard deviation of the fit: {stdev: .4f}\")\n\nNumber of observations (NOBS): 1214\nEstimated standard deviation of the fit:  3.2212\n\n\n\nlake_residuals_ts = residuals_lake.dropna(dim=\"time\")\nlake_residuals_ts.name = \"Residual\"\n\nlake_residuals_ts.hvplot(\n    label=\"Residuals\",\n    color=\"firebrick\",\n    line_width=2,\n    title=\"Residuals of Harmonic Fit (Lake Pixel)\",\n    xlabel=\"Time\",\n    ylabel=\"Residual (VV)\",\n    width=900,\n    height=300,\n)\n\n\n\n\n\n  \n\n\n\n\nAs one can notice, general pattern is a more stochastic signal. One can argue that setting k = 3 actually introduces artifacts, as the original signal was not periodic in the first place.\n\n\n\nC.3.5 Overfitting Problem - Choosing \\(k\\) iterations\nParameter \\(k\\) that governs the number of harmonic terms, is usually two or three. Higher order terms would lead to overfitting. A flood event in time series would be an impulse (jump in backscatter value) that would propagate as an artefact if higher order harmonics are fitted to years-long time series. Higher order terms would usually have low amplitude, an estimation of those would highly depend on noise level in signal. Therefore, those harmonics would not be of a physical nature, or in other words, they wouldnâ€™t represent seasonal vegetation cycles.\n\nks = [1, 2, 3, 10]\nfitted_das = []\n\nfor k in ks:\n    param_names, p0 = build_initial_parameters(land_VV_series, k)\n\n    fit_result = land_VV_series.curvefit(\n        coords=\"time.dayofyear\",\n        func=harmonic_model,\n        param_names=param_names,\n        reduce_dims=\"time\",\n    )\n\n    estimated_params = fit_result.curvefit_coefficients.values\n    mean = estimated_params[0]\n    coeffs = estimated_params[1:]\n    fitted_vals = harmonic_model(timeseries_dc[\"time.dayofyear\"], mean, *coeffs)\n\n    fitted_da = xr.DataArray(\n        fitted_vals,\n        coords={\"time\": land_VV_series.time},\n        dims=\"time\",\n        name=f\"Harmonic Fit (k={k})\",\n    )\n    fitted_das.append(fitted_da)\n\nplot = land_VV_series.hvplot(label=\"Original\", color=\"black\", alpha=0.6)\n\ncolors = [\"red\", \"orange\", \"green\", \"blue\"]\n\nfor da, k_val, color in zip(fitted_das, ks, colors):\n    plot *= da.hvplot(label=f\"k = {k_val}\", line_width=2, color=color)\n\nplot.opts(\n    title=\"Harmonic Fits of VV Timeseries for Multiple k Values\",\n    xlabel=\"Time\",\n    ylabel=\"VV Backscatter\",\n    width=900,\n    height=400,\n    legend_position=\"top_left\",\n)",
    "crumbs": [
      "Appendices",
      "Tutorials",
      "<span class='chapter-number'>C</span>Â  <span class='chapter-title'>Harmonic Parameters of Sentinel 1 Backscatter Time Series</span>"
    ]
  },
  {
    "objectID": "chapters/references.html",
    "href": "chapters/references.html",
    "title": "Appendix D â€” References",
    "section": "",
    "text": "Bauer-Marschallinger, Bernhard, Senmao Cao, Mark Edwin Tupas, Florian\nRoth, Claudio Navacchi, Thomas Melzer, Vahid Freeman, and Wolfgang\nWagner. 2022. â€œSatellite-Based Flood\nMapping Through Bayesian\nInference from a Sentinel-1 SAR\nDatacube.â€ Remote Sensing 14 (15): 3673. https://doi.org/10.3390/rs14153673.\n\n\nNASA. 2020. â€œEarth Observatory.â€ 2020. https://earthobservatory.nasa.gov/features/MeasuringVegetation/measuring_vegetation_2.php.\n\n\nRouse, John Wilson, RÃ¼diger H Haas, John A Schell, Donald W Deering, et\nal. 1974. â€œMonitoring Vegetation Systems in the Great Plains with\nERTS.â€ NASA Spec. Publ 351 (1): 309.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>Â  <span class='chapter-title'>References</span>"
    ]
  }
]